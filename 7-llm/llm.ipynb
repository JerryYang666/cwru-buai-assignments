{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "131542db",
   "metadata": {
    "id": "25577984"
   },
   "source": [
    "# Prompt Tuning & Response Control — 9‑Point Homework\n",
    "\n",
    "**Dataset:** None  \n",
    "Name: Ruihuang Yang  \n",
    "NetID: rxy216  \n",
    "Date: 11/24/2025  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b647e7df",
   "metadata": {
    "id": "1649abe8"
   },
   "source": [
    "## 0. API Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b074b3",
   "metadata": {
    "id": "35ad9dfa"
   },
   "outputs": [],
   "source": [
    "# Load basic libraries\n",
    "# Do NOT import these libraries again below\n",
    "# Re-importing (writing inefficient code) will result in a 0.5 point deduction\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os, json, datetime, textwrap\n",
    "\n",
    "\n",
    "def _require_env_var(name: str) -> str:\n",
    "    \"\"\"Fetch required env var and fail fast with a helpful message.\"\"\"\n",
    "    value = os.getenv(name)\n",
    "    if not value:\n",
    "        raise RuntimeError(\n",
    "            f\"Environment variable '{name}' is missing. \"\n",
    "            \"Set it in your shell or `.env` file.\"\n",
    "        )\n",
    "    return value\n",
    "\n",
    "\n",
    "# Load environment variables from .env if present\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692cba78",
   "metadata": {
    "id": "bbcbd883"
   },
   "outputs": [],
   "source": [
    "XLAB_API_KEY = _require_env_var(\"XLAB_API_KEY\")\n",
    "LLM_BASE_URL = _require_env_var(\"LLM_BASE_URL\")\n",
    "MODEL_PATH = _require_env_var(\"LLM_MODEL_PATH\")\n",
    "client = OpenAI(\n",
    "    api_key=XLAB_API_KEY,\n",
    "    base_url=LLM_BASE_URL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95572526",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "933cf1a3",
    "outputId": "edff4bef-22c1-4cf4-fea0-10b887f7f8b0"
   },
   "outputs": [],
   "source": [
    "#DO NOT RUN! This is an example code\n",
    "\n",
    "def show_tweet_by_temperature(temp):\n",
    "    resp = client.chat.completions.create(\n",
    "        model=MODEL_PATH,\n",
    "        messages=[{\"role\": \"user\", \"content\":  \"Write a poetic tweet about AI and humanity discovering each other for the first time. /no_think\"}],\n",
    "        temperature=temp,\n",
    "        max_tokens=2000\n",
    "    )\n",
    "    tweet = resp.choices[0].message.content.strip()\n",
    "    print(f\"\\n Temperature = {temp}\")\n",
    "    print(tweet)\n",
    "\n",
    "# Run demo\n",
    "for t in [0.1, 0.9]:\n",
    "    show_tweet_by_temperature(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76ea599",
   "metadata": {
    "id": "8ae18372"
   },
   "source": [
    "## Q1 (2 pt) — Temperature Controls\n",
    "\n",
    "**Goal:** Observe how model behavior changes when varying the sampling parameters `temperature` and `top_p`, while keeping the **prompt fixed**.\n",
    "\n",
    "\n",
    "### **Tasks**\n",
    "\n",
    "1. **Keep the prompt, max_tokens, and function name exactly as specified.** (0.5 pt)  \n",
    "   To receive full credit for this part, your code must:\n",
    "   - Use **exactly** the following prompt (no changes in wording or punctuation):  \n",
    "     `\"Write five different short, catchy marketing slogans for a new coffee machine. Do not explain or think — only output the slogan itself.\"`\n",
    "   - Set **`max_tokens = 150`**\n",
    "   - Name the function **exactly** `show_slogan`\n",
    "\n",
    "2. **Run the model with four different sampling settings** on the **same prompt.** (0.5 pt)\n",
    "\n",
    "   You will explore how `temperature` and `top_p` jointly influence creativity, tone, and originality in marketing messages.\n",
    "\n",
    "   - **`temperature`** controls **randomness**:  \n",
    "     - Lower values (e.g., `0.1`) → more focused, consistent, and “safe” slogans.  \n",
    "     - Higher values (e.g., `0.9`) → more varied, bold, and creative slogans.\n",
    "\n",
    "   - **`top_p` (nucleus sampling)** controls **how much of the probability mass** the model samples from:  \n",
    "     - Smaller values (e.g., `0.3`) → restricts the model to only the most likely word choices (predictable).  \n",
    "     - Larger values (e.g., `1.0`) → allows it to explore a broader set of possible words (diverse and imaginative).\n",
    "\n",
    "   **Run all four combinations below using the same prompt:**\n",
    "\n",
    "   | Setting | temperature | top_p |\n",
    "   |----------|--------------|-------|\n",
    "   | A | 0.1 | 0.3 |\n",
    "   | B | 0.1 | 1.0 |\n",
    "   | C | 0.9 | 0.3 |\n",
    "   | D | 0.9 | 1.0 |\n",
    "\n",
    "   For each case, clearly label and print the output (e.g., `= Setting A: temp=0.1, top_p=0.3 =`).\n",
    "\n",
    "3. **Show all outputs** clearly labeled in the console. (0.5 pt)\n",
    "\n",
    "4. **(Markdown cell)**  \n",
    "   Write a short comparison (3–4 bullet points) describing how the outputs differ. (0.5 pt)  \n",
    "   You may comment on:  \n",
    "   - Simplicity vs. creativity  \n",
    "   - Variety of slogans\n",
    "\n",
    "*Note:* In some cases, you may notice **no difference** among the four outputs.  \n",
    "   If no difference appears, simply write that there was no noticeable variation.  \n",
    "   If differences exist, describe how they change.  \n",
    "   Finally, **imagine you are a marketing manager**, explain **which sampling style** (e.g., low or high temperature)  \n",
    "   you would prefer to use for generating slogans, and why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6bfbe8",
   "metadata": {
    "id": "c679a9a8"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2126ea9",
   "metadata": {
    "id": "ddbeb455"
   },
   "source": [
    "## Q2 (2 pt) — Output Length Control (max_tokens)\n",
    "\n",
    "**Goal:** Observe how changing max_tokens influences the generated content.\n",
    "\n",
    "\n",
    "### **Tasks**\n",
    "\n",
    "1. **Keep the prompt, temperature, top_p, and function name exactly as specified.** (0.5 pt)  \n",
    "   To receive full credit for this part, your code must:\n",
    "   - Use **exactly** the following prompt (no changes in wording or punctuation):  \n",
    "     `\"Write a full email introducing a new coffee subscription service. Do not explain or think — only output the email itself.\"`\n",
    "   - Name the function **exactly** `show_email`\n",
    "   - temperature=0.5, top_p=0.5.\n",
    "\n",
    "2. **Run the model three times, once for each max_tokens value: 50, 500, 1000** (0.5 pt)\n",
    "   For each case, clearly label and print the output (e.g., max_tokens = 50).\n",
    "\n",
    "3. **Show all outputs** clearly labeled in the console. (0.5 pt)\n",
    "\n",
    "4. **(Markdown cell)**  \n",
    "   Write a short comparison (3–4 bullet points) describing how the outputs differ. (0.5 pt)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf07af1d",
   "metadata": {
    "id": "426da8c5"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ad0854e",
   "metadata": {
    "id": "1a120993"
   },
   "source": [
    "## Q3 (2 pt) — Reducing Repetition (frequency_penalty)\n",
    "\n",
    "**Goal:** Observe how adjusting frequency_penalty changes repetition and naturalness in generated descriptions.\n",
    "\n",
    "\n",
    "### **Tasks**\n",
    "\n",
    "1. **Keep the prompt, temperature, top_p, max_token and function name exactly as specified.** (0.5 pt)  \n",
    "   To receive full credit for this part, your code must:\n",
    "   - Use **exactly** the following prompt (no changes in wording or punctuation):  \n",
    "     `\"Write a detailed product description for a new coffee machine. Do not explain or think — only output the description itself.\"`\n",
    "   - Name the function **exactly** `show_description`\n",
    "   - temperature=0.7, top_p=0.9.\n",
    "   - max_token = 1000.\n",
    "\n",
    "2. **Run the model three times, once for each frequency_penalty value: 0.0, 0.5, 1.0** (0.5 pt)\n",
    "   frequency_penalty is a parameter that reduces the likelihood of the model repeating the same words or phrases in its output.\n",
    "   For each case, clearly label and print the output (e.g., frequency_penalty = 0.5).\n",
    "\n",
    "3. **Show all outputs** clearly labeled in the console. (0.5 pt)\n",
    "\n",
    "4. **(Markdown cell)**  \n",
    "   Write a short comparison (3–4 bullet points) describing how the outputs differ. (0.5 pt)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1718839",
   "metadata": {
    "id": "16f89e27"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2d02fd6",
   "metadata": {
    "id": "50b7c8a8"
   },
   "source": [
    "## Q4 (2 pt) — Encouraging Novelty (presence_penalty)\n",
    "\n",
    "**Goal:** Observe how presence_penalty encourages the model to generate more diverse or exploratory ideas.\n",
    "\n",
    "\n",
    "### **Tasks**\n",
    "\n",
    "1. **Keep the prompt, temperature, top_p, max_token and function name exactly as specified.** (0.5 pt)  \n",
    "   To receive full credit for this part, your code must:\n",
    "   - Use **exactly** the following prompt (no changes in wording or punctuation):  \n",
    "     `\"Generate five creative social media post ideas to promote a new coffee machine. Do not explain or think — only output the post itself.\"`\n",
    "   - Name the function **exactly** `show_posts`\n",
    "   - temperature=0.8, top_p=0.9.\n",
    "   - max_token = 1000.\n",
    "\n",
    "2. **Run the model three times, once for each presence_penalty value: 0.0, 0.5, 1.0** (0.5 pt)\n",
    "   presence_penalty is a parameter that encourages the model to introduce new ideas or words instead of repeating ones it has already used.\n",
    "   For each case, clearly label and print the output (e.g., presence_penalty = 0.5).\n",
    "\n",
    "3. **Show all outputs** clearly labeled in the console. (0.5 pt)\n",
    "\n",
    "4. **(Markdown cell)**  \n",
    "   Write a short comparison (3–4 bullet points) describing how the outputs differ. (0.5 pt)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d0ac0f",
   "metadata": {
    "id": "2b423ee5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b63d5658",
   "metadata": {
    "id": "c3d09372"
   },
   "source": [
    "## Q5 (1 pt) — Applying LLMs to Real Marketing Scenarios\n",
    "\n",
    "Think creatively about how LLMs can be applied to solve real marketing problems.\n",
    "\n",
    "So far, you have experimented with LLMs to:\n",
    "\n",
    "Generate marketing slogans, Write promotional emails, Craft product descriptions, Suggest social media post ideas (Q4)\n",
    "\n",
    "These tasks show how LLMs can automate and enhance content creation.\n",
    "Now, imagine you are a digital marketing strategist planning to integrate LLM tools into your marketing workflow.\n",
    "\n",
    "**Tasks**\n",
    "\n",
    "1. Propose 3 new marketing use cases for LLMs (beyond the four above).\n",
    "\n",
    "- Think beyond copywriting.\n",
    "- Your ideas can involve areas such as: Market research or trend detection, Customer segmentation and personalization, Sentiment or review analysis, A/B test generation, etc.\n",
    "\n",
    "2. Provide specific task or workflow step for one marketing use case.\n",
    "\n",
    "- Choose one of your ideas and describe concretely how you would implement it using an LLM.\n",
    "- Describe the input prompts you might use.\n",
    "- Explain what outputs you would expect.\n",
    "- Briefly discuss potential challenges or risks (e.g., hallucination, bias).\n",
    "\n",
    "**Submission Format**\n",
    "\n",
    "- Markdown cell only — no code required.\n",
    "- Write your response in 2 sections:\n",
    "\n",
    "Section A: List 3–4 new marketing use cases (bullet points)\n",
    "\n",
    "Section B: Choose one idea and describe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870c6b48",
   "metadata": {
    "id": "a375f9ad"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
