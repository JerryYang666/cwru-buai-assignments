{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "714adb97",
   "metadata": {},
   "source": [
    "# BUAI 446 Assignment 1 - Akron Zoo Membership Upgrade Prediction\n",
    "\n",
    "**Name:** Ruihuang Yang, Bochen Fu  \n",
    "**NetID:** rxy216, bxf196  \n",
    "**Date:** 09/07/2025  \n",
    "\n",
    "**Disclaimer:** Some code in this document was generated with assistance from Claude 4.0 Sonnet.  \n",
    "**Prompts used:**  \n",
    "- \"Please clean up the code, make it more well formatted and more readable. For all comments, please optimize the grammar and sentence structure.\"  \n",
    "- \"Please generate beautiful plots for this ML pipeline at important points along the way so that I can use the visualizations to report the results to executives of the company.\"  \n",
    "- \"Please add comprehensive print statements in the code so that I can get lots of useful information for the report to executives of the company.\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815e5945",
   "metadata": {},
   "source": [
    "## Executive Summary & Analytical Approach\n",
    "\n",
    "### Business Problem\n",
    "This analysis addresses Akron Zoo's need to **identify reliable predictors of membership upgrades** at annual renewal. Our goal is to develop an interpretable, high-accuracy classification model that can:\n",
    "- Predict upgrade probability for individual customers\n",
    "- Identify the most influential features for management decisions\n",
    "- Quantify the predictive effects of key variables\n",
    "- Generate actionable business insights for increasing upgrade rates\n",
    "\n",
    "### Analytical Strategy\n",
    "We implement a **comprehensive model comparison approach** testing multiple algorithms to identify the optimal balance between predictive accuracy and business interpretability:\n",
    "\n",
    "1. **Logistic Regression**\n",
    "2. **Support Vector Machine**\n",
    "3. **Naive Bayes**\n",
    "4. **Random Forest**\n",
    "5. **Gradient Boosting**\n",
    "6. **K-Nearest Neighbors**\n",
    "\n",
    "### Success Criteria\n",
    "- **Accuracy**: >80% on held-out test set with statistical significance testing\n",
    "- **Robustness**: Consistent performance across cross-validation folds\n",
    "- **Interpretability**: Clear feature importance rankings for management decisions\n",
    "- **Business Impact**: Actionable insights for customer retention and upgrade strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d9865a",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Loading\n",
    "### Library Import Strategy\n",
    "We import libraries progressively as needed for each analysis phase, ensuring clean organization and explaining the purpose of each major library group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab5bebf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde1a776",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)\n",
    "### Strategic Approach to Data Understanding\n",
    "\n",
    "#### Phase 1: Data Quality Assessment\n",
    "- **Completeness**: Verify no missing values (critical for model reliability)\n",
    "- **Balance**: Confirm target variable distribution (affects model selection)\n",
    "- **Scale**: Understand feature ranges (impacts algorithm choice)\n",
    "- **Types**: Categorize features for appropriate preprocessing\n",
    "\n",
    "#### Phase 2: Univariate Analysis\n",
    "- **Distribution Analysis**: Identify skewness, outliers, and data quality issues\n",
    "- **Target Correlation**: Rank features by predictive potential\n",
    "- **Business Logic Validation**: Ensure patterns align with domain knowledge\n",
    "\n",
    "### Visualization Philosophy\n",
    "All visualizations are designed with **executive presentation in mind**, emphasizing:\n",
    "- **Aesthetic Appeal**: Professional styling for stakeholder engagement\n",
    "- **Clear Insights**: Direct business interpretation of patterns\n",
    "- **Statistical Rigor**: Confidence intervals and significance testing\n",
    "- **Actionable Intelligence**: Focus on implementable findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "489f566b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (740, 20)\n",
      "Test Data Shape: (303, 20)\n"
     ]
    }
   ],
   "source": [
    "# Load training and test datasets\n",
    "train_data = pd.read_csv(\"data/ZOOLOG1-TRAIN-2025.csv\")\n",
    "test_data = pd.read_csv(\"data/ZOOLOG1-TEST-2025.csv\")\n",
    "\n",
    "print(\"Training Data Shape:\", train_data.shape)\n",
    "print(\"Test Data Shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551c4a9a",
   "metadata": {},
   "source": [
    "#### Basic Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f253ec59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data - First 5 rows:\n",
      "   NID  UPD  benefits   costs   value  identity    know     sat     fle  \\\n",
      "0    1    0    0.8011 -0.2225 -0.2900    0.7353  0.4332  0.8511 -0.6795   \n",
      "1    2    0   -0.8915 -0.2831  0.8196   -0.9243 -2.4690  0.8511 -0.6795   \n",
      "2    3    1   -0.4484  1.0290 -0.4391   -0.8858 -0.2342  0.8511  0.8696   \n",
      "3    4    0   -0.9444  0.4703 -1.6980   -0.2679 -0.6842 -0.5246 -1.2470   \n",
      "4    5    0   -0.1004  0.8337 -0.4391   -1.0960 -0.6842 -0.5246  0.3787   \n",
      "\n",
      "   trustfor  age  gender  educ  mstat  size  child1  dist  tvis  age_rec  \\\n",
      "0 -0.057583    4       2     1      1     3       4     3     3        3   \n",
      "1  0.105467    2       2     3      1     5       3     4     2        1   \n",
      "2 -0.057583    2       2     4      1     5       3     3     3        1   \n",
      "3 -0.709000    4       1     3      1     5       3     4     3        3   \n",
      "4 -1.732333    4       1     2      1     2       4     3     5        3   \n",
      "\n",
      "   educnew  \n",
      "0        0  \n",
      "1        1  \n",
      "2        2  \n",
      "3        1  \n",
      "4        0  \n"
     ]
    }
   ],
   "source": [
    "# Display first few rows of training data\n",
    "print(\"Training Data - First 5 rows:\")\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abee0b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Data - Column Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 740 entries, 0 to 739\n",
      "Data columns (total 20 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   NID       740 non-null    int64  \n",
      " 1   UPD       740 non-null    int64  \n",
      " 2   benefits  740 non-null    float64\n",
      " 3   costs     740 non-null    float64\n",
      " 4   value     740 non-null    float64\n",
      " 5   identity  740 non-null    float64\n",
      " 6   know      740 non-null    float64\n",
      " 7   sat       740 non-null    float64\n",
      " 8   fle       740 non-null    float64\n",
      " 9   trustfor  740 non-null    float64\n",
      " 10  age       740 non-null    int64  \n",
      " 11  gender    740 non-null    int64  \n",
      " 12  educ      740 non-null    int64  \n",
      " 13  mstat     740 non-null    int64  \n",
      " 14  size      740 non-null    int64  \n",
      " 15  child1    740 non-null    int64  \n",
      " 16  dist      740 non-null    int64  \n",
      " 17  tvis      740 non-null    int64  \n",
      " 18  age_rec   740 non-null    int64  \n",
      " 19  educnew   740 non-null    int64  \n",
      "dtypes: float64(8), int64(12)\n",
      "memory usage: 115.8 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display column information\n",
    "print(\"\\nTraining Data - Column Info:\")\n",
    "print(train_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d01186ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Data - Descriptive Statistics:\n",
      "               NID         UPD    benefits       costs       value  \\\n",
      "count   740.000000  740.000000  740.000000  740.000000  740.000000   \n",
      "mean    524.189189    0.500000   -0.032099   -0.007556   -0.035639   \n",
      "std     305.265029    0.500338    1.209893    1.090441    1.053612   \n",
      "min       1.000000    0.000000   -4.988000   -1.332000   -4.728000   \n",
      "25%     257.500000    0.000000   -0.643500   -1.039000   -0.439100   \n",
      "50%     531.500000    0.500000    0.152200    0.043310    0.370100   \n",
      "75%     790.500000    1.000000    0.811500    0.673700    0.819600   \n",
      "max    1042.000000    1.000000    1.355000    4.169000    0.819600   \n",
      "\n",
      "         identity        know         sat         fle    trustfor         age  \\\n",
      "count  740.000000  740.000000  740.000000  740.000000  740.000000  740.000000   \n",
      "mean    -0.025827   -0.020556   -0.027073   -0.006966    0.003556    3.459459   \n",
      "std      1.105308    1.065872    1.037607    1.030317    0.884611    1.007270   \n",
      "min     -4.201000   -2.919000   -5.356000   -5.480000   -2.755833    1.000000   \n",
      "25%     -0.653200   -0.684200   -0.524600   -0.188600   -0.546417    3.000000   \n",
      "50%     -0.006795    0.433200    0.179400    0.378700   -0.057583    3.000000   \n",
      "75%      0.888100    0.433200    0.851100    0.869600    0.639967    4.000000   \n",
      "max      1.353000    1.551000    0.851100    0.869600    1.337667    5.000000   \n",
      "\n",
      "           gender        educ       mstat        size      child1        dist  \\\n",
      "count  740.000000  740.000000  740.000000  740.000000  740.000000  740.000000   \n",
      "mean     1.706757    2.979730    1.218919    3.633784    2.204054    2.905405   \n",
      "std      0.455557    0.904579    0.627014    1.314927    1.701781    0.859066   \n",
      "min      1.000000    1.000000    1.000000    1.000000    0.000000    1.000000   \n",
      "25%      1.000000    2.000000    1.000000    2.000000    1.000000    2.000000   \n",
      "50%      2.000000    3.000000    1.000000    4.000000    2.000000    3.000000   \n",
      "75%      2.000000    4.000000    1.000000    4.000000    3.000000    4.000000   \n",
      "max      2.000000    4.000000    4.000000    6.000000    6.000000    4.000000   \n",
      "\n",
      "             tvis     age_rec     educnew  \n",
      "count  740.000000  740.000000  740.000000  \n",
      "mean     2.743243    2.464865    1.051351  \n",
      "std      1.388731    0.996670    0.775163  \n",
      "min      1.000000    1.000000    0.000000  \n",
      "25%      2.000000    2.000000    0.000000  \n",
      "50%      2.000000    2.000000    1.000000  \n",
      "75%      4.000000    3.000000    2.000000  \n",
      "max      5.000000    4.000000    2.000000  \n"
     ]
    }
   ],
   "source": [
    "# Display basic statistics\n",
    "print(\"\\nTraining Data - Descriptive Statistics:\")\n",
    "print(train_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd766779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in training data:\n",
      "NID         0\n",
      "UPD         0\n",
      "benefits    0\n",
      "costs       0\n",
      "value       0\n",
      "identity    0\n",
      "know        0\n",
      "sat         0\n",
      "fle         0\n",
      "trustfor    0\n",
      "age         0\n",
      "gender      0\n",
      "educ        0\n",
      "mstat       0\n",
      "size        0\n",
      "child1      0\n",
      "dist        0\n",
      "tvis        0\n",
      "age_rec     0\n",
      "educnew     0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in test data:\n",
      "NID         0\n",
      "UPD         0\n",
      "benefits    0\n",
      "costs       0\n",
      "value       0\n",
      "identity    0\n",
      "know        0\n",
      "sat         0\n",
      "fle         0\n",
      "trustfor    0\n",
      "age         0\n",
      "gender      0\n",
      "educ        0\n",
      "mstat       0\n",
      "size        0\n",
      "child1      0\n",
      "dist        0\n",
      "tvis        0\n",
      "age_rec     0\n",
      "educnew     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values in training data:\")\n",
    "print(train_data.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in test data:\")\n",
    "print(test_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16095ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable (UPD) distribution in training data:\n",
      "UPD\n",
      "0    370\n",
      "1    370\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Upgrade rate: 0.500\n"
     ]
    }
   ],
   "source": [
    "# Check target variable distribution\n",
    "print(\"\\nTarget variable (UPD) distribution in training data:\")\n",
    "print(train_data[\"UPD\"].value_counts())\n",
    "print(f\"\\nUpgrade rate: {train_data['UPD'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc484991",
   "metadata": {},
   "source": [
    "### EDA Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7a11e62",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from scipy.stats import chi2_contingency\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Create graphs directory if it doesn't exist\n",
    "os.makedirs(\"graphs\", exist_ok=True)\n",
    "\n",
    "# Set up beautiful styling for plots\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "plt.rcParams[\"axes.titlesize\"] = 16\n",
    "plt.rcParams[\"axes.labelsize\"] = 14\n",
    "plt.rcParams[\"xtick.labelsize\"] = 12\n",
    "plt.rcParams[\"ytick.labelsize\"] = 12\n",
    "plt.rcParams[\"legend.fontsize\"] = 12\n",
    "\n",
    "# Define a professional color palette\n",
    "colors = [\"#2E86AB\", \"#A23B72\", \"#F18F01\", \"#C73E1D\", \"#592E83\", \"#27AE60\"]\n",
    "upgrade_colors = [\"#E74C3C\", \"#2ECC71\"]  # Red for No Upgrade, Green for Upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111daab3",
   "metadata": {},
   "source": [
    "#### Dataset Balance Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55cf9ab9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Balance Summary:\n",
      "• No Upgrade: 370 customers (50.0%)\n",
      "• Upgrade: 370 customers (50.0%)\n",
      "• Perfect balance ratio: 1:1\n",
      "• Total sample size: 740 customers\n"
     ]
    }
   ],
   "source": [
    "# Create a comprehensive view of dataset balance\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar chart showing upgrade distribution\n",
    "upgrade_counts = train_data[\"UPD\"].value_counts().sort_index()\n",
    "bars = ax1.bar(\n",
    "    [\"No Upgrade\", \"Upgrade\"],\n",
    "    upgrade_counts.values,\n",
    "    color=upgrade_colors,\n",
    "    alpha=0.8,\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=2,\n",
    ")\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, count) in enumerate(zip(bars, upgrade_counts.values)):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 5,\n",
    "        f\"{count}\\n({count / len(train_data) * 100:.1f}%)\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "\n",
    "ax1.set_title(\n",
    "    \"Customer Upgrade Distribution\\n(Training Dataset)\", fontweight=\"bold\", pad=20\n",
    ")\n",
    "ax1.set_ylabel(\"Number of Customers\", fontweight=\"bold\")\n",
    "ax1.set_ylim(0, max(upgrade_counts.values) * 1.15)\n",
    "ax1.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "# Add sample size annotation\n",
    "ax1.text(\n",
    "    0.5,\n",
    "    -0.15,\n",
    "    f\"Total Sample Size: {len(train_data)} customers\",\n",
    "    transform=ax1.transAxes,\n",
    "    ha=\"center\",\n",
    "    fontsize=12,\n",
    "    style=\"italic\",\n",
    ")\n",
    "\n",
    "# Pie chart for visual balance\n",
    "wedges, texts, autotexts = ax2.pie(\n",
    "    upgrade_counts.values,\n",
    "    labels=[\"No Upgrade\\n(50.0%)\", \"Upgrade\\n(50.0%)\"],\n",
    "    colors=upgrade_colors,\n",
    "    autopct=\"\",\n",
    "    startangle=90,\n",
    "    textprops={\"fontsize\": 14, \"fontweight\": \"bold\"},\n",
    "    wedgeprops={\"edgecolor\": \"white\", \"linewidth\": 3},\n",
    ")\n",
    "\n",
    "ax2.set_title(\n",
    "    \"Dataset Balance Visualization\\n(Perfectly Balanced)\", fontweight=\"bold\", pad=20\n",
    ")\n",
    "\n",
    "# Add center circle for donut effect\n",
    "centre_circle = plt.Circle((0, 0), 0.50, fc=\"white\", linewidth=2, edgecolor=\"gray\")\n",
    "ax2.add_artist(centre_circle)\n",
    "ax2.text(\n",
    "    0,\n",
    "    0,\n",
    "    \"Balanced\\nDataset\",\n",
    "    ha=\"center\",\n",
    "    va=\"center\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\",\n",
    "    color=\"gray\",\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graphs/01_dataset_balance.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print(\"Dataset Balance Summary:\")\n",
    "print(\n",
    "    f\"• No Upgrade: {upgrade_counts[0]} customers ({upgrade_counts[0] / len(train_data) * 100:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"• Upgrade: {upgrade_counts[1]} customers ({upgrade_counts[1] / len(train_data) * 100:.1f}%)\"\n",
    ")\n",
    "print(\"• Perfect balance ratio: 1:1\")\n",
    "print(f\"• Total sample size: {len(train_data)} customers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbcc340",
   "metadata": {},
   "source": [
    "#### Distance vs Upgrade Behavior Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fcb136c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance vs Upgrade Analysis:\n",
      "==================================================\n",
      "< 10 min    :  37 customers,  27 upgrades ( 73.0%)\n",
      "10-20 min   : 200 customers, 105 upgrades ( 52.5%)\n",
      "21-30 min   : 299 customers, 147 upgrades ( 49.2%)\n",
      "> 30 min    : 204 customers,  91 upgrades ( 44.6%)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Create distance labels for better visualization\n",
    "distance_labels = {1: \"< 10 min\", 2: \"10-20 min\", 3: \"21-30 min\", 4: \"> 30 min\"}\n",
    "train_data[\"dist_label\"] = train_data[\"dist\"].map(distance_labels)\n",
    "\n",
    "# Calculate upgrade rates by distance\n",
    "dist_analysis = (\n",
    "    train_data.groupby(\"dist_label\").agg({\"UPD\": [\"count\", \"sum\", \"mean\"]}).round(3)\n",
    ")\n",
    "dist_analysis.columns = [\"Total_Customers\", \"Upgrades\", \"Upgrade_Rate\"]\n",
    "dist_analysis = dist_analysis.reindex(\n",
    "    [\"< 10 min\", \"10-20 min\", \"21-30 min\", \"> 30 min\"]\n",
    ")\n",
    "\n",
    "print(\"Distance vs Upgrade Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "for dist, row in dist_analysis.iterrows():\n",
    "    print(\n",
    "        f\"{dist:12s}: {row['Total_Customers']:3.0f} customers, \"\n",
    "        f\"{row['Upgrades']:3.0f} upgrades ({row['Upgrade_Rate'] * 100:5.1f}%)\"\n",
    "    )\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e73a5c97",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Create comprehensive distance vs upgrade visualizations\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(18, 14))\n",
    "\n",
    "# 1. Stacked Bar Chart showing absolute numbers\n",
    "dist_crosstab = pd.crosstab(train_data[\"dist_label\"], train_data[\"UPD\"])\n",
    "dist_crosstab = dist_crosstab.reindex(\n",
    "    [\"< 10 min\", \"10-20 min\", \"21-30 min\", \"> 30 min\"]\n",
    ")\n",
    "\n",
    "bars1 = ax1.bar(\n",
    "    dist_crosstab.index,\n",
    "    dist_crosstab[0],\n",
    "    color=upgrade_colors[0],\n",
    "    alpha=0.8,\n",
    "    label=\"No Upgrade\",\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=1,\n",
    ")\n",
    "bars2 = ax1.bar(\n",
    "    dist_crosstab.index,\n",
    "    dist_crosstab[1],\n",
    "    bottom=dist_crosstab[0],\n",
    "    color=upgrade_colors[1],\n",
    "    alpha=0.8,\n",
    "    label=\"Upgrade\",\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=1,\n",
    ")\n",
    "\n",
    "# Add value labels\n",
    "for i, (idx, row) in enumerate(dist_crosstab.iterrows()):\n",
    "    total = row.sum()\n",
    "    ax1.text(\n",
    "        i,\n",
    "        row[0] / 2,\n",
    "        f\"{row[0]}\",\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        fontweight=\"bold\",\n",
    "        color=\"white\",\n",
    "    )\n",
    "    ax1.text(\n",
    "        i,\n",
    "        row[0] + row[1] / 2,\n",
    "        f\"{row[1]}\",\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        fontweight=\"bold\",\n",
    "        color=\"white\",\n",
    "    )\n",
    "    ax1.text(\n",
    "        i,\n",
    "        total + 5,\n",
    "        f\"Total: {total}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "ax1.set_title(\n",
    "    \"Customer Distribution by Distance\\n(Absolute Numbers)\", fontweight=\"bold\", pad=20\n",
    ")\n",
    "ax1.set_ylabel(\"Number of Customers\", fontweight=\"bold\")\n",
    "ax1.legend(loc=\"upper right\", framealpha=0.9)\n",
    "ax1.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "# 2. Upgrade Rate by Distance (Percentage)\n",
    "upgrade_rates = dist_analysis[\"Upgrade_Rate\"] * 100\n",
    "colors_gradient = [\"#FF6B6B\", \"#4ECDC4\", \"#45B7D1\", \"#96CEB4\"]\n",
    "\n",
    "bars = ax2.bar(\n",
    "    upgrade_rates.index,\n",
    "    upgrade_rates.values,\n",
    "    color=colors_gradient,\n",
    "    alpha=0.8,\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=2,\n",
    ")\n",
    "\n",
    "# Add percentage labels on bars\n",
    "for bar, rate in zip(bars, upgrade_rates.values):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 1,\n",
    "        f\"{rate:.1f}%\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=12,\n",
    "    )\n",
    "\n",
    "ax2.set_title(\n",
    "    \"Upgrade Rate by Distance from Zoo\\n(Percentage)\", fontweight=\"bold\", pad=20\n",
    ")\n",
    "ax2.set_ylabel(\"Upgrade Rate (%)\", fontweight=\"bold\")\n",
    "ax2.set_ylim(0, max(upgrade_rates.values) * 1.2)\n",
    "ax2.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "# Add average line\n",
    "avg_rate = train_data[\"UPD\"].mean() * 100\n",
    "ax2.axhline(y=avg_rate, color=\"red\", linestyle=\"--\", alpha=0.7, linewidth=2)\n",
    "ax2.text(\n",
    "    0.02,\n",
    "    avg_rate + 1,\n",
    "    f\"Overall Average: {avg_rate:.1f}%\",\n",
    "    transform=ax2.get_yaxis_transform(),\n",
    "    fontsize=10,\n",
    "    color=\"red\",\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "\n",
    "# 3. Grouped Bar Chart for detailed comparison\n",
    "x = np.arange(len(dist_analysis.index))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax3.bar(\n",
    "    x - width / 2,\n",
    "    dist_analysis[\"Total_Customers\"],\n",
    "    width,\n",
    "    label=\"Total Customers\",\n",
    "    color=\"#3498DB\",\n",
    "    alpha=0.8,\n",
    "    edgecolor=\"white\",\n",
    ")\n",
    "bars2 = ax3.bar(\n",
    "    x + width / 2,\n",
    "    dist_analysis[\"Upgrades\"],\n",
    "    width,\n",
    "    label=\"Upgrades\",\n",
    "    color=\"#2ECC71\",\n",
    "    alpha=0.8,\n",
    "    edgecolor=\"white\",\n",
    ")\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar1, bar2) in enumerate(zip(bars1, bars2)):\n",
    "    ax3.text(\n",
    "        bar1.get_x() + bar1.get_width() / 2.0,\n",
    "        bar1.get_height() + 2,\n",
    "        f\"{int(bar1.get_height())}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "    ax3.text(\n",
    "        bar2.get_x() + bar2.get_width() / 2.0,\n",
    "        bar2.get_height() + 2,\n",
    "        f\"{int(bar2.get_height())}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "ax3.set_title(\n",
    "    \"Customer Count vs Upgrades by Distance\\n(Side-by-side Comparison)\",\n",
    "    fontweight=\"bold\",\n",
    "    pad=20,\n",
    ")\n",
    "ax3.set_ylabel(\"Number of Customers\", fontweight=\"bold\")\n",
    "ax3.set_xticks(x)\n",
    "ax3.set_xticklabels(dist_analysis.index, rotation=45)\n",
    "ax3.legend(framealpha=0.9)\n",
    "ax3.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "# 4. Heatmap showing upgrade patterns\n",
    "pivot_data = train_data.groupby([\"dist_label\", \"UPD\"]).size().unstack(fill_value=0)\n",
    "pivot_data = pivot_data.reindex([\"< 10 min\", \"10-20 min\", \"21-30 min\", \"> 30 min\"])\n",
    "pivot_pct = pivot_data.div(pivot_data.sum(axis=1), axis=0) * 100\n",
    "\n",
    "sns.heatmap(\n",
    "    pivot_pct,\n",
    "    annot=True,\n",
    "    fmt=\".1f\",\n",
    "    cmap=\"RdYlGn\",\n",
    "    center=50,\n",
    "    ax=ax4,\n",
    "    cbar_kws={\"label\": \"Percentage\"},\n",
    ")\n",
    "ax4.set_title(\n",
    "    \"Upgrade Behavior Heatmap\\n(Percentage Distribution)\", fontweight=\"bold\", pad=20\n",
    ")\n",
    "ax4.set_xlabel(\"Upgrade Decision\", fontweight=\"bold\")\n",
    "ax4.set_ylabel(\"Distance from Zoo\", fontweight=\"bold\")\n",
    "ax4.set_xticklabels([\"No Upgrade\", \"Upgrade\"], rotation=0)\n",
    "ax4.set_yticklabels(ax4.get_yticklabels(), rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graphs/02_distance_analysis.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1cea814",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "KEY INSIGHTS FROM DISTANCE ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "📍 DISTANCE IMPACT ON UPGRADES:\n",
      "   • Highest upgrade rate: < 10 min (73.0%)\n",
      "   • Lowest upgrade rate:  > 30 min (44.6%)\n",
      "   • Difference: 28.4 percentage points\n",
      "\n",
      "📊 STATISTICAL SIGNIFICANCE:\n",
      "   • Chi-square statistic: 10.767\n",
      "   • P-value: 0.0131\n",
      "   • Significance: Significant at α=0.05\n",
      "\n",
      "💡 BUSINESS IMPLICATIONS:\n",
      "   • Customers living < 10 min show higher upgrade propensity\n",
      "   • Consider targeted marketing for this distance segment\n",
      "   • Overall upgrade rate: 50.0%\n",
      "   • Distance-based segmentation may be valuable for strategy\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Generate insights summary for presentation\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"KEY INSIGHTS FROM DISTANCE ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Find the distance category with highest and lowest upgrade rates\n",
    "max_upgrade_dist = dist_analysis[\"Upgrade_Rate\"].idxmax()\n",
    "min_upgrade_dist = dist_analysis[\"Upgrade_Rate\"].idxmin()\n",
    "max_rate = dist_analysis.loc[max_upgrade_dist, \"Upgrade_Rate\"] * 100\n",
    "min_rate = dist_analysis.loc[min_upgrade_dist, \"Upgrade_Rate\"] * 100\n",
    "\n",
    "print(\"\\n📍 DISTANCE IMPACT ON UPGRADES:\")\n",
    "print(f\"   • Highest upgrade rate: {max_upgrade_dist} ({max_rate:.1f}%)\")\n",
    "print(f\"   • Lowest upgrade rate:  {min_upgrade_dist} ({min_rate:.1f}%)\")\n",
    "print(f\"   • Difference: {max_rate - min_rate:.1f} percentage points\")\n",
    "\n",
    "# Calculate statistical significance (Chi-square test)\n",
    "chi2, p_value, dof, expected = chi2_contingency(dist_crosstab)\n",
    "\n",
    "print(\"\\n📊 STATISTICAL SIGNIFICANCE:\")\n",
    "print(f\"   • Chi-square statistic: {chi2:.3f}\")\n",
    "print(f\"   • P-value: {p_value:.4f}\")\n",
    "print(\n",
    "    f\"   • Significance: {'Significant' if p_value < 0.05 else 'Not significant'} at α=0.05\"\n",
    ")\n",
    "\n",
    "# Business implications\n",
    "print(\"\\n💡 BUSINESS IMPLICATIONS:\")\n",
    "if max_rate > 50:\n",
    "    print(f\"   • Customers living {max_upgrade_dist} show higher upgrade propensity\")\n",
    "    print(\"   • Consider targeted marketing for this distance segment\")\n",
    "else:\n",
    "    print(\"   • Distance appears to negatively impact upgrade likelihood\")\n",
    "    print(\"   • Focus on improving value proposition for distant customers\")\n",
    "\n",
    "print(f\"   • Overall upgrade rate: {train_data['UPD'].mean() * 100:.1f}%\")\n",
    "print(\"   • Distance-based segmentation may be valuable for strategy\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04614239",
   "metadata": {},
   "source": [
    "#### Visit Frequency vs Upgrade Behavior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54dd8ad0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Visit Frequency vs Upgrade Analysis:\n",
      "=======================================================\n",
      "≤ 2 visits  : 161 customers,  69 upgrades ( 42.9%)\n",
      "3-4 visits  : 211 customers, 112 upgrades ( 53.1%)\n",
      "5-6 visits  : 163 customers,  76 upgrades ( 46.6%)\n",
      "7-8 visits  :  67 customers,  37 upgrades ( 55.2%)\n",
      "> 8 visits  : 138 customers,  76 upgrades ( 55.1%)\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "# Create visit frequency labels for better visualization\n",
    "visit_labels = {\n",
    "    1: \"≤ 2 visits\",\n",
    "    2: \"3-4 visits\",\n",
    "    3: \"5-6 visits\",\n",
    "    4: \"7-8 visits\",\n",
    "    5: \"> 8 visits\",\n",
    "}\n",
    "train_data[\"tvis_label\"] = train_data[\"tvis\"].map(visit_labels)\n",
    "\n",
    "# Calculate upgrade rates by visit frequency\n",
    "visit_analysis = (\n",
    "    train_data.groupby(\"tvis_label\").agg({\"UPD\": [\"count\", \"sum\", \"mean\"]}).round(3)\n",
    ")\n",
    "visit_analysis.columns = [\"Total_Customers\", \"Upgrades\", \"Upgrade_Rate\"]\n",
    "visit_analysis = visit_analysis.reindex(\n",
    "    [\"≤ 2 visits\", \"3-4 visits\", \"5-6 visits\", \"7-8 visits\", \"> 8 visits\"]\n",
    ")\n",
    "\n",
    "# Create a beautiful visualization for visit frequency vs upgrades\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# 1. Upgrade rate by visit frequency\n",
    "upgrade_rates_visits = visit_analysis[\"Upgrade_Rate\"] * 100\n",
    "colors_visits = [\"#FF6B6B\", \"#4ECDC4\", \"#45B7D1\", \"#96CEB4\", \"#FFA07A\"]\n",
    "\n",
    "bars = ax1.bar(\n",
    "    range(len(upgrade_rates_visits)),\n",
    "    upgrade_rates_visits.values,\n",
    "    color=colors_visits,\n",
    "    alpha=0.8,\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=2,\n",
    ")\n",
    "\n",
    "# Add percentage labels on bars\n",
    "for i, (bar, rate) in enumerate(zip(bars, upgrade_rates_visits.values)):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 1,\n",
    "        f\"{rate:.1f}%\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=11,\n",
    "    )\n",
    "\n",
    "ax1.set_title(\n",
    "    \"Upgrade Rate by Visit Frequency\\n(Higher engagement = Higher upgrades?)\",\n",
    "    fontweight=\"bold\",\n",
    "    pad=20,\n",
    ")\n",
    "ax1.set_ylabel(\"Upgrade Rate (%)\", fontweight=\"bold\")\n",
    "ax1.set_xticks(range(len(upgrade_rates_visits)))\n",
    "ax1.set_xticklabels(upgrade_rates_visits.index, rotation=45, ha=\"right\")\n",
    "ax1.set_ylim(0, max(upgrade_rates_visits.values) * 1.2)\n",
    "ax1.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "# Add average line\n",
    "avg_rate = train_data[\"UPD\"].mean() * 100\n",
    "ax1.axhline(y=avg_rate, color=\"red\", linestyle=\"--\", alpha=0.7, linewidth=2)\n",
    "ax1.text(\n",
    "    0.02,\n",
    "    avg_rate + 2,\n",
    "    f\"Overall Average: {avg_rate:.1f}%\",\n",
    "    transform=ax1.get_yaxis_transform(),\n",
    "    fontsize=10,\n",
    "    color=\"red\",\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "\n",
    "# 2. Customer distribution by visit frequency\n",
    "visit_counts = train_data[\"tvis_label\"].value_counts()\n",
    "visit_counts = visit_counts.reindex(\n",
    "    [\"≤ 2 visits\", \"3-4 visits\", \"5-6 visits\", \"7-8 visits\", \"> 8 visits\"]\n",
    ")\n",
    "\n",
    "bars = ax2.bar(\n",
    "    range(len(visit_counts)),\n",
    "    visit_counts.values,\n",
    "    color=colors_visits,\n",
    "    alpha=0.8,\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=2,\n",
    ")\n",
    "\n",
    "# Add count labels on bars\n",
    "for i, (bar, count) in enumerate(zip(bars, visit_counts.values)):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 3,\n",
    "        f\"{count}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=11,\n",
    "    )\n",
    "    # Add percentage of total\n",
    "    pct = count / len(train_data) * 100\n",
    "    ax2.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height / 2,\n",
    "        f\"{pct:.1f}%\",\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        fontweight=\"bold\",\n",
    "        color=\"white\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "ax2.set_title(\n",
    "    \"Customer Distribution by Visit Frequency\\n(Engagement Patterns)\",\n",
    "    fontweight=\"bold\",\n",
    "    pad=20,\n",
    ")\n",
    "ax2.set_ylabel(\"Number of Customers\", fontweight=\"bold\")\n",
    "ax2.set_xticks(range(len(visit_counts)))\n",
    "ax2.set_xticklabels(visit_counts.index, rotation=45, ha=\"right\")\n",
    "ax2.set_ylim(0, max(visit_counts.values) * 1.15)\n",
    "ax2.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graphs/03_visit_frequency_analysis.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nVisit Frequency vs Upgrade Analysis:\")\n",
    "print(\"=\" * 55)\n",
    "for visit, row in visit_analysis.iterrows():\n",
    "    print(\n",
    "        f\"{visit:12s}: {row['Total_Customers']:3.0f} customers, \"\n",
    "        f\"{row['Upgrades']:3.0f} upgrades ({row['Upgrade_Rate'] * 100:5.1f}%)\"\n",
    "    )\n",
    "print(\"=\" * 55)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560f8447",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing & Feature Engineering\n",
    "\n",
    "#### Rationale for Preprocessing Decisions\n",
    "\n",
    "**1. Feature Categorization Strategy**\n",
    "- **Categorical Non-linear Features** → One-Hot Encoding\n",
    "  - *Justification*: Variables like `gender`, `mstat`, `educ` have no inherent ordering\n",
    "  - *Business Impact*: Preserves interpretability of demographic segments\n",
    "  - *Statistical Benefit*: Prevents false ordinal assumptions in algorithms\n",
    "\n",
    "**2. Ordinal Linear Features** → Standardization Only  \n",
    "  - *Example*: `dist` (distance categories have clear progression)\n",
    "  - *Justification*: Preserves meaningful numerical relationships\n",
    "  - *Algorithm Benefit*: Maintains gradient information for optimization\n",
    "\n",
    "**3. Pre-standardized Features** → Pass-through\n",
    "  - *Rationale*: Perception variables (benefits, costs, value, etc.) already standardized\n",
    "  - *Efficiency*: Avoids unnecessary transformation and potential information loss\n",
    "  - *Interpretability*: Maintains original scale for business understanding\n",
    "\n",
    "**4. Numeric Features** → Standardization\n",
    "  - *Purpose*: Ensure equal algorithmic treatment regardless of scale\n",
    "  - *Critical for*: SVM, KNN, Logistic Regression (distance-based algorithms)\n",
    "  - *Business Value*: Enables meaningful coefficient interpretation\n",
    "\n",
    "#### Data Leakage Prevention\n",
    "- **Fit on Training Only**: All preprocessing parameters learned exclusively from training data\n",
    "- **Transform Test Separately**: Test data transformed using training-derived parameters\n",
    "- **Validation Strategy**: Proper train/validation split maintains data integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35a63724",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessing Setup\n",
      "==================================================\n",
      "Training data shape: (740, 22)\n",
      "Test data shape: (303, 20)\n",
      "Missing values in training: 0\n",
      "Missing values in test: 0\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Import preprocessing libraries\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Check current data shape and missing values\n",
    "print(\"Data Preprocessing Setup\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "print(f\"Missing values in training: {train_data.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in test: {test_data.isnull().sum().sum()}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a37ea88",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Categorization:\n",
      "==================================================\n",
      "Categorical (dummy encode): ['gender', 'mstat', 'educ', 'educnew', 'age_rec', 'tvis']\n",
      "Ordinal linear (normalize): ['dist']\n",
      "Already standardized: ['benefits', 'costs', 'value', 'identity', 'know', 'sat', 'fle', 'trustfor']\n",
      "Numeric (need scaling): ['age', 'size', 'child1']\n",
      "ID features (exclude): ['NID']\n",
      "Target variable: UPD\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Feature categorization based on business logic and statistical properties\n",
    "print(\"\\nFeature Categorization:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Features to exclude (ID variables)\n",
    "id_features = [\"NID\"]\n",
    "\n",
    "# Target variable\n",
    "target = \"UPD\"\n",
    "\n",
    "# Categorical features (non-linear relationship) - need dummy encoding\n",
    "categorical_nonlinear = [\n",
    "    \"gender\",  # 1=Male, 2=Female (nominal)\n",
    "    \"mstat\",  # 1=Married, 2=Single, 3=Divorced, 4=Widow (nominal)\n",
    "    \"educ\",  # 1=Some college, 2=College, 3=Graduate school (treated as nominal per user)\n",
    "    \"educnew\",  # Recoded education variable (nominal)\n",
    "    \"age_rec\",  # 1=18-34, 2=35-44, 3=45-54, 4=54+ (treated as nominal per user)\n",
    "    \"tvis\",  # 1=≤2, 2=3-4, 3=5-6, 4=7-8, 5=>8 visits (treated as nominal per user)\n",
    "]\n",
    "\n",
    "# Ordinal features with linear relationship - use numeric + normalize\n",
    "ordinal_linear = [\n",
    "    \"dist\",  # 1=<10min, 2=10-20min, 3=21-30min, 4=>30min (clear distance progression)\n",
    "]\n",
    "\n",
    "# Already standardized perception features (mean≈0, std≈1)\n",
    "standardized_features = [\n",
    "    \"benefits\",\n",
    "    \"costs\",\n",
    "    \"value\",\n",
    "    \"identity\",\n",
    "    \"know\",\n",
    "    \"sat\",\n",
    "    \"fle\",\n",
    "    \"trustfor\",\n",
    "]\n",
    "\n",
    "# Other numeric features that need scaling\n",
    "numeric_features = [\n",
    "    \"age\",  # Age in categories (1-5 scale)\n",
    "    \"size\",  # Household size (1-6)\n",
    "    \"child1\",  # Number of children/grandchildren (0-6)\n",
    "]\n",
    "\n",
    "print(f\"Categorical (dummy encode): {categorical_nonlinear}\")\n",
    "print(f\"Ordinal linear (normalize): {ordinal_linear}\")\n",
    "print(f\"Already standardized: {standardized_features}\")\n",
    "print(f\"Numeric (need scaling): {numeric_features}\")\n",
    "print(f\"ID features (exclude): {id_features}\")\n",
    "print(f\"Target variable: {target}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20bf2cbf",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building Preprocessing Pipeline:\n",
      "==================================================\n",
      "Pipeline Components:\n",
      "• OneHotEncoder: Categorical features → Binary dummy variables\n",
      "• StandardScaler: Ordinal/Numeric features → Mean=0, Std=1\n",
      "• PassThrough: Pre-standardized features → Unchanged\n",
      "• Remainder: ID features → Dropped\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive preprocessing pipeline\n",
    "print(\"\\nBuilding Preprocessing Pipeline:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create preprocessing steps for different feature types\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # One-hot encode categorical features (drop='first' to avoid multicollinearity)\n",
    "        (\n",
    "            \"categorical\",\n",
    "            OneHotEncoder(drop=\"first\", sparse_output=False),\n",
    "            categorical_nonlinear,\n",
    "        ),\n",
    "        # Standardize ordinal features with linear relationship\n",
    "        (\"ordinal\", StandardScaler(), ordinal_linear),\n",
    "        # Keep already standardized features as-is\n",
    "        (\"standardized\", \"passthrough\", standardized_features),\n",
    "        # Standardize other numeric features\n",
    "        (\"numeric\", StandardScaler(), numeric_features),\n",
    "    ],\n",
    "    remainder=\"drop\",  # Drop any remaining features (like NID)\n",
    ")\n",
    "\n",
    "print(\"Pipeline Components:\")\n",
    "print(\"• OneHotEncoder: Categorical features → Binary dummy variables\")\n",
    "print(\"• StandardScaler: Ordinal/Numeric features → Mean=0, Std=1\")\n",
    "print(\"• PassThrough: Pre-standardized features → Unchanged\")\n",
    "print(\"• Remainder: ID features → Dropped\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0e42e74",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing Data for Preprocessing:\n",
      "==================================================\n",
      "Training features shape: (740, 21)\n",
      "Training target shape: (740,)\n",
      "Test features shape: (303, 19)\n",
      "Test target shape: (303,)\n",
      "\n",
      "Original features (21):\n",
      "['NID', 'benefits', 'costs', 'value', 'identity', 'know', 'sat', 'fle', 'trustfor', 'age', 'gender', 'educ', 'mstat', 'size', 'child1', 'dist', 'tvis', 'age_rec', 'educnew', 'dist_label', 'tvis_label']\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for preprocessing\n",
    "print(\"\\nPreparing Data for Preprocessing:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Separate features and target for training data\n",
    "X_train_raw = train_data.drop(columns=[target])\n",
    "y_train = train_data[target]\n",
    "\n",
    "# Separate features for test data (test data has target too, but we'll use it for final evaluation)\n",
    "X_test_raw = test_data.drop(columns=[target])\n",
    "y_test = test_data[target]\n",
    "\n",
    "print(f\"Training features shape: {X_train_raw.shape}\")\n",
    "print(f\"Training target shape: {y_train.shape}\")\n",
    "print(f\"Test features shape: {X_test_raw.shape}\")\n",
    "print(f\"Test target shape: {y_test.shape}\")\n",
    "\n",
    "# Show feature names before preprocessing\n",
    "print(f\"\\nOriginal features ({len(X_train_raw.columns)}):\")\n",
    "print(list(X_train_raw.columns))\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ec2b61d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying Preprocessing Pipeline:\n",
      "==================================================\n",
      "Fitting preprocessor on training data...\n",
      "Transforming test data...\n",
      "Processed training shape: (740, 28)\n",
      "Processed test shape: (303, 28)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing pipeline\n",
    "print(\"\\nApplying Preprocessing Pipeline:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Fit preprocessor on training data only (prevents data leakage)\n",
    "print(\"Fitting preprocessor on training data...\")\n",
    "X_train_processed = preprocessor.fit_transform(X_train_raw)\n",
    "\n",
    "# Transform test data using fitted preprocessor\n",
    "print(\"Transforming test data...\")\n",
    "X_test_processed = preprocessor.transform(X_test_raw)\n",
    "\n",
    "print(f\"Processed training shape: {X_train_processed.shape}\")\n",
    "print(f\"Processed test shape: {X_test_processed.shape}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5732cf5f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Names After Preprocessing:\n",
      "==================================================\n",
      "Total features after preprocessing: 28\n",
      "Feature expansion: 21 → 28 features\n",
      "\n",
      "Feature breakdown:\n",
      "• Categorical (dummy): 16 features\n",
      "• Ordinal (scaled): 1 features\n",
      "• Standardized (passthrough): 8 features\n",
      "• Numeric (scaled): 3 features\n",
      "\n",
      "Sample categorical features (first 10):\n",
      "['gender_2', 'mstat_2', 'mstat_3', 'mstat_4', 'educ_2', 'educ_3', 'educ_4', 'educnew_1', 'educnew_2', 'age_rec_2']\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Get feature names after preprocessing\n",
    "print(\"\\nFeature Names After Preprocessing:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get feature names from the fitted preprocessor\n",
    "feature_names = []\n",
    "\n",
    "# Get names from each transformer\n",
    "categorical_names = list(\n",
    "    preprocessor.named_transformers_[\"categorical\"].get_feature_names_out(\n",
    "        categorical_nonlinear\n",
    "    )\n",
    ")\n",
    "ordinal_names = [f\"ordinal__{col}\" for col in ordinal_linear]\n",
    "standardized_names = [f\"standardized__{col}\" for col in standardized_features]\n",
    "numeric_names = [f\"numeric__{col}\" for col in numeric_features]\n",
    "\n",
    "# Combine all feature names\n",
    "feature_names = categorical_names + ordinal_names + standardized_names + numeric_names\n",
    "\n",
    "print(f\"Total features after preprocessing: {len(feature_names)}\")\n",
    "print(f\"Feature expansion: {X_train_raw.shape[1]} → {len(feature_names)} features\")\n",
    "print(\"\\nFeature breakdown:\")\n",
    "print(f\"• Categorical (dummy): {len(categorical_names)} features\")\n",
    "print(f\"• Ordinal (scaled): {len(ordinal_names)} features\")\n",
    "print(f\"• Standardized (passthrough): {len(standardized_names)} features\")\n",
    "print(f\"• Numeric (scaled): {len(numeric_names)} features\")\n",
    "\n",
    "# Show first few categorical feature names (dummy variables)\n",
    "print(\"\\nSample categorical features (first 10):\")\n",
    "print(categorical_names[:10])\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b07bafc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating Validation Split:\n",
      "==================================================\n",
      "Training split: (592, 28)\n",
      "Validation split: (148, 28)\n",
      "Training target distribution: [296 296]\n",
      "Validation target distribution: [74 74]\n",
      "Training upgrade rate: 0.500\n",
      "Validation upgrade rate: 0.500\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Create validation split from training data\n",
    "print(\"\\nCreating Validation Split:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Split training data into train/validation (80/20 split, stratified)\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train_processed, y_train, test_size=0.2, random_state=SEED, stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"Training split: {X_train_split.shape}\")\n",
    "print(f\"Validation split: {X_val_split.shape}\")\n",
    "print(f\"Training target distribution: {np.bincount(y_train_split)}\")\n",
    "print(f\"Validation target distribution: {np.bincount(y_val_split)}\")\n",
    "print(f\"Training upgrade rate: {y_train_split.mean():.3f}\")\n",
    "print(f\"Validation upgrade rate: {y_val_split.mean():.3f}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23803da4",
   "metadata": {},
   "source": [
    "### Feature Engineering & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6eb82235",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Engineering Setup:\n",
      "==================================================\n",
      "Training DataFrame shape: (740, 28)\n",
      "Validation DataFrame shape: (148, 28)\n",
      "Test DataFrame shape: (303, 28)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame for easier manipulation and feature engineering\n",
    "print(\"\\nFeature Engineering Setup:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Convert to DataFrame for easier feature engineering\n",
    "X_train_df = pd.DataFrame(X_train_processed, columns=feature_names)\n",
    "X_val_df = pd.DataFrame(X_val_split, columns=feature_names)\n",
    "X_test_df = pd.DataFrame(X_test_processed, columns=feature_names)\n",
    "\n",
    "print(f\"Training DataFrame shape: {X_train_df.shape}\")\n",
    "print(f\"Validation DataFrame shape: {X_val_df.shape}\")\n",
    "print(f\"Test DataFrame shape: {X_test_df.shape}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18873f4e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correlation Analysis:\n",
      "==================================================\n",
      "Found 2 highly correlated feature pairs (|r| > 0.8):\n",
      "  educ_3 ↔ educnew_1: 1.000\n",
      "  educ_4 ↔ educnew_2: 1.000\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Correlation analysis and feature relationships\n",
    "print(\"\\nCorrelation Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = X_train_df.corr()\n",
    "\n",
    "# Find highly correlated features (threshold = 0.8)\n",
    "high_corr_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i + 1, len(correlation_matrix.columns)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.8:\n",
    "            high_corr_pairs.append(\n",
    "                (\n",
    "                    correlation_matrix.columns[i],\n",
    "                    correlation_matrix.columns[j],\n",
    "                    correlation_matrix.iloc[i, j],\n",
    "                )\n",
    "            )\n",
    "\n",
    "print(f\"Found {len(high_corr_pairs)} highly correlated feature pairs (|r| > 0.8):\")\n",
    "for feat1, feat2, corr in high_corr_pairs[:10]:  # Show first 10\n",
    "    print(f\"  {feat1} ↔ {feat2}: {corr:.3f}\")\n",
    "\n",
    "if len(high_corr_pairs) > 10:\n",
    "    print(f\"  ... and {len(high_corr_pairs) - 10} more pairs\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e07e1537",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature-Target Correlations:\n",
      "==================================================\n",
      "Top 15 features most correlated with upgrade decision:\n",
      " 1. standardized__identity                  :  0.195\n",
      " 2. standardized__know                      :  0.172\n",
      " 3. standardized__fle                       :  0.134\n",
      " 4. standardized__benefits                  :  0.115\n",
      " 5. standardized__trustfor                  :  0.109\n",
      " 6. ordinal__dist                           : -0.104\n",
      " 7. standardized__value                     :  0.084\n",
      " 8. numeric__size                           : -0.077\n",
      " 9. educ_2                                  :  0.077\n",
      "10. age_rec_2                               : -0.058\n",
      "11. educ_4                                  : -0.058\n",
      "12. educnew_2                               : -0.058\n",
      "13. tvis_5                                  :  0.049\n",
      "14. mstat_3                                 :  0.043\n",
      "15. standardized__sat                       :  0.041\n",
      "\n",
      "Bottom 5 features least correlated with upgrade decision:\n",
      "24. educnew_1                               : -0.028\n",
      "25. standardized__costs                     :  0.026\n",
      "26. numeric__age                            :  0.019\n",
      "27. numeric__child1                         : -0.010\n",
      "28. age_rec_4                               :  0.010\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Feature correlation with target variable\n",
    "print(\"\\nFeature-Target Correlations:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calculate correlations with target\n",
    "target_correlations = []\n",
    "for feature in feature_names:\n",
    "    corr = np.corrcoef(X_train_df[feature], y_train)[0, 1]\n",
    "    target_correlations.append((feature, corr))\n",
    "\n",
    "# Sort by absolute correlation\n",
    "target_correlations.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "print(\"Top 15 features most correlated with upgrade decision:\")\n",
    "for i, (feature, corr) in enumerate(target_correlations[:15], 1):\n",
    "    print(f\"{i:2d}. {feature:<40}: {corr:6.3f}\")\n",
    "\n",
    "print(\"\\nBottom 5 features least correlated with upgrade decision:\")\n",
    "for i, (feature, corr) in enumerate(\n",
    "    target_correlations[-5:], len(target_correlations) - 4\n",
    "):\n",
    "    print(f\"{i:2d}. {feature:<40}: {corr:6.3f}\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cfd882",
   "metadata": {},
   "source": [
    "## 4. Machine Learning Model Development & Selection\n",
    "\n",
    "#### Algorithm Selection Rationale\n",
    "\n",
    "**1. Logistic Regression**\n",
    "- *Business Value*: Direct coefficient interpretation for feature impact quantification\n",
    "- *Statistical Strength*: Significance testing, confidence intervals, odds ratios\n",
    "- *Management Appeal*: \"Change in X leads to Y% change in upgrade probability\"\n",
    "- *Regularization*: L2 penalty prevents overfitting with multicollinear features\n",
    "\n",
    "**2. Support Vector Machine (SVM)**  \n",
    "- *Robustness*: Excellent performance with outliers and high-dimensional data\n",
    "- *Flexibility*: RBF kernel captures complex non-linear relationships\n",
    "- *Theoretical Foundation*: Maximum margin principle provides statistical guarantees\n",
    "- *Business Application*: Identifies subtle customer behavior patterns\n",
    "\n",
    "**3. Naive Bayes**\n",
    "- *Probabilistic Output*: Natural upgrade probability estimates for business decisions\n",
    "- *Speed & Efficiency*: Fast predictions for real-time customer scoring\n",
    "- *Baseline Performance*: Strong performance despite simplifying assumptions\n",
    "- *Interpretability*: Clear conditional probability relationships\n",
    "\n",
    "**4. Random Forest**\n",
    "- *Feature Importance*: Natural ranking of predictive variables for strategy focus\n",
    "- *Interaction Handling*: Captures complex feature combinations automatically\n",
    "- *Robustness*: Ensemble approach reduces overfitting risk\n",
    "- *Business Insights*: Non-linear threshold effects and segment-specific patterns\n",
    "\n",
    "**5. Gradient Boosting Machine**\n",
    "- *Predictive Power*: Often achieves highest accuracy in classification tasks\n",
    "- *Feature Importance*: Sophisticated importance metrics considering interactions\n",
    "- *Pattern Recognition*: Identifies subtle sequential relationships in customer data\n",
    "- *Competitive Advantage*: State-of-the-art performance for strategic applications\n",
    "\n",
    "**6. K-Nearest Neighbors**\n",
    "- *Local Patterns*: Captures neighborhood effects in customer behavior\n",
    "- *Non-parametric*: No distributional assumptions about data\n",
    "- *Similarity-based*: Intuitive \"customers like this one\" reasoning\n",
    "- *Segmentation*: Natural customer clustering for targeted strategies\n",
    "\n",
    "### Model Evaluation Framework\n",
    "\n",
    "#### Primary Metrics Strategy\n",
    "- **ROC-AUC**: Primary metric (handles class balance, threshold-independent)\n",
    "- **Precision**: Critical for marketing efficiency (avoid false positives)\n",
    "- **Recall**: Important for customer retention (capture actual upgraders)  \n",
    "- **F1-Score**: Balanced metric for overall classification quality\n",
    "\n",
    "#### Robustness Testing Protocol\n",
    "- **5-Fold Stratified Cross-Validation**: Maintains target balance across folds\n",
    "- **Statistical Significance**: Confidence intervals for performance differences\n",
    "- **Stability Analysis**: Performance consistency across different data subsets\n",
    "- **Training Time**: Computational efficiency for operational deployment\n",
    "\n",
    "### Model Selection Criteria\n",
    "We prioritize the algorithm that best balances:\n",
    "1. **Predictive Accuracy**: Reliable upgrade probability estimates\n",
    "2. **Business Interpretability**: Clear insights for management decisions  \n",
    "3. **Operational Robustness**: Consistent performance across customer segments\n",
    "4. **Implementation Feasibility**: Practical deployment considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "736396a6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning Model Setup\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Import machine learning libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "import time\n",
    "\n",
    "print(\"Machine Learning Model Setup\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "368d3665",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing Models:\n",
      "==================================================\n",
      "✓ Logistic Regression: LogisticRegression\n",
      "✓ SVM: SVC\n",
      "✓ Naive Bayes: GaussianNB\n",
      "✓ Random Forest: RandomForestClassifier\n",
      "✓ Gradient Boosting: GradientBoostingClassifier\n",
      "✓ K-Nearest Neighbors: KNeighborsClassifier\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Define models with initial parameters\n",
    "print(\"\\nInitializing Models:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        random_state=SEED, max_iter=1000, penalty=\"l2\"\n",
    "    ),\n",
    "    \"SVM\": SVC(\n",
    "        random_state=SEED,\n",
    "        probability=True,  # Enable probability estimates for ROC-AUC\n",
    "        kernel=\"rbf\",\n",
    "    ),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=SEED, n_estimators=500),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(\n",
    "        random_state=SEED, n_estimators=500\n",
    "    ),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5, weights=\"distance\"),\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"✓ {name}: {type(model).__name__}\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55f3587b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Evaluation:\n",
      "==================================================\n",
      "Performing 5-fold cross-validation for each model...\n",
      "\n",
      "Model Performance (CV Mean ± Std):\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Training Logistic Regression...\n",
      "Logistic Regression : 0.6101 ± 0.0670 (Time: 1.33s)\n",
      "\n",
      "Training SVM...\n",
      "SVM                 : 0.6004 ± 0.0801 (Time: 1.02s)\n",
      "\n",
      "Training Naive Bayes...\n",
      "Naive Bayes         : 0.5894 ± 0.0575 (Time: 0.83s)\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest       : 0.5857 ± 0.0471 (Time: 1.29s)\n",
      "\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting   : 0.5498 ± 0.0408 (Time: 0.42s)\n",
      "\n",
      "Training K-Nearest Neighbors...\n",
      "K-Nearest Neighbors : 0.5147 ± 0.0411 (Time: 0.03s)\n",
      "----------------------------------------------------------------------\n",
      "Metric: ROC-AUC (Higher is better)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation evaluation\n",
    "print(\"\\nCross-Validation Evaluation:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Setup stratified k-fold cross-validation\n",
    "cv_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Store results\n",
    "cv_results = {}\n",
    "training_times = {}\n",
    "\n",
    "print(\"Performing 5-fold cross-validation for each model...\")\n",
    "print(\"\\nModel Performance (CV Mean ± Std):\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "\n",
    "    # Time the training\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(\n",
    "        model, X_train_split, y_train_split, cv=cv_folds, scoring=\"roc_auc\", n_jobs=-1\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    # Store results\n",
    "    cv_results[name] = cv_scores\n",
    "    training_times[name] = training_time\n",
    "\n",
    "    # Print results\n",
    "    mean_score = cv_scores.mean()\n",
    "    std_score = cv_scores.std()\n",
    "    print(\n",
    "        f\"{name:<20}: {mean_score:.4f} ± {std_score:.4f} (Time: {training_time:.2f}s)\"\n",
    "    )\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(\"Metric: ROC-AUC (Higher is better)\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77eba3e2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Set Evaluation:\n",
      "==================================================\n",
      "Training models on full training split and evaluating on validation set...\n",
      "\n",
      "Validation Performance:\n",
      "--------------------------------------------------------------------------------\n",
      "Model                ROC-AUC  Accuracy Precision  Recall   F1-Score\n",
      "--------------------------------------------------------------------------------\n",
      "Logistic Regression  0.5860   0.6081   0.5976     0.6622   0.6282  \n",
      "SVM                  0.5646   0.5878   0.5844     0.6081   0.5960  \n",
      "Naive Bayes          0.5705   0.5743   0.5679     0.6216   0.5935  \n",
      "Random Forest        0.5908   0.5878   0.5867     0.5946   0.5906  \n",
      "Gradient Boosting    0.5279   0.5270   0.5250     0.5676   0.5455  \n",
      "K-Nearest Neighbors  0.4978   0.5338   0.5309     0.5811   0.5548  \n",
      "--------------------------------------------------------------------------------\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Train models on full training split and evaluate on validation\n",
    "print(\"\\nValidation Set Evaluation:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Store validation results\n",
    "val_results = {}\n",
    "trained_models = {}\n",
    "\n",
    "print(\"Training models on full training split and evaluating on validation set...\")\n",
    "print(\"\\nValidation Performance:\")\n",
    "print(\"-\" * 80)\n",
    "print(\n",
    "    f\"{'Model':<20} {'ROC-AUC':<8} {'Accuracy':<8} {'Precision':<10} {'Recall':<8} {'F1-Score':<8}\"\n",
    ")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train model on training split\n",
    "    model.fit(X_train_split, y_train_split)\n",
    "    trained_models[name] = model\n",
    "\n",
    "    # Predict on validation set\n",
    "    val_pred = model.predict(X_val_split)\n",
    "    val_pred_proba = model.predict_proba(X_val_split)[:, 1]\n",
    "\n",
    "    # Calculate metrics\n",
    "    val_auc = roc_auc_score(y_val_split, val_pred_proba)\n",
    "    val_accuracy = (val_pred == y_val_split).mean()\n",
    "\n",
    "    # Get precision, recall, f1 from classification report\n",
    "    report = classification_report(y_val_split, val_pred, output_dict=True)\n",
    "    val_precision = report[\"1\"][\"precision\"]\n",
    "    val_recall = report[\"1\"][\"recall\"]\n",
    "    val_f1 = report[\"1\"][\"f1-score\"]\n",
    "\n",
    "    # Store results\n",
    "    val_results[name] = {\n",
    "        \"auc\": val_auc,\n",
    "        \"accuracy\": val_accuracy,\n",
    "        \"precision\": val_precision,\n",
    "        \"recall\": val_recall,\n",
    "        \"f1\": val_f1,\n",
    "        \"predictions\": val_pred,\n",
    "        \"probabilities\": val_pred_proba,\n",
    "    }\n",
    "\n",
    "    # Print results\n",
    "    print(\n",
    "        f\"{name:<20} {val_auc:<8.4f} {val_accuracy:<8.4f} {val_precision:<10.4f} {val_recall:<8.4f} {val_f1:<8.4f}\"\n",
    "    )\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16a9d17f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Ranking and Selection:\n",
      "==================================================\n",
      "Model Performance Ranking (by ROC-AUC):\n",
      "------------------------------------------------------------\n",
      "Rank  Model                ROC-AUC    CV Score     Robustness\n",
      "------------------------------------------------------------\n",
      "1     Random Forest        0.5908     0.5857±0.047 Medium\n",
      "2     Logistic Regression  0.5860     0.6101±0.067 Low\n",
      "3     Naive Bayes          0.5705     0.5894±0.057 Low\n",
      "4     SVM                  0.5646     0.6004±0.080 Low\n",
      "5     Gradient Boosting    0.5279     0.5498±0.041 Medium\n",
      "6     K-Nearest Neighbors  0.4978     0.5147±0.041 Medium\n",
      "------------------------------------------------------------\n",
      "\n",
      "🏆 BEST MODEL: Random Forest\n",
      "   • ROC-AUC: 0.5908\n",
      "   • Accuracy: 0.5878\n",
      "   • F1-Score: 0.5906\n",
      "   • Cross-validation: 0.5857 ± 0.047\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Model ranking and selection\n",
    "print(\"\\nModel Ranking and Selection:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Rank models by ROC-AUC on validation set\n",
    "model_ranking = sorted(val_results.items(), key=lambda x: x[1][\"auc\"], reverse=True)\n",
    "\n",
    "print(\"Model Performance Ranking (by ROC-AUC):\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Rank':<5} {'Model':<20} {'ROC-AUC':<10} {'CV Score':<12} {'Robustness'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for i, (name, results) in enumerate(model_ranking, 1):\n",
    "    cv_mean = cv_results[name].mean()\n",
    "    cv_std = cv_results[name].std()\n",
    "    robustness = \"High\" if cv_std < 0.02 else \"Medium\" if cv_std < 0.05 else \"Low\"\n",
    "\n",
    "    print(\n",
    "        f\"{i:<5} {name:<20} {results['auc']:<10.4f} {cv_mean:.4f}±{cv_std:.3f} {robustness}\"\n",
    "    )\n",
    "\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Select best model\n",
    "best_model_name = model_ranking[0][0]\n",
    "best_model = trained_models[best_model_name]\n",
    "best_results = val_results[best_model_name]\n",
    "\n",
    "print(f\"\\n🏆 BEST MODEL: {best_model_name}\")\n",
    "print(f\"   • ROC-AUC: {best_results['auc']:.4f}\")\n",
    "print(f\"   • Accuracy: {best_results['accuracy']:.4f}\")\n",
    "print(f\"   • F1-Score: {best_results['f1']:.4f}\")\n",
    "print(\n",
    "    f\"   • Cross-validation: {cv_results[best_model_name].mean():.4f} ± {cv_results[best_model_name].std():.3f}\"\n",
    ")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977d0039",
   "metadata": {},
   "source": [
    "### Feature Importance Analysis & Business Interpretation\n",
    "#### Strategic Approach to Model Interpretability\n",
    "\n",
    "Our interpretation strategy employs **multiple complementary methods** to extract maximum business value from model insights:\n",
    "\n",
    "**1. Model-Specific Importance Methods**\n",
    "- **Logistic Regression**: Coefficient magnitudes indicate feature impact on log-odds\n",
    "  - *Business Translation*: Direct probability change calculations\n",
    "  - *Statistical Validity*: Built-in significance testing available\n",
    "  - *Actionability*: Clear direction and magnitude of effects\n",
    "\n",
    "- **Tree-Based Models** (Random Forest, Gradient Boosting): Gini/Entropy importance\n",
    "  - *Advantage*: Captures feature interactions naturally\n",
    "  - *Business Value*: Identifies key decision points in customer behavior\n",
    "  - *Limitation*: Biased toward high-cardinality features\n",
    "\n",
    "**2. Model-Agnostic Importance** (Permutation Importance)\n",
    "- **Universal Application**: Works with any algorithm (SVM, KNN, Naive Bayes)\n",
    "- **Unbiased Measurement**: True predictive contribution regardless of feature type\n",
    "- **Business Insight**: \"What happens to accuracy if we ignore this feature?\"\n",
    "- **Strategic Planning**: Identifies which customer data to prioritize collecting\n",
    "\n",
    "#### Business Impact Translation Framework\n",
    "For each important feature, we provide:\n",
    "- **Predictive Power**: Quantitative impact on upgrade probability\n",
    "- **Operational Control**: Management's ability to influence this variable\n",
    "- **Implementation Cost**: Resources required to act on insights  \n",
    "- **Strategic Priority**: Alignment with business objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73d51f02",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importance Analysis:\n",
      "==================================================\n",
      "\n",
      "Top 15 Most Important Features (Random Forest):\n",
      "----------------------------------------------------------------------\n",
      "Feature                                  Importance     \n",
      "----------------------------------------------------------------------\n",
      " 1. standardized__trustfor                0.1069\n",
      " 2. standardized__identity                0.1033\n",
      " 3. standardized__benefits                0.1027\n",
      " 4. standardized__costs                   0.0968\n",
      " 5. standardized__know                    0.0651\n",
      " 6. numeric__child1                       0.0532\n",
      " 7. ordinal__dist                         0.0516\n",
      " 8. standardized__value                   0.0506\n",
      " 9. numeric__size                         0.0481\n",
      "10. standardized__fle                     0.0459\n",
      "11. standardized__sat                     0.0393\n",
      "12. numeric__age                          0.0317\n",
      "13. gender_2                              0.0209\n",
      "14. tvis_2                                0.0171\n",
      "15. tvis_3                                0.0169\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Feature importance analysis for interpretable models\n",
    "print(\"\\nFeature Importance Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Extract feature importance from different models\n",
    "importance_results = {}\n",
    "\n",
    "# 1. Logistic Regression - Coefficients\n",
    "if \"Logistic Regression\" in trained_models:\n",
    "    lr_model = trained_models[\"Logistic Regression\"]\n",
    "    lr_coef = lr_model.coef_[0]\n",
    "    importance_results[\"Logistic Regression\"] = list(zip(feature_names, lr_coef))\n",
    "\n",
    "# 2. Random Forest - Feature Importance\n",
    "if \"Random Forest\" in trained_models:\n",
    "    rf_model = trained_models[\"Random Forest\"]\n",
    "    rf_importance = rf_model.feature_importances_\n",
    "    importance_results[\"Random Forest\"] = list(zip(feature_names, rf_importance))\n",
    "\n",
    "# 3. Gradient Boosting - Feature Importance\n",
    "if \"Gradient Boosting\" in trained_models:\n",
    "    gb_model = trained_models[\"Gradient Boosting\"]\n",
    "    gb_importance = gb_model.feature_importances_\n",
    "    importance_results[\"Gradient Boosting\"] = list(zip(feature_names, gb_importance))\n",
    "\n",
    "# 4. For models without inherent feature importance (KNN, SVM, Naive Bayes)\n",
    "# Use permutation importance as a model-agnostic approach\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "non_interpretable_models = [\"K-Nearest Neighbors\", \"SVM\", \"Naive Bayes\"]\n",
    "for model_name in non_interpretable_models:\n",
    "    if model_name in trained_models:\n",
    "        model = trained_models[model_name]\n",
    "        # Calculate permutation importance on validation set (faster than full training set)\n",
    "        perm_importance = permutation_importance(\n",
    "            model, X_val_split, y_val_split, n_repeats=5, random_state=SEED, n_jobs=-1\n",
    "        )\n",
    "        importance_results[model_name] = list(\n",
    "            zip(feature_names, perm_importance.importances_mean)\n",
    "        )\n",
    "\n",
    "# Display feature importance for best model\n",
    "if best_model_name in importance_results:\n",
    "    print(f\"\\nTop 15 Most Important Features ({best_model_name}):\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    best_importance = importance_results[best_model_name]\n",
    "    if best_model_name == \"Logistic Regression\":\n",
    "        # Sort by absolute coefficient value\n",
    "        best_importance.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "        print(f\"{'Feature':<40} {'Coefficient':<15} {'Abs Value':<10}\")\n",
    "        print(\"-\" * 70)\n",
    "        for i, (feature, coef) in enumerate(best_importance[:15], 1):\n",
    "            print(f\"{i:2d}. {feature:<35} {coef:8.4f} {abs(coef):8.4f}\")\n",
    "    elif best_model_name in non_interpretable_models:\n",
    "        # Sort by permutation importance value\n",
    "        best_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "        print(f\"{'Feature':<40} {'Perm Importance':<15}\")\n",
    "        print(\"-\" * 70)\n",
    "        for i, (feature, importance) in enumerate(best_importance[:15], 1):\n",
    "            print(f\"{i:2d}. {feature:<35} {importance:8.4f}\")\n",
    "    else:\n",
    "        # Sort by feature importance value (tree-based models)\n",
    "        best_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "        print(f\"{'Feature':<40} {'Importance':<15}\")\n",
    "        print(\"-\" * 70)\n",
    "        for i, (feature, importance) in enumerate(best_importance[:15], 1):\n",
    "            print(f\"{i:2d}. {feature:<35} {importance:8.4f}\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0533761",
   "metadata": {},
   "source": [
    "## 5. Model Performance Visualization & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f01b8d89",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating Model Comparison Visualizations:\n",
      "==================================================\n",
      "✓ Model comparison plots saved to: graphs/04_model_comparison.png\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive model comparison and prediction visualizations\n",
    "print(\"\\nCreating Model Comparison Visualizations:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create a large figure with multiple subplots for model comparison\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "\n",
    "# 1. Model Performance Comparison (ROC-AUC with CV confidence)\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "model_names = list(cv_results.keys())\n",
    "cv_means = [cv_results[name].mean() for name in model_names]\n",
    "cv_stds = [cv_results[name].std() for name in model_names]\n",
    "val_aucs = [val_results[name][\"auc\"] for name in model_names]\n",
    "\n",
    "x_pos = np.arange(len(model_names))\n",
    "width = 0.35\n",
    "\n",
    "# CV scores with error bars\n",
    "bars1 = ax1.bar(\n",
    "    x_pos - width / 2,\n",
    "    cv_means,\n",
    "    width,\n",
    "    yerr=cv_stds,\n",
    "    color=colors[: len(model_names)],\n",
    "    alpha=0.8,\n",
    "    label=\"CV Mean ± Std\",\n",
    "    capsize=5,\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=1,\n",
    ")\n",
    "\n",
    "# Validation scores\n",
    "bars2 = ax1.bar(\n",
    "    x_pos + width / 2,\n",
    "    val_aucs,\n",
    "    width,\n",
    "    color=colors[: len(model_names)],\n",
    "    alpha=0.6,\n",
    "    label=\"Validation AUC\",\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=1,\n",
    ")\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar1, bar2, mean_val, val_auc) in enumerate(\n",
    "    zip(bars1, bars2, cv_means, val_aucs)\n",
    "):\n",
    "    ax1.text(\n",
    "        bar1.get_x() + bar1.get_width() / 2,\n",
    "        bar1.get_height() + cv_stds[i] + 0.01,\n",
    "        f\"{mean_val:.3f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=9,\n",
    "    )\n",
    "    ax1.text(\n",
    "        bar2.get_x() + bar2.get_width() / 2,\n",
    "        bar2.get_height() + 0.01,\n",
    "        f\"{val_auc:.3f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=9,\n",
    "    )\n",
    "\n",
    "ax1.set_title(\n",
    "    \"Model Performance Comparison\\n(ROC-AUC Scores)\", fontweight=\"bold\", pad=15\n",
    ")\n",
    "ax1.set_ylabel(\"ROC-AUC Score\", fontweight=\"bold\")\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels([name.replace(\" \", \"\\n\") for name in model_names], fontsize=10)\n",
    "ax1.legend(loc=\"lower right\", framealpha=0.9)\n",
    "ax1.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "ax1.set_ylim(0, 1.1)\n",
    "\n",
    "# 2. Model Robustness (CV Standard Deviation)\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "robustness_colors = [\n",
    "    \"#2ECC71\" if std < 0.02 else \"#F39C12\" if std < 0.05 else \"#E74C3C\"\n",
    "    for std in cv_stds\n",
    "]\n",
    "\n",
    "bars = ax2.bar(\n",
    "    x_pos, cv_stds, color=robustness_colors, alpha=0.8, edgecolor=\"white\", linewidth=2\n",
    ")\n",
    "\n",
    "# Add value labels\n",
    "for bar, std in zip(bars, cv_stds):\n",
    "    ax2.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height() + 0.001,\n",
    "        f\"{std:.3f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "ax2.set_title(\"Model Robustness\\n(Lower = More Robust)\", fontweight=\"bold\", pad=15)\n",
    "ax2.set_ylabel(\"Cross-Validation Std Dev\", fontweight=\"bold\")\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels([name.replace(\" \", \"\\n\") for name in model_names], fontsize=10)\n",
    "ax2.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "# Add robustness legend\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "legend_elements = [\n",
    "    Patch(facecolor=\"#2ECC71\", label=\"High (< 0.02)\"),\n",
    "    Patch(facecolor=\"#F39C12\", label=\"Medium (0.02-0.05)\"),\n",
    "    Patch(facecolor=\"#E74C3C\", label=\"Low (> 0.05)\"),\n",
    "]\n",
    "ax2.legend(\n",
    "    handles=legend_elements, title=\"Robustness\", loc=\"upper right\", framealpha=0.9\n",
    ")\n",
    "\n",
    "# 3. Training Time Comparison\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "training_time_values = [training_times[name] for name in model_names]\n",
    "time_colors = [\n",
    "    \"#3498DB\" if t < 1 else \"#F39C12\" if t < 10 else \"#E74C3C\"\n",
    "    for t in training_time_values\n",
    "]\n",
    "\n",
    "bars = ax3.bar(\n",
    "    x_pos,\n",
    "    training_time_values,\n",
    "    color=time_colors,\n",
    "    alpha=0.8,\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=2,\n",
    ")\n",
    "\n",
    "# Add value labels\n",
    "for bar, time_val in zip(bars, training_time_values):\n",
    "    ax3.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height() + max(training_time_values) * 0.02,\n",
    "        f\"{time_val:.1f}s\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "ax3.set_title(\n",
    "    \"Training Time Comparison\\n(5-Fold Cross-Validation)\", fontweight=\"bold\", pad=15\n",
    ")\n",
    "ax3.set_ylabel(\"Training Time (seconds)\", fontweight=\"bold\")\n",
    "ax3.set_xticks(x_pos)\n",
    "ax3.set_xticklabels([name.replace(\" \", \"\\n\") for name in model_names], fontsize=10)\n",
    "ax3.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "# 4. ROC Curves for All Models\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "for i, (name, results) in enumerate(val_results.items()):\n",
    "    y_pred_proba = results[\"probabilities\"]\n",
    "    fpr, tpr, _ = roc_curve(y_val_split, y_pred_proba)\n",
    "    auc = results[\"auc\"]\n",
    "\n",
    "    ax4.plot(\n",
    "        fpr,\n",
    "        tpr,\n",
    "        color=colors[i],\n",
    "        linewidth=2.5,\n",
    "        alpha=0.8,\n",
    "        label=f\"{name} (AUC = {auc:.3f})\",\n",
    "    )\n",
    "\n",
    "# Add diagonal line (random classifier)\n",
    "ax4.plot([0, 1], [0, 1], \"k--\", alpha=0.5, linewidth=1.5, label=\"Random Classifier\")\n",
    "\n",
    "ax4.set_title(\"ROC Curves Comparison\\n(Validation Set)\", fontweight=\"bold\", pad=15)\n",
    "ax4.set_xlabel(\"False Positive Rate\", fontweight=\"bold\")\n",
    "ax4.set_ylabel(\"True Positive Rate\", fontweight=\"bold\")\n",
    "ax4.legend(loc=\"lower right\", framealpha=0.9, fontsize=9)\n",
    "ax4.grid(alpha=0.3)\n",
    "ax4.set_xlim([0, 1])\n",
    "ax4.set_ylim([0, 1])\n",
    "\n",
    "# 5. Model Scores Heatmap\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "metrics = [\"ROC-AUC\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "scores_matrix = []\n",
    "for name in model_names:\n",
    "    results = val_results[name]\n",
    "    scores = [\n",
    "        results[\"auc\"],\n",
    "        results[\"accuracy\"],\n",
    "        results[\"precision\"],\n",
    "        results[\"recall\"],\n",
    "        results[\"f1\"],\n",
    "    ]\n",
    "    scores_matrix.append(scores)\n",
    "\n",
    "scores_df = pd.DataFrame(\n",
    "    scores_matrix,\n",
    "    index=[name.replace(\" \", \"\\n\") for name in model_names],\n",
    "    columns=metrics,\n",
    ")\n",
    "sns.heatmap(\n",
    "    scores_df,\n",
    "    annot=True,\n",
    "    fmt=\".3f\",\n",
    "    cmap=\"RdYlGn\",\n",
    "    center=0.5,\n",
    "    ax=ax5,\n",
    "    cbar_kws={\"label\": \"Score\"},\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    ")\n",
    "ax5.set_title(\n",
    "    \"Model Performance Heatmap\\n(Validation Metrics)\", fontweight=\"bold\", pad=15\n",
    ")\n",
    "ax5.set_xlabel(\"Metrics\", fontweight=\"bold\")\n",
    "ax5.set_ylabel(\"Models\", fontweight=\"bold\")\n",
    "\n",
    "# 6. Best Model Confusion Matrix\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "best_cm = confusion_matrix(y_val_split, val_results[best_model_name][\"predictions\"])\n",
    "best_cm_normalized = best_cm.astype(\"float\") / best_cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "sns.heatmap(\n",
    "    best_cm_normalized,\n",
    "    annot=True,\n",
    "    fmt=\".2%\",\n",
    "    cmap=\"Blues\",\n",
    "    ax=ax6,\n",
    "    cbar_kws={\"label\": \"Percentage\"},\n",
    ")\n",
    "ax6.set_title(\n",
    "    f\"Best Model Confusion Matrix\\n({best_model_name})\", fontweight=\"bold\", pad=15\n",
    ")\n",
    "ax6.set_xlabel(\"Predicted\", fontweight=\"bold\")\n",
    "ax6.set_ylabel(\"Actual\", fontweight=\"bold\")\n",
    "ax6.set_xticklabels([\"No Upgrade\", \"Upgrade\"])\n",
    "ax6.set_yticklabels([\"No Upgrade\", \"Upgrade\"])\n",
    "\n",
    "# Add count annotations\n",
    "for i in range(best_cm.shape[0]):\n",
    "    for j in range(best_cm.shape[1]):\n",
    "        ax6.text(\n",
    "            j + 0.5,\n",
    "            i + 0.7,\n",
    "            f\"n={best_cm[i, j]}\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            fontsize=9,\n",
    "            color=\"black\",\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graphs/04_model_comparison.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print(\"✓ Model comparison plots saved to: graphs/04_model_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04df42a9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating Best Model Analysis Visualizations:\n",
      "==================================================\n",
      "✓ Best model analysis plots saved to: graphs/05_best_model_analysis.png\n",
      "\n",
      "======================================================================\n",
      "VISUALIZATION INSIGHTS SUMMARY\n",
      "======================================================================\n",
      "\n",
      "📈 MODEL COMPARISON INSIGHTS:\n",
      "   • Best CV performance: Logistic Regression (0.6101)\n",
      "   • Most robust model: Gradient Boosting (std: 0.0408)\n",
      "   • Fastest training: K-Nearest Neighbors (0.03s)\n",
      "\n",
      "🎯 BEST MODEL (Random Forest) INSIGHTS:\n",
      "   • Validation AUC: 0.5908\n",
      "   • Average Precision: 0.5469\n",
      "   • Model calibration: Needs calibration\n",
      "   • Probability separation: Fair\n",
      "   • Top 3 predictive features:\n",
      "     1. trustfor\n",
      "     2. identity\n",
      "     3. benefits\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Best Model Detailed Analysis\n",
    "print(\"\\nCreating Best Model Analysis Visualizations:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create detailed visualizations for the best model\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(18, 14))\n",
    "\n",
    "# 1. Feature Importance for Best Model\n",
    "if best_model_name in importance_results:\n",
    "    best_importance = importance_results[best_model_name].copy()\n",
    "\n",
    "    if best_model_name == \"Logistic Regression\":\n",
    "        # Sort by absolute coefficient value\n",
    "        best_importance.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "        top_features = best_importance[:15]\n",
    "        feature_names_clean = [\n",
    "            feat.replace(\"standardized__\", \"\")\n",
    "            .replace(\"categorical__\", \"\")\n",
    "            .replace(\"numeric__\", \"\")\n",
    "            .replace(\"ordinal__\", \"\")\n",
    "            for feat, _ in top_features\n",
    "        ]\n",
    "        importance_values = [abs(val) for _, val in top_features]\n",
    "        title_suffix = \"(Absolute Coefficients)\"\n",
    "    elif best_model_name in non_interpretable_models:\n",
    "        # Sort by permutation importance value\n",
    "        best_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_features = best_importance[:15]\n",
    "        feature_names_clean = [\n",
    "            feat.replace(\"standardized__\", \"\")\n",
    "            .replace(\"categorical__\", \"\")\n",
    "            .replace(\"numeric__\", \"\")\n",
    "            .replace(\"ordinal__\", \"\")\n",
    "            for feat, _ in top_features\n",
    "        ]\n",
    "        importance_values = [val for _, val in top_features]\n",
    "        title_suffix = \"(Permutation Importance)\"\n",
    "    else:\n",
    "        # Sort by importance value (tree-based models)\n",
    "        best_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_features = best_importance[:15]\n",
    "        feature_names_clean = [\n",
    "            feat.replace(\"standardized__\", \"\")\n",
    "            .replace(\"categorical__\", \"\")\n",
    "            .replace(\"numeric__\", \"\")\n",
    "            .replace(\"ordinal__\", \"\")\n",
    "            for feat, _ in top_features\n",
    "        ]\n",
    "        importance_values = [val for _, val in top_features]\n",
    "        title_suffix = \"(Feature Importance)\"\n",
    "\n",
    "    # Create horizontal bar plot\n",
    "    colors_gradient = plt.cm.viridis(np.linspace(0, 1, len(importance_values)))\n",
    "    bars = ax1.barh(\n",
    "        range(len(importance_values)),\n",
    "        importance_values,\n",
    "        color=colors_gradient,\n",
    "        alpha=0.8,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1,\n",
    "    )\n",
    "\n",
    "    # Add value labels\n",
    "    for i, (bar, val) in enumerate(zip(bars, importance_values)):\n",
    "        ax1.text(\n",
    "            val + max(importance_values) * 0.01,\n",
    "            bar.get_y() + bar.get_height() / 2,\n",
    "            f\"{val:.3f}\",\n",
    "            va=\"center\",\n",
    "            fontweight=\"bold\",\n",
    "            fontsize=9,\n",
    "        )\n",
    "\n",
    "    ax1.set_title(\n",
    "        f\"Top 15 Most Important Features\\n{best_model_name} {title_suffix}\",\n",
    "        fontweight=\"bold\",\n",
    "        pad=15,\n",
    "    )\n",
    "    ax1.set_xlabel(\"Importance Score\", fontweight=\"bold\")\n",
    "    ax1.set_yticks(range(len(feature_names_clean)))\n",
    "    ax1.set_yticklabels(feature_names_clean, fontsize=10)\n",
    "    ax1.grid(axis=\"x\", alpha=0.3, linestyle=\"--\")\n",
    "    ax1.invert_yaxis()\n",
    "\n",
    "# 2. Prediction Probability Distribution\n",
    "best_proba = val_results[best_model_name][\"probabilities\"]\n",
    "upgrade_proba = best_proba[y_val_split == 1]\n",
    "no_upgrade_proba = best_proba[y_val_split == 0]\n",
    "\n",
    "ax2.hist(\n",
    "    no_upgrade_proba,\n",
    "    bins=30,\n",
    "    alpha=0.7,\n",
    "    color=upgrade_colors[0],\n",
    "    label=f\"No Upgrade (n={len(no_upgrade_proba)})\",\n",
    "    density=True,\n",
    "    edgecolor=\"white\",\n",
    ")\n",
    "ax2.hist(\n",
    "    upgrade_proba,\n",
    "    bins=30,\n",
    "    alpha=0.7,\n",
    "    color=upgrade_colors[1],\n",
    "    label=f\"Upgrade (n={len(upgrade_proba)})\",\n",
    "    density=True,\n",
    "    edgecolor=\"white\",\n",
    ")\n",
    "\n",
    "ax2.set_title(\n",
    "    f\"Prediction Probability Distribution\\n({best_model_name})\",\n",
    "    fontweight=\"bold\",\n",
    "    pad=15,\n",
    ")\n",
    "ax2.set_xlabel(\"Predicted Probability of Upgrade\", fontweight=\"bold\")\n",
    "ax2.set_ylabel(\"Density\", fontweight=\"bold\")\n",
    "ax2.legend(framealpha=0.9)\n",
    "ax2.grid(alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "# Add vertical line at decision threshold (0.5)\n",
    "ax2.axvline(x=0.5, color=\"red\", linestyle=\"--\", linewidth=2, alpha=0.8)\n",
    "ax2.text(\n",
    "    0.52, ax2.get_ylim()[1] * 0.9, \"Decision\\nThreshold\", color=\"red\", fontweight=\"bold\"\n",
    ")\n",
    "\n",
    "# 3. Precision-Recall Curve\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_val_split, best_proba)\n",
    "avg_precision = average_precision_score(y_val_split, best_proba)\n",
    "\n",
    "ax3.plot(\n",
    "    recall,\n",
    "    precision,\n",
    "    color=colors[0],\n",
    "    linewidth=3,\n",
    "    alpha=0.8,\n",
    "    label=f\"{best_model_name}\\n(AP = {avg_precision:.3f})\",\n",
    ")\n",
    "ax3.fill_between(recall, precision, alpha=0.2, color=colors[0])\n",
    "\n",
    "# Add baseline (random classifier)\n",
    "baseline = y_val_split.mean()\n",
    "ax3.axhline(\n",
    "    y=baseline,\n",
    "    color=\"gray\",\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.8,\n",
    "    linewidth=2,\n",
    "    label=f\"Random Classifier\\n(AP = {baseline:.3f})\",\n",
    ")\n",
    "\n",
    "ax3.set_title(\"Precision-Recall Curve\\n(Validation Set)\", fontweight=\"bold\", pad=15)\n",
    "ax3.set_xlabel(\"Recall (True Positive Rate)\", fontweight=\"bold\")\n",
    "ax3.set_ylabel(\"Precision (Positive Predictive Value)\", fontweight=\"bold\")\n",
    "ax3.legend(loc=\"lower left\", framealpha=0.9)\n",
    "ax3.grid(alpha=0.3)\n",
    "ax3.set_xlim([0, 1])\n",
    "ax3.set_ylim([0, 1])\n",
    "\n",
    "# 4. Model Calibration (Reliability Diagram)\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(\n",
    "    y_val_split, best_proba, n_bins=10\n",
    ")\n",
    "\n",
    "ax4.plot(\n",
    "    mean_predicted_value,\n",
    "    fraction_of_positives,\n",
    "    \"s-\",\n",
    "    color=colors[0],\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    "    alpha=0.8,\n",
    "    label=f\"{best_model_name}\",\n",
    ")\n",
    "ax4.plot([0, 1], [0, 1], \"k--\", alpha=0.8, linewidth=2, label=\"Perfectly Calibrated\")\n",
    "\n",
    "# Fill area between perfect calibration and actual\n",
    "ax4.fill_between(\n",
    "    mean_predicted_value,\n",
    "    fraction_of_positives,\n",
    "    mean_predicted_value,\n",
    "    alpha=0.3,\n",
    "    color=colors[0],\n",
    ")\n",
    "\n",
    "ax4.set_title(\"Model Calibration\\n(Reliability Diagram)\", fontweight=\"bold\", pad=15)\n",
    "ax4.set_xlabel(\"Mean Predicted Probability\", fontweight=\"bold\")\n",
    "ax4.set_ylabel(\"Fraction of Positives\", fontweight=\"bold\")\n",
    "ax4.legend(framealpha=0.9)\n",
    "ax4.grid(alpha=0.3)\n",
    "ax4.set_xlim([0, 1])\n",
    "ax4.set_ylim([0, 1])\n",
    "\n",
    "# Add calibration score annotation\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "brier_score = brier_score_loss(y_val_split, best_proba)\n",
    "ax4.text(\n",
    "    0.02,\n",
    "    0.98,\n",
    "    f\"Brier Score: {brier_score:.4f}\\n(Lower is Better)\",\n",
    "    transform=ax4.transAxes,\n",
    "    va=\"top\",\n",
    "    fontsize=10,\n",
    "    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8),\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graphs/05_best_model_analysis.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print(\"✓ Best model analysis plots saved to: graphs/05_best_model_analysis.png\")\n",
    "\n",
    "# Generate insights summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"VISUALIZATION INSIGHTS SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n📈 MODEL COMPARISON INSIGHTS:\")\n",
    "best_cv = max(cv_results.items(), key=lambda x: x[1].mean())\n",
    "most_robust = min(cv_results.items(), key=lambda x: x[1].std())\n",
    "fastest = min(training_times.items(), key=lambda x: x[1])\n",
    "\n",
    "print(f\"   • Best CV performance: {best_cv[0]} ({best_cv[1].mean():.4f})\")\n",
    "print(f\"   • Most robust model: {most_robust[0]} (std: {most_robust[1].std():.4f})\")\n",
    "print(f\"   • Fastest training: {fastest[0]} ({fastest[1]:.2f}s)\")\n",
    "\n",
    "print(f\"\\n🎯 BEST MODEL ({best_model_name}) INSIGHTS:\")\n",
    "print(f\"   • Validation AUC: {val_results[best_model_name]['auc']:.4f}\")\n",
    "print(f\"   • Average Precision: {avg_precision:.4f}\")\n",
    "print(\n",
    "    f\"   • Model calibration: {'Well calibrated' if brier_score < 0.25 else 'Needs calibration'}\"\n",
    ")\n",
    "print(\n",
    "    f\"   • Probability separation: {'Good' if abs(upgrade_proba.mean() - no_upgrade_proba.mean()) > 0.2 else 'Fair'}\"\n",
    ")\n",
    "\n",
    "if best_model_name in importance_results:\n",
    "    top_3_features = importance_results[best_model_name][:3]\n",
    "    if best_model_name == \"Logistic Regression\":\n",
    "        top_3_features.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "    else:\n",
    "        # For both permutation importance and tree-based importance, sort by value\n",
    "        top_3_features.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(f\"   • Top 3 predictive features:\")\n",
    "    for i, (feature, _) in enumerate(top_3_features[:3], 1):\n",
    "        clean_feature = (\n",
    "            feature.replace(\"standardized__\", \"\")\n",
    "            .replace(\"categorical__\", \"\")\n",
    "            .replace(\"numeric__\", \"\")\n",
    "            .replace(\"ordinal__\", \"\")\n",
    "        )\n",
    "        print(f\"     {i}. {clean_feature}\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77152083",
   "metadata": {},
   "source": [
    "## 6. Final Model Validation & Business Impact Assessment  \n",
    "\n",
    "#### Methodological Rigor\n",
    "**1. Proper Model Retraining**\n",
    "- *Process*: Retrain selected model on full training dataset (training + validation)\n",
    "- *Justification*: Maximizes available information while maintaining test set integrity\n",
    "- *Statistical Validity*: Prevents information leakage and optimistic bias\n",
    "- *Business Confidence*: Final performance represents true expected performance\n",
    "\n",
    "**2. Comprehensive Metric Evaluation**\n",
    "- *ROC-AUC*: Threshold-independent classification performance\n",
    "- *Precision*: Marketing campaign efficiency (percentage of predicted upgraders who actually upgrade)\n",
    "- *Recall*: Customer retention effectiveness (percentage of actual upgraders successfully identified)\n",
    "- *F1-Score*: Balanced performance measure for overall classification quality\n",
    "- *Accuracy*: Overall correctness for general business communication\n",
    "\n",
    "**3. Statistical Significance Assessment**\n",
    "- *Confusion Matrix Analysis*: Detailed breakdown of prediction accuracy by class\n",
    "- *Probability Distribution Analysis*: Model calibration and confidence assessment\n",
    "- *ROC Curve Analysis*: Complete performance profile across all decision thresholds\n",
    "\n",
    "#### Business Impact Translation Framework\n",
    "\n",
    "**Marketing Efficiency Metrics**\n",
    "- *Precision*: \"What percentage of customers we target will actually upgrade?\"\n",
    "- *Campaign ROI*: Cost-effectiveness of targeted marketing based on prediction accuracy\n",
    "- *Resource Optimization*: Optimal allocation of customer relationship management efforts\n",
    "\n",
    "**Customer Retention Insights**\n",
    "- *Recall*: \"What percentage of potential upgraders do we successfully identify?\"\n",
    "- *Revenue Protection*: Value of customers retained through targeted interventions\n",
    "- *Competitive Advantage*: Early identification of upgrade-ready customers\n",
    "\n",
    "**Strategic Planning Applications**\n",
    "- *Probability Segmentation*: Customer tiers based on upgrade likelihood\n",
    "- *Resource Prioritization*: Focus areas for maximum business impact\n",
    "- *Performance Monitoring*: Benchmarks for ongoing model performance assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d93840a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Set Evaluation:\n",
      "==================================================\n",
      "Retraining Random Forest on full training data...\n",
      "\n",
      "Final Model Performance on Test Set:\n",
      "--------------------------------------------------\n",
      "Model: Random Forest\n",
      "ROC-AUC:   0.5968\n",
      "Accuracy:  0.5743\n",
      "Precision: 0.5660\n",
      "Recall:    0.6000\n",
      "F1-Score:  0.5825\n",
      "\n",
      "Confusion Matrix:\n",
      "                 Predicted\n",
      "Actual    No Upgrade  Upgrade\n",
      "No Upgrade      84       69\n",
      "Upgrade         60       90\n",
      "--------------------------------------------------\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Final test set evaluation\n",
    "print(\"\\nFinal Test Set Evaluation:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Retrain best model on full training data (training + validation)\n",
    "print(f\"Retraining {best_model_name} on full training data...\")\n",
    "final_model = models[best_model_name]\n",
    "final_model.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "test_pred = final_model.predict(X_test_processed)\n",
    "test_pred_proba = final_model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "# Calculate test metrics\n",
    "test_auc = roc_auc_score(y_test, test_pred_proba)\n",
    "test_accuracy = (test_pred == y_test).mean()\n",
    "\n",
    "# Get detailed metrics\n",
    "test_report = classification_report(y_test, test_pred, output_dict=True)\n",
    "test_precision = test_report[\"1\"][\"precision\"]\n",
    "test_recall = test_report[\"1\"][\"recall\"]\n",
    "test_f1 = test_report[\"1\"][\"f1-score\"]\n",
    "\n",
    "print(\"\\nFinal Model Performance on Test Set:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Model: {best_model_name}\")\n",
    "print(f\"ROC-AUC:   {test_auc:.4f}\")\n",
    "print(f\"Accuracy:  {test_accuracy:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall:    {test_recall:.4f}\")\n",
    "print(f\"F1-Score:  {test_f1:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "test_cm = confusion_matrix(y_test, test_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(\"                 Predicted\")\n",
    "print(\"Actual    No Upgrade  Upgrade\")\n",
    "print(f\"No Upgrade    {test_cm[0, 0]:4d}     {test_cm[0, 1]:4d}\")\n",
    "print(f\"Upgrade       {test_cm[1, 0]:4d}     {test_cm[1, 1]:4d}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b7691af",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating Final Test Results Visualization:\n",
      "==================================================\n",
      "✓ Final test results plots saved to: graphs/06_final_test_results.png\n",
      "\n",
      "======================================================================\n",
      "FINAL TEST RESULTS SUMMARY\n",
      "======================================================================\n",
      "\n",
      "🏆 FINAL MODEL: Random Forest\n",
      "   • Test ROC-AUC: 0.5968\n",
      "   • Test Accuracy: 0.5743 (57.4%)\n",
      "   • Test Precision: 0.5660\n",
      "   • Test Recall: 0.6000\n",
      "   • Test F1-Score: 0.5825\n",
      "\n",
      "📊 PROBABILITY ANALYSIS:\n",
      "   • Mean probability for upgrades: 0.538\n",
      "   • Mean probability for no upgrades: 0.495\n",
      "   • Separation: 0.043\n",
      "\n",
      "🎯 CONFUSION MATRIX BREAKDOWN:\n",
      "   • True Negatives (Correct No-Upgrade): 84\n",
      "   • False Positives (Incorrect Upgrade): 69\n",
      "   • False Negatives (Missed Upgrade): 60\n",
      "   • True Positives (Correct Upgrade): 90\n",
      "\n",
      "💼 BUSINESS METRICS:\n",
      "   • Total test customers: 303\n",
      "   • Actual upgrades: 150 (49.5%)\n",
      "   • Predicted upgrades: 159\n",
      "   • Correctly identified upgrades: 90\n",
      "   • Marketing efficiency: 56.6% (precision)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Final Test Results Visualization\n",
    "print(\"\\nCreating Final Test Results Visualization:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create final test results visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Performance Metrics Comparison (Validation vs Test)\n",
    "metrics = [\"ROC-AUC\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "val_scores = [\n",
    "    val_results[best_model_name][\"auc\"],\n",
    "    val_results[best_model_name][\"accuracy\"],\n",
    "    val_results[best_model_name][\"precision\"],\n",
    "    val_results[best_model_name][\"recall\"],\n",
    "    val_results[best_model_name][\"f1\"],\n",
    "]\n",
    "test_scores = [test_auc, test_accuracy, test_precision, test_recall, test_f1]\n",
    "\n",
    "x_pos = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(\n",
    "    x_pos - width / 2,\n",
    "    val_scores,\n",
    "    width,\n",
    "    label=\"Validation\",\n",
    "    color=colors[0],\n",
    "    alpha=0.8,\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=1,\n",
    ")\n",
    "bars2 = ax1.bar(\n",
    "    x_pos + width / 2,\n",
    "    test_scores,\n",
    "    width,\n",
    "    label=\"Test\",\n",
    "    color=colors[1],\n",
    "    alpha=0.8,\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=1,\n",
    ")\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar1, bar2, val_score, test_score) in enumerate(\n",
    "    zip(bars1, bars2, val_scores, test_scores)\n",
    "):\n",
    "    ax1.text(\n",
    "        bar1.get_x() + bar1.get_width() / 2,\n",
    "        bar1.get_height() + 0.01,\n",
    "        f\"{val_score:.3f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=9,\n",
    "    )\n",
    "    ax1.text(\n",
    "        bar2.get_x() + bar2.get_width() / 2,\n",
    "        bar2.get_height() + 0.01,\n",
    "        f\"{test_score:.3f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=9,\n",
    "    )\n",
    "\n",
    "ax1.set_title(\n",
    "    f\"Final Model Performance\\n{best_model_name} (Validation vs Test)\",\n",
    "    fontweight=\"bold\",\n",
    "    pad=15,\n",
    ")\n",
    "ax1.set_ylabel(\"Score\", fontweight=\"bold\")\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(metrics, rotation=45, ha=\"right\")\n",
    "ax1.legend(framealpha=0.9)\n",
    "ax1.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "ax1.set_ylim(0, 1.1)\n",
    "\n",
    "# 2. Test Set Confusion Matrix (Enhanced)\n",
    "test_cm = confusion_matrix(y_test, test_pred)\n",
    "test_cm_normalized = test_cm.astype(\"float\") / test_cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Create custom colormap\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "colors_cm = [\"white\", colors[0]]\n",
    "cm_custom = LinearSegmentedColormap.from_list(\"custom\", colors_cm)\n",
    "\n",
    "sns.heatmap(\n",
    "    test_cm_normalized,\n",
    "    annot=True,\n",
    "    fmt=\".2%\",\n",
    "    cmap=cm_custom,\n",
    "    ax=ax2,\n",
    "    cbar_kws={\"label\": \"Percentage\"},\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    ")\n",
    "\n",
    "# Add count annotations\n",
    "for i in range(test_cm.shape[0]):\n",
    "    for j in range(test_cm.shape[1]):\n",
    "        ax2.text(\n",
    "            j + 0.5,\n",
    "            i + 0.3,\n",
    "            f\"n={test_cm[i, j]}\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            fontsize=11,\n",
    "            color=\"black\",\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "ax2.set_title(\n",
    "    f\"Final Test Confusion Matrix\\n{best_model_name}\", fontweight=\"bold\", pad=15\n",
    ")\n",
    "ax2.set_xlabel(\"Predicted\", fontweight=\"bold\")\n",
    "ax2.set_ylabel(\"Actual\", fontweight=\"bold\")\n",
    "ax2.set_xticklabels([\"No Upgrade\", \"Upgrade\"])\n",
    "ax2.set_yticklabels([\"No Upgrade\", \"Upgrade\"])\n",
    "\n",
    "# 3. Test Set ROC Curve\n",
    "test_fpr, test_tpr, _ = roc_curve(y_test, test_pred_proba)\n",
    "ax3.plot(\n",
    "    test_fpr,\n",
    "    test_tpr,\n",
    "    color=colors[0],\n",
    "    linewidth=3,\n",
    "    alpha=0.8,\n",
    "    label=f\"{best_model_name}\\n(AUC = {test_auc:.3f})\",\n",
    ")\n",
    "ax3.fill_between(test_fpr, test_tpr, alpha=0.2, color=colors[0])\n",
    "\n",
    "# Add diagonal line (random classifier)\n",
    "ax3.plot([0, 1], [0, 1], \"k--\", alpha=0.8, linewidth=2, label=\"Random Classifier\")\n",
    "\n",
    "ax3.set_title(\"Final Test ROC Curve\", fontweight=\"bold\", pad=15)\n",
    "ax3.set_xlabel(\"False Positive Rate\", fontweight=\"bold\")\n",
    "ax3.set_ylabel(\"True Positive Rate\", fontweight=\"bold\")\n",
    "ax3.legend(loc=\"lower right\", framealpha=0.9)\n",
    "ax3.grid(alpha=0.3)\n",
    "ax3.set_xlim([0, 1])\n",
    "ax3.set_ylim([0, 1])\n",
    "\n",
    "# 4. Prediction Probability Distribution (Test Set)\n",
    "test_upgrade_proba = test_pred_proba[y_test == 1]\n",
    "test_no_upgrade_proba = test_pred_proba[y_test == 0]\n",
    "\n",
    "ax4.hist(\n",
    "    test_no_upgrade_proba,\n",
    "    bins=25,\n",
    "    alpha=0.7,\n",
    "    color=upgrade_colors[0],\n",
    "    label=f\"No Upgrade (n={len(test_no_upgrade_proba)})\",\n",
    "    density=True,\n",
    "    edgecolor=\"white\",\n",
    ")\n",
    "ax4.hist(\n",
    "    test_upgrade_proba,\n",
    "    bins=25,\n",
    "    alpha=0.7,\n",
    "    color=upgrade_colors[1],\n",
    "    label=f\"Upgrade (n={len(test_upgrade_proba)})\",\n",
    "    density=True,\n",
    "    edgecolor=\"white\",\n",
    ")\n",
    "\n",
    "ax4.set_title(\n",
    "    f\"Test Set Probability Distribution\\n{best_model_name}\", fontweight=\"bold\", pad=15\n",
    ")\n",
    "ax4.set_xlabel(\"Predicted Probability of Upgrade\", fontweight=\"bold\")\n",
    "ax4.set_ylabel(\"Density\", fontweight=\"bold\")\n",
    "ax4.legend(framealpha=0.9)\n",
    "ax4.grid(alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "# Add vertical line at decision threshold (0.5)\n",
    "ax4.axvline(x=0.5, color=\"red\", linestyle=\"--\", linewidth=2, alpha=0.8)\n",
    "ax4.text(\n",
    "    0.52, ax4.get_ylim()[1] * 0.9, \"Decision\\nThreshold\", color=\"red\", fontweight=\"bold\"\n",
    ")\n",
    "\n",
    "# Add mean probabilities\n",
    "mean_upgrade = test_upgrade_proba.mean()\n",
    "mean_no_upgrade = test_no_upgrade_proba.mean()\n",
    "ax4.axvline(\n",
    "    x=mean_upgrade, color=upgrade_colors[1], linestyle=\":\", alpha=0.8, linewidth=2\n",
    ")\n",
    "ax4.axvline(\n",
    "    x=mean_no_upgrade, color=upgrade_colors[0], linestyle=\":\", alpha=0.8, linewidth=2\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graphs/06_final_test_results.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print(\"✓ Final test results plots saved to: graphs/06_final_test_results.png\")\n",
    "\n",
    "# Final test summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FINAL TEST RESULTS SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n🏆 FINAL MODEL: {best_model_name}\")\n",
    "print(f\"   • Test ROC-AUC: {test_auc:.4f}\")\n",
    "print(f\"   • Test Accuracy: {test_accuracy:.4f} ({test_accuracy:.1%})\")\n",
    "print(f\"   • Test Precision: {test_precision:.4f}\")\n",
    "print(f\"   • Test Recall: {test_recall:.4f}\")\n",
    "print(f\"   • Test F1-Score: {test_f1:.4f}\")\n",
    "\n",
    "print(f\"\\n📊 PROBABILITY ANALYSIS:\")\n",
    "print(f\"   • Mean probability for upgrades: {test_upgrade_proba.mean():.3f}\")\n",
    "print(f\"   • Mean probability for no upgrades: {test_no_upgrade_proba.mean():.3f}\")\n",
    "print(\n",
    "    f\"   • Separation: {abs(test_upgrade_proba.mean() - test_no_upgrade_proba.mean()):.3f}\"\n",
    ")\n",
    "\n",
    "print(f\"\\n🎯 CONFUSION MATRIX BREAKDOWN:\")\n",
    "tn, fp, fn, tp = test_cm.ravel()\n",
    "print(f\"   • True Negatives (Correct No-Upgrade): {tn}\")\n",
    "print(f\"   • False Positives (Incorrect Upgrade): {fp}\")\n",
    "print(f\"   • False Negatives (Missed Upgrade): {fn}\")\n",
    "print(f\"   • True Positives (Correct Upgrade): {tp}\")\n",
    "\n",
    "print(f\"\\n💼 BUSINESS METRICS:\")\n",
    "print(f\"   • Total test customers: {len(y_test)}\")\n",
    "print(f\"   • Actual upgrades: {y_test.sum()} ({y_test.mean():.1%})\")\n",
    "print(f\"   • Predicted upgrades: {test_pred.sum()}\")\n",
    "print(f\"   • Correctly identified upgrades: {tp}\")\n",
    "print(\n",
    "    f\"   • Marketing efficiency: {tp / max(test_pred.sum(), 1) * 100:.1f}% (precision)\"\n",
    ")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a45c6d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Business Insights & Recommendations:\n",
      "============================================================\n",
      "\n",
      "📊 MODEL PERFORMANCE SUMMARY:\n",
      "   • Best performing model: Random Forest\n",
      "   • Test set accuracy: 57.4%\n",
      "   • Test set ROC-AUC: 0.597\n",
      "   • Model can identify 60.0% of customers who will upgrade\n",
      "   • 56.6% of predicted upgrades are correct\n",
      "\n",
      "💼 BUSINESS IMPACT:\n",
      "   • Total test customers: 303\n",
      "   • Actual upgrades: 150 (49.5%)\n",
      "   • Predicted upgrades: 159\n",
      "   • Correctly identified upgrades: 90\n",
      "   • Potential revenue impact: High (targeted marketing efficiency)\n",
      "\n",
      "🎯 KEY RECOMMENDATIONS:\n",
      "   • Focus on top predictive features:\n",
      "     1. trustfor\n",
      "     2. identity\n",
      "     3. benefits\n",
      "   • Implement targeted retention strategies\n",
      "   • Use model for customer segmentation\n",
      "   • Monitor model performance quarterly\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Business insights and recommendations\n",
    "print(\"\\nBusiness Insights & Recommendations:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n📊 MODEL PERFORMANCE SUMMARY:\")\n",
    "print(f\"   • Best performing model: {best_model_name}\")\n",
    "print(f\"   • Test set accuracy: {test_accuracy:.1%}\")\n",
    "print(f\"   • Test set ROC-AUC: {test_auc:.3f}\")\n",
    "print(f\"   • Model can identify {test_recall:.1%} of customers who will upgrade\")\n",
    "print(f\"   • {test_precision:.1%} of predicted upgrades are correct\")\n",
    "\n",
    "# Calculate business impact\n",
    "total_customers = len(test_data)\n",
    "actual_upgrades = y_test.sum()\n",
    "predicted_upgrades = test_pred.sum()\n",
    "correctly_identified = (test_pred & y_test).sum()\n",
    "\n",
    "print(\"\\n💼 BUSINESS IMPACT:\")\n",
    "print(f\"   • Total test customers: {total_customers}\")\n",
    "print(\n",
    "    f\"   • Actual upgrades: {actual_upgrades} ({actual_upgrades / total_customers:.1%})\"\n",
    ")\n",
    "print(f\"   • Predicted upgrades: {predicted_upgrades}\")\n",
    "print(f\"   • Correctly identified upgrades: {correctly_identified}\")\n",
    "print(\"   • Potential revenue impact: High (targeted marketing efficiency)\")\n",
    "\n",
    "print(\"\\n🎯 KEY RECOMMENDATIONS:\")\n",
    "if best_model_name in importance_results:\n",
    "    top_features = importance_results[best_model_name]\n",
    "    if best_model_name == \"Logistic Regression\":\n",
    "        top_features.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "    else:\n",
    "        # For both permutation importance and tree-based importance, sort by value\n",
    "        top_features.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"   • Focus on top predictive features:\")\n",
    "    for i, (feature, _) in enumerate(top_features[:3], 1):\n",
    "        clean_feature = (\n",
    "            feature.replace(\"standardized__\", \"\")\n",
    "            .replace(\"categorical__\", \"\")\n",
    "            .replace(\"numeric__\", \"\")\n",
    "            .replace(\"ordinal__\", \"\")\n",
    "        )\n",
    "        print(f\"     {i}. {clean_feature}\")\n",
    "\n",
    "print(\"   • Implement targeted retention strategies\")\n",
    "print(\"   • Use model for customer segmentation\")\n",
    "print(\"   • Monitor model performance quarterly\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
