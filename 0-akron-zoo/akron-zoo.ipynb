{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0039fac",
   "metadata": {},
   "source": [
    "BUAI 446 Assignment 1 - Akron Zoo\n",
    "Name: Ruihuang Yang\n",
    "NetID: rxy216\n",
    "Date: 09/07/2025\n",
    "Disclaimer: Some code in this document was generated with assistance from Claude 4.0 Sonnet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8dbc47",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb030c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06fcb15",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e23d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and test datasets\n",
    "train_data = pd.read_csv(\"data/ZOOLOG1-TRAIN-2025.csv\")\n",
    "test_data = pd.read_csv(\"data/ZOOLOG1-TEST-2025.csv\")\n",
    "\n",
    "print(\"Training Data Shape:\", train_data.shape)\n",
    "print(\"Test Data Shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5897a794",
   "metadata": {},
   "source": [
    "#### Basic Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3324025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows of training data\n",
    "print(\"Training Data - First 5 rows:\")\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ff64d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display column information\n",
    "print(\"\\nTraining Data - Column Info:\")\n",
    "print(train_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b90e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic statistics\n",
    "print(\"\\nTraining Data - Descriptive Statistics:\")\n",
    "print(train_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac62ec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values in training data:\")\n",
    "print(train_data.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in test data:\")\n",
    "print(test_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9678520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check target variable distribution\n",
    "print(\"\\nTarget variable (UPD) distribution in training data:\")\n",
    "print(train_data[\"UPD\"].value_counts())\n",
    "print(f\"\\nUpgrade rate: {train_data['UPD'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b337cb",
   "metadata": {},
   "source": [
    "### EDA Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d8c918",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from scipy.stats import chi2_contingency\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Create graphs directory if it doesn't exist\n",
    "os.makedirs(\"graphs\", exist_ok=True)\n",
    "\n",
    "# Set up beautiful styling for plots\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "plt.rcParams[\"axes.titlesize\"] = 16\n",
    "plt.rcParams[\"axes.labelsize\"] = 14\n",
    "plt.rcParams[\"xtick.labelsize\"] = 12\n",
    "plt.rcParams[\"ytick.labelsize\"] = 12\n",
    "plt.rcParams[\"legend.fontsize\"] = 12\n",
    "\n",
    "# Define a professional color palette\n",
    "colors = [\"#2E86AB\", \"#A23B72\", \"#F18F01\", \"#C73E1D\", \"#592E83\", \"#27AE60\"]\n",
    "upgrade_colors = [\"#E74C3C\", \"#2ECC71\"]  # Red for No Upgrade, Green for Upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428a1bbd",
   "metadata": {},
   "source": [
    "#### Dataset Balance Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe94d78",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Create a comprehensive view of dataset balance\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar chart showing upgrade distribution\n",
    "upgrade_counts = train_data[\"UPD\"].value_counts().sort_index()\n",
    "bars = ax1.bar(\n",
    "    [\"No Upgrade\", \"Upgrade\"],\n",
    "    upgrade_counts.values,\n",
    "    color=upgrade_colors,\n",
    "    alpha=0.8,\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=2,\n",
    ")\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, count) in enumerate(zip(bars, upgrade_counts.values)):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 5,\n",
    "        f\"{count}\\n({count / len(train_data) * 100:.1f}%)\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "\n",
    "ax1.set_title(\n",
    "    \"Customer Upgrade Distribution\\n(Training Dataset)\", fontweight=\"bold\", pad=20\n",
    ")\n",
    "ax1.set_ylabel(\"Number of Customers\", fontweight=\"bold\")\n",
    "ax1.set_ylim(0, max(upgrade_counts.values) * 1.15)\n",
    "ax1.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "# Add sample size annotation\n",
    "ax1.text(\n",
    "    0.5,\n",
    "    -0.15,\n",
    "    f\"Total Sample Size: {len(train_data)} customers\",\n",
    "    transform=ax1.transAxes,\n",
    "    ha=\"center\",\n",
    "    fontsize=12,\n",
    "    style=\"italic\",\n",
    ")\n",
    "\n",
    "# Pie chart for visual balance\n",
    "wedges, texts, autotexts = ax2.pie(\n",
    "    upgrade_counts.values,\n",
    "    labels=[\"No Upgrade\\n(50.0%)\", \"Upgrade\\n(50.0%)\"],\n",
    "    colors=upgrade_colors,\n",
    "    autopct=\"\",\n",
    "    startangle=90,\n",
    "    textprops={\"fontsize\": 14, \"fontweight\": \"bold\"},\n",
    "    wedgeprops={\"edgecolor\": \"white\", \"linewidth\": 3},\n",
    ")\n",
    "\n",
    "ax2.set_title(\n",
    "    \"Dataset Balance Visualization\\n(Perfectly Balanced)\", fontweight=\"bold\", pad=20\n",
    ")\n",
    "\n",
    "# Add center circle for donut effect\n",
    "centre_circle = plt.Circle((0, 0), 0.50, fc=\"white\", linewidth=2, edgecolor=\"gray\")\n",
    "ax2.add_artist(centre_circle)\n",
    "ax2.text(\n",
    "    0,\n",
    "    0,\n",
    "    \"Balanced\\nDataset\",\n",
    "    ha=\"center\",\n",
    "    va=\"center\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\",\n",
    "    color=\"gray\",\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graphs/01_dataset_balance.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print(\"Dataset Balance Summary:\")\n",
    "print(\n",
    "    f\"• No Upgrade: {upgrade_counts[0]} customers ({upgrade_counts[0] / len(train_data) * 100:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"• Upgrade: {upgrade_counts[1]} customers ({upgrade_counts[1] / len(train_data) * 100:.1f}%)\"\n",
    ")\n",
    "print(\"• Perfect balance ratio: 1:1\")\n",
    "print(f\"• Total sample size: {len(train_data)} customers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12efcef5",
   "metadata": {},
   "source": [
    "#### Distance vs Upgrade Behavior Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f255785",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Create distance labels for better visualization\n",
    "distance_labels = {1: \"< 10 min\", 2: \"10-20 min\", 3: \"21-30 min\", 4: \"> 30 min\"}\n",
    "train_data[\"dist_label\"] = train_data[\"dist\"].map(distance_labels)\n",
    "\n",
    "# Calculate upgrade rates by distance\n",
    "dist_analysis = (\n",
    "    train_data.groupby(\"dist_label\").agg({\"UPD\": [\"count\", \"sum\", \"mean\"]}).round(3)\n",
    ")\n",
    "dist_analysis.columns = [\"Total_Customers\", \"Upgrades\", \"Upgrade_Rate\"]\n",
    "dist_analysis = dist_analysis.reindex(\n",
    "    [\"< 10 min\", \"10-20 min\", \"21-30 min\", \"> 30 min\"]\n",
    ")\n",
    "\n",
    "print(\"Distance vs Upgrade Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "for dist, row in dist_analysis.iterrows():\n",
    "    print(\n",
    "        f\"{dist:12s}: {row['Total_Customers']:3.0f} customers, \"\n",
    "        f\"{row['Upgrades']:3.0f} upgrades ({row['Upgrade_Rate'] * 100:5.1f}%)\"\n",
    "    )\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8dd3ca",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Create comprehensive distance vs upgrade visualizations\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(18, 14))\n",
    "\n",
    "# 1. Stacked Bar Chart showing absolute numbers\n",
    "dist_crosstab = pd.crosstab(train_data[\"dist_label\"], train_data[\"UPD\"])\n",
    "dist_crosstab = dist_crosstab.reindex(\n",
    "    [\"< 10 min\", \"10-20 min\", \"21-30 min\", \"> 30 min\"]\n",
    ")\n",
    "\n",
    "bars1 = ax1.bar(\n",
    "    dist_crosstab.index,\n",
    "    dist_crosstab[0],\n",
    "    color=upgrade_colors[0],\n",
    "    alpha=0.8,\n",
    "    label=\"No Upgrade\",\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=1,\n",
    ")\n",
    "bars2 = ax1.bar(\n",
    "    dist_crosstab.index,\n",
    "    dist_crosstab[1],\n",
    "    bottom=dist_crosstab[0],\n",
    "    color=upgrade_colors[1],\n",
    "    alpha=0.8,\n",
    "    label=\"Upgrade\",\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=1,\n",
    ")\n",
    "\n",
    "# Add value labels\n",
    "for i, (idx, row) in enumerate(dist_crosstab.iterrows()):\n",
    "    total = row.sum()\n",
    "    ax1.text(\n",
    "        i,\n",
    "        row[0] / 2,\n",
    "        f\"{row[0]}\",\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        fontweight=\"bold\",\n",
    "        color=\"white\",\n",
    "    )\n",
    "    ax1.text(\n",
    "        i,\n",
    "        row[0] + row[1] / 2,\n",
    "        f\"{row[1]}\",\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        fontweight=\"bold\",\n",
    "        color=\"white\",\n",
    "    )\n",
    "    ax1.text(\n",
    "        i,\n",
    "        total + 5,\n",
    "        f\"Total: {total}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "ax1.set_title(\n",
    "    \"Customer Distribution by Distance\\n(Absolute Numbers)\", fontweight=\"bold\", pad=20\n",
    ")\n",
    "ax1.set_ylabel(\"Number of Customers\", fontweight=\"bold\")\n",
    "ax1.legend(loc=\"upper right\", framealpha=0.9)\n",
    "ax1.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "# 2. Upgrade Rate by Distance (Percentage)\n",
    "upgrade_rates = dist_analysis[\"Upgrade_Rate\"] * 100\n",
    "colors_gradient = [\"#FF6B6B\", \"#4ECDC4\", \"#45B7D1\", \"#96CEB4\"]\n",
    "\n",
    "bars = ax2.bar(\n",
    "    upgrade_rates.index,\n",
    "    upgrade_rates.values,\n",
    "    color=colors_gradient,\n",
    "    alpha=0.8,\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=2,\n",
    ")\n",
    "\n",
    "# Add percentage labels on bars\n",
    "for bar, rate in zip(bars, upgrade_rates.values):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 1,\n",
    "        f\"{rate:.1f}%\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=12,\n",
    "    )\n",
    "\n",
    "ax2.set_title(\n",
    "    \"Upgrade Rate by Distance from Zoo\\n(Percentage)\", fontweight=\"bold\", pad=20\n",
    ")\n",
    "ax2.set_ylabel(\"Upgrade Rate (%)\", fontweight=\"bold\")\n",
    "ax2.set_ylim(0, max(upgrade_rates.values) * 1.2)\n",
    "ax2.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "# Add average line\n",
    "avg_rate = train_data[\"UPD\"].mean() * 100\n",
    "ax2.axhline(y=avg_rate, color=\"red\", linestyle=\"--\", alpha=0.7, linewidth=2)\n",
    "ax2.text(\n",
    "    0.02,\n",
    "    avg_rate + 1,\n",
    "    f\"Overall Average: {avg_rate:.1f}%\",\n",
    "    transform=ax2.get_yaxis_transform(),\n",
    "    fontsize=10,\n",
    "    color=\"red\",\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "\n",
    "# 3. Grouped Bar Chart for detailed comparison\n",
    "x = np.arange(len(dist_analysis.index))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax3.bar(\n",
    "    x - width / 2,\n",
    "    dist_analysis[\"Total_Customers\"],\n",
    "    width,\n",
    "    label=\"Total Customers\",\n",
    "    color=\"#3498DB\",\n",
    "    alpha=0.8,\n",
    "    edgecolor=\"white\",\n",
    ")\n",
    "bars2 = ax3.bar(\n",
    "    x + width / 2,\n",
    "    dist_analysis[\"Upgrades\"],\n",
    "    width,\n",
    "    label=\"Upgrades\",\n",
    "    color=\"#2ECC71\",\n",
    "    alpha=0.8,\n",
    "    edgecolor=\"white\",\n",
    ")\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar1, bar2) in enumerate(zip(bars1, bars2)):\n",
    "    ax3.text(\n",
    "        bar1.get_x() + bar1.get_width() / 2.0,\n",
    "        bar1.get_height() + 2,\n",
    "        f\"{int(bar1.get_height())}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "    ax3.text(\n",
    "        bar2.get_x() + bar2.get_width() / 2.0,\n",
    "        bar2.get_height() + 2,\n",
    "        f\"{int(bar2.get_height())}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "ax3.set_title(\n",
    "    \"Customer Count vs Upgrades by Distance\\n(Side-by-side Comparison)\",\n",
    "    fontweight=\"bold\",\n",
    "    pad=20,\n",
    ")\n",
    "ax3.set_ylabel(\"Number of Customers\", fontweight=\"bold\")\n",
    "ax3.set_xticks(x)\n",
    "ax3.set_xticklabels(dist_analysis.index, rotation=45)\n",
    "ax3.legend(framealpha=0.9)\n",
    "ax3.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "# 4. Heatmap showing upgrade patterns\n",
    "pivot_data = train_data.groupby([\"dist_label\", \"UPD\"]).size().unstack(fill_value=0)\n",
    "pivot_data = pivot_data.reindex([\"< 10 min\", \"10-20 min\", \"21-30 min\", \"> 30 min\"])\n",
    "pivot_pct = pivot_data.div(pivot_data.sum(axis=1), axis=0) * 100\n",
    "\n",
    "sns.heatmap(\n",
    "    pivot_pct,\n",
    "    annot=True,\n",
    "    fmt=\".1f\",\n",
    "    cmap=\"RdYlGn\",\n",
    "    center=50,\n",
    "    ax=ax4,\n",
    "    cbar_kws={\"label\": \"Percentage\"},\n",
    ")\n",
    "ax4.set_title(\n",
    "    \"Upgrade Behavior Heatmap\\n(Percentage Distribution)\", fontweight=\"bold\", pad=20\n",
    ")\n",
    "ax4.set_xlabel(\"Upgrade Decision\", fontweight=\"bold\")\n",
    "ax4.set_ylabel(\"Distance from Zoo\", fontweight=\"bold\")\n",
    "ax4.set_xticklabels([\"No Upgrade\", \"Upgrade\"], rotation=0)\n",
    "ax4.set_yticklabels(ax4.get_yticklabels(), rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graphs/02_distance_analysis.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134e8d21",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Generate insights summary for presentation\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"KEY INSIGHTS FROM DISTANCE ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Find the distance category with highest and lowest upgrade rates\n",
    "max_upgrade_dist = dist_analysis[\"Upgrade_Rate\"].idxmax()\n",
    "min_upgrade_dist = dist_analysis[\"Upgrade_Rate\"].idxmin()\n",
    "max_rate = dist_analysis.loc[max_upgrade_dist, \"Upgrade_Rate\"] * 100\n",
    "min_rate = dist_analysis.loc[min_upgrade_dist, \"Upgrade_Rate\"] * 100\n",
    "\n",
    "print(\"\\n📍 DISTANCE IMPACT ON UPGRADES:\")\n",
    "print(f\"   • Highest upgrade rate: {max_upgrade_dist} ({max_rate:.1f}%)\")\n",
    "print(f\"   • Lowest upgrade rate:  {min_upgrade_dist} ({min_rate:.1f}%)\")\n",
    "print(f\"   • Difference: {max_rate - min_rate:.1f} percentage points\")\n",
    "\n",
    "# Calculate statistical significance (Chi-square test)\n",
    "chi2, p_value, dof, expected = chi2_contingency(dist_crosstab)\n",
    "\n",
    "print(\"\\n📊 STATISTICAL SIGNIFICANCE:\")\n",
    "print(f\"   • Chi-square statistic: {chi2:.3f}\")\n",
    "print(f\"   • P-value: {p_value:.4f}\")\n",
    "print(\n",
    "    f\"   • Significance: {'Significant' if p_value < 0.05 else 'Not significant'} at α=0.05\"\n",
    ")\n",
    "\n",
    "# Business implications\n",
    "print(\"\\n💡 BUSINESS IMPLICATIONS:\")\n",
    "if max_rate > 50:\n",
    "    print(f\"   • Customers living {max_upgrade_dist} show higher upgrade propensity\")\n",
    "    print(\"   • Consider targeted marketing for this distance segment\")\n",
    "else:\n",
    "    print(\"   • Distance appears to negatively impact upgrade likelihood\")\n",
    "    print(\"   • Focus on improving value proposition for distant customers\")\n",
    "\n",
    "print(f\"   • Overall upgrade rate: {train_data['UPD'].mean() * 100:.1f}%\")\n",
    "print(\"   • Distance-based segmentation may be valuable for strategy\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767bb047",
   "metadata": {},
   "source": [
    "#### Visit Frequency vs Upgrade Behavior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffad8dd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Create visit frequency labels for better visualization\n",
    "visit_labels = {\n",
    "    1: \"≤ 2 visits\",\n",
    "    2: \"3-4 visits\",\n",
    "    3: \"5-6 visits\",\n",
    "    4: \"7-8 visits\",\n",
    "    5: \"> 8 visits\",\n",
    "}\n",
    "train_data[\"tvis_label\"] = train_data[\"tvis\"].map(visit_labels)\n",
    "\n",
    "# Calculate upgrade rates by visit frequency\n",
    "visit_analysis = (\n",
    "    train_data.groupby(\"tvis_label\").agg({\"UPD\": [\"count\", \"sum\", \"mean\"]}).round(3)\n",
    ")\n",
    "visit_analysis.columns = [\"Total_Customers\", \"Upgrades\", \"Upgrade_Rate\"]\n",
    "visit_analysis = visit_analysis.reindex(\n",
    "    [\"≤ 2 visits\", \"3-4 visits\", \"5-6 visits\", \"7-8 visits\", \"> 8 visits\"]\n",
    ")\n",
    "\n",
    "# Create a beautiful visualization for visit frequency vs upgrades\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# 1. Upgrade rate by visit frequency\n",
    "upgrade_rates_visits = visit_analysis[\"Upgrade_Rate\"] * 100\n",
    "colors_visits = [\"#FF6B6B\", \"#4ECDC4\", \"#45B7D1\", \"#96CEB4\", \"#FFA07A\"]\n",
    "\n",
    "bars = ax1.bar(\n",
    "    range(len(upgrade_rates_visits)),\n",
    "    upgrade_rates_visits.values,\n",
    "    color=colors_visits,\n",
    "    alpha=0.8,\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=2,\n",
    ")\n",
    "\n",
    "# Add percentage labels on bars\n",
    "for i, (bar, rate) in enumerate(zip(bars, upgrade_rates_visits.values)):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 1,\n",
    "        f\"{rate:.1f}%\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=11,\n",
    "    )\n",
    "\n",
    "ax1.set_title(\n",
    "    \"Upgrade Rate by Visit Frequency\\n(Higher engagement = Higher upgrades?)\",\n",
    "    fontweight=\"bold\",\n",
    "    pad=20,\n",
    ")\n",
    "ax1.set_ylabel(\"Upgrade Rate (%)\", fontweight=\"bold\")\n",
    "ax1.set_xticks(range(len(upgrade_rates_visits)))\n",
    "ax1.set_xticklabels(upgrade_rates_visits.index, rotation=45, ha=\"right\")\n",
    "ax1.set_ylim(0, max(upgrade_rates_visits.values) * 1.2)\n",
    "ax1.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "# Add average line\n",
    "avg_rate = train_data[\"UPD\"].mean() * 100\n",
    "ax1.axhline(y=avg_rate, color=\"red\", linestyle=\"--\", alpha=0.7, linewidth=2)\n",
    "ax1.text(\n",
    "    0.02,\n",
    "    avg_rate + 2,\n",
    "    f\"Overall Average: {avg_rate:.1f}%\",\n",
    "    transform=ax1.get_yaxis_transform(),\n",
    "    fontsize=10,\n",
    "    color=\"red\",\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "\n",
    "# 2. Customer distribution by visit frequency\n",
    "visit_counts = train_data[\"tvis_label\"].value_counts()\n",
    "visit_counts = visit_counts.reindex(\n",
    "    [\"≤ 2 visits\", \"3-4 visits\", \"5-6 visits\", \"7-8 visits\", \"> 8 visits\"]\n",
    ")\n",
    "\n",
    "bars = ax2.bar(\n",
    "    range(len(visit_counts)),\n",
    "    visit_counts.values,\n",
    "    color=colors_visits,\n",
    "    alpha=0.8,\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=2,\n",
    ")\n",
    "\n",
    "# Add count labels on bars\n",
    "for i, (bar, count) in enumerate(zip(bars, visit_counts.values)):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 3,\n",
    "        f\"{count}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=11,\n",
    "    )\n",
    "    # Add percentage of total\n",
    "    pct = count / len(train_data) * 100\n",
    "    ax2.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height / 2,\n",
    "        f\"{pct:.1f}%\",\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        fontweight=\"bold\",\n",
    "        color=\"white\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "ax2.set_title(\n",
    "    \"Customer Distribution by Visit Frequency\\n(Engagement Patterns)\",\n",
    "    fontweight=\"bold\",\n",
    "    pad=20,\n",
    ")\n",
    "ax2.set_ylabel(\"Number of Customers\", fontweight=\"bold\")\n",
    "ax2.set_xticks(range(len(visit_counts)))\n",
    "ax2.set_xticklabels(visit_counts.index, rotation=45, ha=\"right\")\n",
    "ax2.set_ylim(0, max(visit_counts.values) * 1.15)\n",
    "ax2.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graphs/03_visit_frequency_analysis.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nVisit Frequency vs Upgrade Analysis:\")\n",
    "print(\"=\" * 55)\n",
    "for visit, row in visit_analysis.iterrows():\n",
    "    print(\n",
    "        f\"{visit:12s}: {row['Total_Customers']:3.0f} customers, \"\n",
    "        f\"{row['Upgrades']:3.0f} upgrades ({row['Upgrade_Rate'] * 100:5.1f}%)\"\n",
    "    )\n",
    "print(\"=\" * 55)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e2c084",
   "metadata": {},
   "source": [
    "### Data Preprocessing & Feature Engineering\n",
    "\n",
    "#### Objective: Prepare data for machine learning models with appropriate encoding and scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c65170b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Import preprocessing libraries\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Check current data shape and missing values\n",
    "print(\"Data Preprocessing Setup\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "print(f\"Missing values in training: {train_data.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in test: {test_data.isnull().sum().sum()}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a394ea",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Feature categorization based on business logic and statistical properties\n",
    "print(\"\\nFeature Categorization:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Features to exclude (ID variables)\n",
    "id_features = [\"NID\"]\n",
    "\n",
    "# Target variable\n",
    "target = \"UPD\"\n",
    "\n",
    "# Categorical features (non-linear relationship) - need dummy encoding\n",
    "categorical_nonlinear = [\n",
    "    \"gender\",  # 1=Male, 2=Female (nominal)\n",
    "    \"mstat\",  # 1=Married, 2=Single, 3=Divorced, 4=Widow (nominal)\n",
    "    \"educ\",  # 1=Some college, 2=College, 3=Graduate school (treated as nominal per user)\n",
    "    \"educnew\",  # Recoded education variable (nominal)\n",
    "    \"age_rec\",  # 1=18-34, 2=35-44, 3=45-54, 4=54+ (treated as nominal per user)\n",
    "    \"tvis\",  # 1=≤2, 2=3-4, 3=5-6, 4=7-8, 5=>8 visits (treated as nominal per user)\n",
    "]\n",
    "\n",
    "# Ordinal features with linear relationship - use numeric + normalize\n",
    "ordinal_linear = [\n",
    "    \"dist\",  # 1=<10min, 2=10-20min, 3=21-30min, 4=>30min (clear distance progression)\n",
    "]\n",
    "\n",
    "# Already standardized perception features (mean≈0, std≈1)\n",
    "standardized_features = [\n",
    "    \"benefits\",\n",
    "    \"costs\",\n",
    "    \"value\",\n",
    "    \"identity\",\n",
    "    \"know\",\n",
    "    \"sat\",\n",
    "    \"fle\",\n",
    "    \"trustfor\",\n",
    "]\n",
    "\n",
    "# Other numeric features that need scaling\n",
    "numeric_features = [\n",
    "    \"age\",  # Age in categories (1-5 scale)\n",
    "    \"size\",  # Household size (1-6)\n",
    "    \"child1\",  # Number of children/grandchildren (0-6)\n",
    "]\n",
    "\n",
    "print(f\"Categorical (dummy encode): {categorical_nonlinear}\")\n",
    "print(f\"Ordinal linear (normalize): {ordinal_linear}\")\n",
    "print(f\"Already standardized: {standardized_features}\")\n",
    "print(f\"Numeric (need scaling): {numeric_features}\")\n",
    "print(f\"ID features (exclude): {id_features}\")\n",
    "print(f\"Target variable: {target}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963d6f4c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Create comprehensive preprocessing pipeline\n",
    "print(\"\\nBuilding Preprocessing Pipeline:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create preprocessing steps for different feature types\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # One-hot encode categorical features (drop='first' to avoid multicollinearity)\n",
    "        (\n",
    "            \"categorical\",\n",
    "            OneHotEncoder(drop=\"first\", sparse_output=False),\n",
    "            categorical_nonlinear,\n",
    "        ),\n",
    "        # Standardize ordinal features with linear relationship\n",
    "        (\"ordinal\", StandardScaler(), ordinal_linear),\n",
    "        # Keep already standardized features as-is\n",
    "        (\"standardized\", \"passthrough\", standardized_features),\n",
    "        # Standardize other numeric features\n",
    "        (\"numeric\", StandardScaler(), numeric_features),\n",
    "    ],\n",
    "    remainder=\"drop\",  # Drop any remaining features (like NID)\n",
    ")\n",
    "\n",
    "print(\"Pipeline Components:\")\n",
    "print(\"• OneHotEncoder: Categorical features → Binary dummy variables\")\n",
    "print(\"• StandardScaler: Ordinal/Numeric features → Mean=0, Std=1\")\n",
    "print(\"• PassThrough: Pre-standardized features → Unchanged\")\n",
    "print(\"• Remainder: ID features → Dropped\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8b797f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Prepare data for preprocessing\n",
    "print(\"\\nPreparing Data for Preprocessing:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Separate features and target for training data\n",
    "X_train_raw = train_data.drop(columns=[target])\n",
    "y_train = train_data[target]\n",
    "\n",
    "# Separate features for test data (test data has target too, but we'll use it for final evaluation)\n",
    "X_test_raw = test_data.drop(columns=[target])\n",
    "y_test = test_data[target]\n",
    "\n",
    "print(f\"Training features shape: {X_train_raw.shape}\")\n",
    "print(f\"Training target shape: {y_train.shape}\")\n",
    "print(f\"Test features shape: {X_test_raw.shape}\")\n",
    "print(f\"Test target shape: {y_test.shape}\")\n",
    "\n",
    "# Show feature names before preprocessing\n",
    "print(f\"\\nOriginal features ({len(X_train_raw.columns)}):\")\n",
    "print(list(X_train_raw.columns))\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65e0740",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Apply preprocessing pipeline\n",
    "print(\"\\nApplying Preprocessing Pipeline:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Fit preprocessor on training data only (prevents data leakage)\n",
    "print(\"Fitting preprocessor on training data...\")\n",
    "X_train_processed = preprocessor.fit_transform(X_train_raw)\n",
    "\n",
    "# Transform test data using fitted preprocessor\n",
    "print(\"Transforming test data...\")\n",
    "X_test_processed = preprocessor.transform(X_test_raw)\n",
    "\n",
    "print(f\"Processed training shape: {X_train_processed.shape}\")\n",
    "print(f\"Processed test shape: {X_test_processed.shape}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79809282",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Get feature names after preprocessing\n",
    "print(\"\\nFeature Names After Preprocessing:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get feature names from the fitted preprocessor\n",
    "feature_names = []\n",
    "\n",
    "# Get names from each transformer\n",
    "categorical_names = list(\n",
    "    preprocessor.named_transformers_[\"categorical\"].get_feature_names_out(\n",
    "        categorical_nonlinear\n",
    "    )\n",
    ")\n",
    "ordinal_names = [f\"ordinal__{col}\" for col in ordinal_linear]\n",
    "standardized_names = [f\"standardized__{col}\" for col in standardized_features]\n",
    "numeric_names = [f\"numeric__{col}\" for col in numeric_features]\n",
    "\n",
    "# Combine all feature names\n",
    "feature_names = categorical_names + ordinal_names + standardized_names + numeric_names\n",
    "\n",
    "print(f\"Total features after preprocessing: {len(feature_names)}\")\n",
    "print(f\"Feature expansion: {X_train_raw.shape[1]} → {len(feature_names)} features\")\n",
    "print(\"\\nFeature breakdown:\")\n",
    "print(f\"• Categorical (dummy): {len(categorical_names)} features\")\n",
    "print(f\"• Ordinal (scaled): {len(ordinal_names)} features\")\n",
    "print(f\"• Standardized (passthrough): {len(standardized_names)} features\")\n",
    "print(f\"• Numeric (scaled): {len(numeric_names)} features\")\n",
    "\n",
    "# Show first few categorical feature names (dummy variables)\n",
    "print(\"\\nSample categorical features (first 10):\")\n",
    "print(categorical_names[:10])\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ee41a2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Create validation split from training data\n",
    "print(\"\\nCreating Validation Split:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Split training data into train/validation (80/20 split, stratified)\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train_processed, y_train, test_size=0.2, random_state=SEED, stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"Training split: {X_train_split.shape}\")\n",
    "print(f\"Validation split: {X_val_split.shape}\")\n",
    "print(f\"Training target distribution: {np.bincount(y_train_split)}\")\n",
    "print(f\"Validation target distribution: {np.bincount(y_val_split)}\")\n",
    "print(f\"Training upgrade rate: {y_train_split.mean():.3f}\")\n",
    "print(f\"Validation upgrade rate: {y_val_split.mean():.3f}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed30948a",
   "metadata": {},
   "source": [
    "### Feature Engineering & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dff5f71",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Create DataFrame for easier manipulation and feature engineering\n",
    "print(\"\\nFeature Engineering Setup:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Convert to DataFrame for easier feature engineering\n",
    "X_train_df = pd.DataFrame(X_train_processed, columns=feature_names)\n",
    "X_val_df = pd.DataFrame(X_val_split, columns=feature_names)\n",
    "X_test_df = pd.DataFrame(X_test_processed, columns=feature_names)\n",
    "\n",
    "print(f\"Training DataFrame shape: {X_train_df.shape}\")\n",
    "print(f\"Validation DataFrame shape: {X_val_df.shape}\")\n",
    "print(f\"Test DataFrame shape: {X_test_df.shape}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461ff635",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Correlation analysis and feature relationships\n",
    "print(\"\\nCorrelation Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = X_train_df.corr()\n",
    "\n",
    "# Find highly correlated features (threshold = 0.8)\n",
    "high_corr_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i + 1, len(correlation_matrix.columns)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.8:\n",
    "            high_corr_pairs.append(\n",
    "                (\n",
    "                    correlation_matrix.columns[i],\n",
    "                    correlation_matrix.columns[j],\n",
    "                    correlation_matrix.iloc[i, j],\n",
    "                )\n",
    "            )\n",
    "\n",
    "print(f\"Found {len(high_corr_pairs)} highly correlated feature pairs (|r| > 0.8):\")\n",
    "for feat1, feat2, corr in high_corr_pairs[:10]:  # Show first 10\n",
    "    print(f\"  {feat1} ↔ {feat2}: {corr:.3f}\")\n",
    "\n",
    "if len(high_corr_pairs) > 10:\n",
    "    print(f\"  ... and {len(high_corr_pairs) - 10} more pairs\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1172d7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Feature correlation with target variable\n",
    "print(\"\\nFeature-Target Correlations:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calculate correlations with target\n",
    "target_correlations = []\n",
    "for feature in feature_names:\n",
    "    corr = np.corrcoef(X_train_df[feature], y_train)[0, 1]\n",
    "    target_correlations.append((feature, corr))\n",
    "\n",
    "# Sort by absolute correlation\n",
    "target_correlations.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "print(\"Top 15 features most correlated with upgrade decision:\")\n",
    "for i, (feature, corr) in enumerate(target_correlations[:15], 1):\n",
    "    print(f\"{i:2d}. {feature:<40}: {corr:6.3f}\")\n",
    "\n",
    "print(\"\\nBottom 5 features least correlated with upgrade decision:\")\n",
    "for i, (feature, corr) in enumerate(\n",
    "    target_correlations[-5:], len(target_correlations) - 4\n",
    "):\n",
    "    print(f\"{i:2d}. {feature:<40}: {corr:6.3f}\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b351fb",
   "metadata": {},
   "source": [
    "### Machine Learning Model Development\n",
    "\n",
    "#### Implementing 6 models: Logistic Regression, SVM, Naive Bayes, Random Forest, GBM, KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1c090e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Import machine learning libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "import time\n",
    "\n",
    "print(\"Machine Learning Model Setup\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5078bcbe",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Define models with initial parameters\n",
    "print(\"\\nInitializing Models:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        random_state=SEED, max_iter=1000, penalty=\"l2\"\n",
    "    ),\n",
    "    \"SVM\": SVC(\n",
    "        random_state=SEED,\n",
    "        probability=True,  # Enable probability estimates for ROC-AUC\n",
    "        kernel=\"rbf\",\n",
    "    ),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=SEED, n_estimators=500),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(\n",
    "        random_state=SEED, n_estimators=500\n",
    "    ),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5, weights=\"distance\"),\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"✓ {name}: {type(model).__name__}\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc1bdc2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Cross-validation evaluation\n",
    "print(\"\\nCross-Validation Evaluation:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Setup stratified k-fold cross-validation\n",
    "cv_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Store results\n",
    "cv_results = {}\n",
    "training_times = {}\n",
    "\n",
    "print(\"Performing 5-fold cross-validation for each model...\")\n",
    "print(\"\\nModel Performance (CV Mean ± Std):\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "\n",
    "    # Time the training\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(\n",
    "        model, X_train_split, y_train_split, cv=cv_folds, scoring=\"roc_auc\", n_jobs=-1\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    # Store results\n",
    "    cv_results[name] = cv_scores\n",
    "    training_times[name] = training_time\n",
    "\n",
    "    # Print results\n",
    "    mean_score = cv_scores.mean()\n",
    "    std_score = cv_scores.std()\n",
    "    print(\n",
    "        f\"{name:<20}: {mean_score:.4f} ± {std_score:.4f} (Time: {training_time:.2f}s)\"\n",
    "    )\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(\"Metric: ROC-AUC (Higher is better)\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b46bdc5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Train models on full training split and evaluate on validation\n",
    "print(\"\\nValidation Set Evaluation:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Store validation results\n",
    "val_results = {}\n",
    "trained_models = {}\n",
    "\n",
    "print(\"Training models on full training split and evaluating on validation set...\")\n",
    "print(\"\\nValidation Performance:\")\n",
    "print(\"-\" * 80)\n",
    "print(\n",
    "    f\"{'Model':<20} {'ROC-AUC':<8} {'Accuracy':<8} {'Precision':<10} {'Recall':<8} {'F1-Score':<8}\"\n",
    ")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train model on training split\n",
    "    model.fit(X_train_split, y_train_split)\n",
    "    trained_models[name] = model\n",
    "\n",
    "    # Predict on validation set\n",
    "    val_pred = model.predict(X_val_split)\n",
    "    val_pred_proba = model.predict_proba(X_val_split)[:, 1]\n",
    "\n",
    "    # Calculate metrics\n",
    "    val_auc = roc_auc_score(y_val_split, val_pred_proba)\n",
    "    val_accuracy = (val_pred == y_val_split).mean()\n",
    "\n",
    "    # Get precision, recall, f1 from classification report\n",
    "    report = classification_report(y_val_split, val_pred, output_dict=True)\n",
    "    val_precision = report[\"1\"][\"precision\"]\n",
    "    val_recall = report[\"1\"][\"recall\"]\n",
    "    val_f1 = report[\"1\"][\"f1-score\"]\n",
    "\n",
    "    # Store results\n",
    "    val_results[name] = {\n",
    "        \"auc\": val_auc,\n",
    "        \"accuracy\": val_accuracy,\n",
    "        \"precision\": val_precision,\n",
    "        \"recall\": val_recall,\n",
    "        \"f1\": val_f1,\n",
    "        \"predictions\": val_pred,\n",
    "        \"probabilities\": val_pred_proba,\n",
    "    }\n",
    "\n",
    "    # Print results\n",
    "    print(\n",
    "        f\"{name:<20} {val_auc:<8.4f} {val_accuracy:<8.4f} {val_precision:<10.4f} {val_recall:<8.4f} {val_f1:<8.4f}\"\n",
    "    )\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60992c71",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Model ranking and selection\n",
    "print(\"\\nModel Ranking and Selection:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Rank models by ROC-AUC on validation set\n",
    "model_ranking = sorted(val_results.items(), key=lambda x: x[1][\"auc\"], reverse=True)\n",
    "\n",
    "print(\"Model Performance Ranking (by ROC-AUC):\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Rank':<5} {'Model':<20} {'ROC-AUC':<10} {'CV Score':<12} {'Robustness'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for i, (name, results) in enumerate(model_ranking, 1):\n",
    "    cv_mean = cv_results[name].mean()\n",
    "    cv_std = cv_results[name].std()\n",
    "    robustness = \"High\" if cv_std < 0.02 else \"Medium\" if cv_std < 0.05 else \"Low\"\n",
    "\n",
    "    print(\n",
    "        f\"{i:<5} {name:<20} {results['auc']:<10.4f} {cv_mean:.4f}±{cv_std:.3f} {robustness}\"\n",
    "    )\n",
    "\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Select best model\n",
    "best_model_name = model_ranking[0][0]\n",
    "best_model = trained_models[best_model_name]\n",
    "best_results = val_results[best_model_name]\n",
    "\n",
    "print(f\"\\n🏆 BEST MODEL: {best_model_name}\")\n",
    "print(f\"   • ROC-AUC: {best_results['auc']:.4f}\")\n",
    "print(f\"   • Accuracy: {best_results['accuracy']:.4f}\")\n",
    "print(f\"   • F1-Score: {best_results['f1']:.4f}\")\n",
    "print(\n",
    "    f\"   • Cross-validation: {cv_results[best_model_name].mean():.4f} ± {cv_results[best_model_name].std():.3f}\"\n",
    ")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f3e4dd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Feature importance analysis for interpretable models\n",
    "print(\"\\nFeature Importance Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Extract feature importance from different models\n",
    "importance_results = {}\n",
    "\n",
    "# 1. Logistic Regression - Coefficients\n",
    "if \"Logistic Regression\" in trained_models:\n",
    "    lr_model = trained_models[\"Logistic Regression\"]\n",
    "    lr_coef = lr_model.coef_[0]\n",
    "    importance_results[\"Logistic Regression\"] = list(zip(feature_names, lr_coef))\n",
    "\n",
    "# 2. Random Forest - Feature Importance\n",
    "if \"Random Forest\" in trained_models:\n",
    "    rf_model = trained_models[\"Random Forest\"]\n",
    "    rf_importance = rf_model.feature_importances_\n",
    "    importance_results[\"Random Forest\"] = list(zip(feature_names, rf_importance))\n",
    "\n",
    "# 3. Gradient Boosting - Feature Importance\n",
    "if \"Gradient Boosting\" in trained_models:\n",
    "    gb_model = trained_models[\"Gradient Boosting\"]\n",
    "    gb_importance = gb_model.feature_importances_\n",
    "    importance_results[\"Gradient Boosting\"] = list(zip(feature_names, gb_importance))\n",
    "\n",
    "# 4. For models without inherent feature importance (KNN, SVM, Naive Bayes)\n",
    "# Use permutation importance as a model-agnostic approach\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "non_interpretable_models = [\"K-Nearest Neighbors\", \"SVM\", \"Naive Bayes\"]\n",
    "for model_name in non_interpretable_models:\n",
    "    if model_name in trained_models:\n",
    "        model = trained_models[model_name]\n",
    "        # Calculate permutation importance on validation set (faster than full training set)\n",
    "        perm_importance = permutation_importance(\n",
    "            model, X_val_split, y_val_split, n_repeats=5, random_state=SEED, n_jobs=-1\n",
    "        )\n",
    "        importance_results[model_name] = list(\n",
    "            zip(feature_names, perm_importance.importances_mean)\n",
    "        )\n",
    "\n",
    "# Display feature importance for best model\n",
    "if best_model_name in importance_results:\n",
    "    print(f\"\\nTop 15 Most Important Features ({best_model_name}):\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    best_importance = importance_results[best_model_name]\n",
    "    if best_model_name == \"Logistic Regression\":\n",
    "        # Sort by absolute coefficient value\n",
    "        best_importance.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "        print(f\"{'Feature':<40} {'Coefficient':<15} {'Abs Value':<10}\")\n",
    "        print(\"-\" * 70)\n",
    "        for i, (feature, coef) in enumerate(best_importance[:15], 1):\n",
    "            print(f\"{i:2d}. {feature:<35} {coef:8.4f} {abs(coef):8.4f}\")\n",
    "    elif best_model_name in non_interpretable_models:\n",
    "        # Sort by permutation importance value\n",
    "        best_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "        print(f\"{'Feature':<40} {'Perm Importance':<15}\")\n",
    "        print(\"-\" * 70)\n",
    "        for i, (feature, importance) in enumerate(best_importance[:15], 1):\n",
    "            print(f\"{i:2d}. {feature:<35} {importance:8.4f}\")\n",
    "    else:\n",
    "        # Sort by feature importance value (tree-based models)\n",
    "        best_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "        print(f\"{'Feature':<40} {'Importance':<15}\")\n",
    "        print(\"-\" * 70)\n",
    "        for i, (feature, importance) in enumerate(best_importance[:15], 1):\n",
    "            print(f\"{i:2d}. {feature:<35} {importance:8.4f}\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3f9801",
   "metadata": {},
   "source": [
    "#### Model Comparison Visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb490c81",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Create comprehensive model comparison and prediction visualizations\n",
    "print(\"\\nCreating Model Comparison Visualizations:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create a large figure with multiple subplots for model comparison\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "\n",
    "# 1. Model Performance Comparison (ROC-AUC with CV confidence)\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "model_names = list(cv_results.keys())\n",
    "cv_means = [cv_results[name].mean() for name in model_names]\n",
    "cv_stds = [cv_results[name].std() for name in model_names]\n",
    "val_aucs = [val_results[name][\"auc\"] for name in model_names]\n",
    "\n",
    "x_pos = np.arange(len(model_names))\n",
    "width = 0.35\n",
    "\n",
    "# CV scores with error bars\n",
    "bars1 = ax1.bar(\n",
    "    x_pos - width / 2,\n",
    "    cv_means,\n",
    "    width,\n",
    "    yerr=cv_stds,\n",
    "    color=colors[: len(model_names)],\n",
    "    alpha=0.8,\n",
    "    label=\"CV Mean ± Std\",\n",
    "    capsize=5,\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=1,\n",
    ")\n",
    "\n",
    "# Validation scores\n",
    "bars2 = ax1.bar(\n",
    "    x_pos + width / 2,\n",
    "    val_aucs,\n",
    "    width,\n",
    "    color=colors[: len(model_names)],\n",
    "    alpha=0.6,\n",
    "    label=\"Validation AUC\",\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=1,\n",
    ")\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar1, bar2, mean_val, val_auc) in enumerate(\n",
    "    zip(bars1, bars2, cv_means, val_aucs)\n",
    "):\n",
    "    ax1.text(\n",
    "        bar1.get_x() + bar1.get_width() / 2,\n",
    "        bar1.get_height() + cv_stds[i] + 0.01,\n",
    "        f\"{mean_val:.3f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=9,\n",
    "    )\n",
    "    ax1.text(\n",
    "        bar2.get_x() + bar2.get_width() / 2,\n",
    "        bar2.get_height() + 0.01,\n",
    "        f\"{val_auc:.3f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=9,\n",
    "    )\n",
    "\n",
    "ax1.set_title(\n",
    "    \"Model Performance Comparison\\n(ROC-AUC Scores)\", fontweight=\"bold\", pad=15\n",
    ")\n",
    "ax1.set_ylabel(\"ROC-AUC Score\", fontweight=\"bold\")\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels([name.replace(\" \", \"\\n\") for name in model_names], fontsize=10)\n",
    "ax1.legend(loc=\"lower right\", framealpha=0.9)\n",
    "ax1.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "ax1.set_ylim(0, 1.1)\n",
    "\n",
    "# 2. Model Robustness (CV Standard Deviation)\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "robustness_colors = [\n",
    "    \"#2ECC71\" if std < 0.02 else \"#F39C12\" if std < 0.05 else \"#E74C3C\"\n",
    "    for std in cv_stds\n",
    "]\n",
    "\n",
    "bars = ax2.bar(\n",
    "    x_pos, cv_stds, color=robustness_colors, alpha=0.8, edgecolor=\"white\", linewidth=2\n",
    ")\n",
    "\n",
    "# Add value labels\n",
    "for bar, std in zip(bars, cv_stds):\n",
    "    ax2.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height() + 0.001,\n",
    "        f\"{std:.3f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "ax2.set_title(\"Model Robustness\\n(Lower = More Robust)\", fontweight=\"bold\", pad=15)\n",
    "ax2.set_ylabel(\"Cross-Validation Std Dev\", fontweight=\"bold\")\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels([name.replace(\" \", \"\\n\") for name in model_names], fontsize=10)\n",
    "ax2.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "# Add robustness legend\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "legend_elements = [\n",
    "    Patch(facecolor=\"#2ECC71\", label=\"High (< 0.02)\"),\n",
    "    Patch(facecolor=\"#F39C12\", label=\"Medium (0.02-0.05)\"),\n",
    "    Patch(facecolor=\"#E74C3C\", label=\"Low (> 0.05)\"),\n",
    "]\n",
    "ax2.legend(\n",
    "    handles=legend_elements, title=\"Robustness\", loc=\"upper right\", framealpha=0.9\n",
    ")\n",
    "\n",
    "# 3. Training Time Comparison\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "training_time_values = [training_times[name] for name in model_names]\n",
    "time_colors = [\n",
    "    \"#3498DB\" if t < 1 else \"#F39C12\" if t < 10 else \"#E74C3C\"\n",
    "    for t in training_time_values\n",
    "]\n",
    "\n",
    "bars = ax3.bar(\n",
    "    x_pos,\n",
    "    training_time_values,\n",
    "    color=time_colors,\n",
    "    alpha=0.8,\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=2,\n",
    ")\n",
    "\n",
    "# Add value labels\n",
    "for bar, time_val in zip(bars, training_time_values):\n",
    "    ax3.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height() + max(training_time_values) * 0.02,\n",
    "        f\"{time_val:.1f}s\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "ax3.set_title(\n",
    "    \"Training Time Comparison\\n(5-Fold Cross-Validation)\", fontweight=\"bold\", pad=15\n",
    ")\n",
    "ax3.set_ylabel(\"Training Time (seconds)\", fontweight=\"bold\")\n",
    "ax3.set_xticks(x_pos)\n",
    "ax3.set_xticklabels([name.replace(\" \", \"\\n\") for name in model_names], fontsize=10)\n",
    "ax3.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "# 4. ROC Curves for All Models\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "for i, (name, results) in enumerate(val_results.items()):\n",
    "    y_pred_proba = results[\"probabilities\"]\n",
    "    fpr, tpr, _ = roc_curve(y_val_split, y_pred_proba)\n",
    "    auc = results[\"auc\"]\n",
    "\n",
    "    ax4.plot(\n",
    "        fpr,\n",
    "        tpr,\n",
    "        color=colors[i],\n",
    "        linewidth=2.5,\n",
    "        alpha=0.8,\n",
    "        label=f\"{name} (AUC = {auc:.3f})\",\n",
    "    )\n",
    "\n",
    "# Add diagonal line (random classifier)\n",
    "ax4.plot([0, 1], [0, 1], \"k--\", alpha=0.5, linewidth=1.5, label=\"Random Classifier\")\n",
    "\n",
    "ax4.set_title(\"ROC Curves Comparison\\n(Validation Set)\", fontweight=\"bold\", pad=15)\n",
    "ax4.set_xlabel(\"False Positive Rate\", fontweight=\"bold\")\n",
    "ax4.set_ylabel(\"True Positive Rate\", fontweight=\"bold\")\n",
    "ax4.legend(loc=\"lower right\", framealpha=0.9, fontsize=9)\n",
    "ax4.grid(alpha=0.3)\n",
    "ax4.set_xlim([0, 1])\n",
    "ax4.set_ylim([0, 1])\n",
    "\n",
    "# 5. Model Scores Heatmap\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "metrics = [\"ROC-AUC\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "scores_matrix = []\n",
    "for name in model_names:\n",
    "    results = val_results[name]\n",
    "    scores = [\n",
    "        results[\"auc\"],\n",
    "        results[\"accuracy\"],\n",
    "        results[\"precision\"],\n",
    "        results[\"recall\"],\n",
    "        results[\"f1\"],\n",
    "    ]\n",
    "    scores_matrix.append(scores)\n",
    "\n",
    "scores_df = pd.DataFrame(\n",
    "    scores_matrix,\n",
    "    index=[name.replace(\" \", \"\\n\") for name in model_names],\n",
    "    columns=metrics,\n",
    ")\n",
    "sns.heatmap(\n",
    "    scores_df,\n",
    "    annot=True,\n",
    "    fmt=\".3f\",\n",
    "    cmap=\"RdYlGn\",\n",
    "    center=0.5,\n",
    "    ax=ax5,\n",
    "    cbar_kws={\"label\": \"Score\"},\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    ")\n",
    "ax5.set_title(\n",
    "    \"Model Performance Heatmap\\n(Validation Metrics)\", fontweight=\"bold\", pad=15\n",
    ")\n",
    "ax5.set_xlabel(\"Metrics\", fontweight=\"bold\")\n",
    "ax5.set_ylabel(\"Models\", fontweight=\"bold\")\n",
    "\n",
    "# 6. Best Model Confusion Matrix\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "best_cm = confusion_matrix(y_val_split, val_results[best_model_name][\"predictions\"])\n",
    "best_cm_normalized = best_cm.astype(\"float\") / best_cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "sns.heatmap(\n",
    "    best_cm_normalized,\n",
    "    annot=True,\n",
    "    fmt=\".2%\",\n",
    "    cmap=\"Blues\",\n",
    "    ax=ax6,\n",
    "    cbar_kws={\"label\": \"Percentage\"},\n",
    ")\n",
    "ax6.set_title(\n",
    "    f\"Best Model Confusion Matrix\\n({best_model_name})\", fontweight=\"bold\", pad=15\n",
    ")\n",
    "ax6.set_xlabel(\"Predicted\", fontweight=\"bold\")\n",
    "ax6.set_ylabel(\"Actual\", fontweight=\"bold\")\n",
    "ax6.set_xticklabels([\"No Upgrade\", \"Upgrade\"])\n",
    "ax6.set_yticklabels([\"No Upgrade\", \"Upgrade\"])\n",
    "\n",
    "# Add count annotations\n",
    "for i in range(best_cm.shape[0]):\n",
    "    for j in range(best_cm.shape[1]):\n",
    "        ax6.text(\n",
    "            j + 0.5,\n",
    "            i + 0.7,\n",
    "            f\"n={best_cm[i, j]}\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            fontsize=9,\n",
    "            color=\"black\",\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graphs/04_model_comparison.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print(\"✓ Model comparison plots saved to: graphs/04_model_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f8bf8c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Best Model Detailed Analysis\n",
    "print(\"\\nCreating Best Model Analysis Visualizations:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create detailed visualizations for the best model\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(18, 14))\n",
    "\n",
    "# 1. Feature Importance for Best Model\n",
    "if best_model_name in importance_results:\n",
    "    best_importance = importance_results[best_model_name].copy()\n",
    "\n",
    "    if best_model_name == \"Logistic Regression\":\n",
    "        # Sort by absolute coefficient value\n",
    "        best_importance.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "        top_features = best_importance[:15]\n",
    "        feature_names_clean = [\n",
    "            feat.replace(\"standardized__\", \"\")\n",
    "            .replace(\"categorical__\", \"\")\n",
    "            .replace(\"numeric__\", \"\")\n",
    "            .replace(\"ordinal__\", \"\")\n",
    "            for feat, _ in top_features\n",
    "        ]\n",
    "        importance_values = [abs(val) for _, val in top_features]\n",
    "        title_suffix = \"(Absolute Coefficients)\"\n",
    "    elif best_model_name in non_interpretable_models:\n",
    "        # Sort by permutation importance value\n",
    "        best_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_features = best_importance[:15]\n",
    "        feature_names_clean = [\n",
    "            feat.replace(\"standardized__\", \"\")\n",
    "            .replace(\"categorical__\", \"\")\n",
    "            .replace(\"numeric__\", \"\")\n",
    "            .replace(\"ordinal__\", \"\")\n",
    "            for feat, _ in top_features\n",
    "        ]\n",
    "        importance_values = [val for _, val in top_features]\n",
    "        title_suffix = \"(Permutation Importance)\"\n",
    "    else:\n",
    "        # Sort by importance value (tree-based models)\n",
    "        best_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_features = best_importance[:15]\n",
    "        feature_names_clean = [\n",
    "            feat.replace(\"standardized__\", \"\")\n",
    "            .replace(\"categorical__\", \"\")\n",
    "            .replace(\"numeric__\", \"\")\n",
    "            .replace(\"ordinal__\", \"\")\n",
    "            for feat, _ in top_features\n",
    "        ]\n",
    "        importance_values = [val for _, val in top_features]\n",
    "        title_suffix = \"(Feature Importance)\"\n",
    "\n",
    "    # Create horizontal bar plot\n",
    "    colors_gradient = plt.cm.viridis(np.linspace(0, 1, len(importance_values)))\n",
    "    bars = ax1.barh(\n",
    "        range(len(importance_values)),\n",
    "        importance_values,\n",
    "        color=colors_gradient,\n",
    "        alpha=0.8,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1,\n",
    "    )\n",
    "\n",
    "    # Add value labels\n",
    "    for i, (bar, val) in enumerate(zip(bars, importance_values)):\n",
    "        ax1.text(\n",
    "            val + max(importance_values) * 0.01,\n",
    "            bar.get_y() + bar.get_height() / 2,\n",
    "            f\"{val:.3f}\",\n",
    "            va=\"center\",\n",
    "            fontweight=\"bold\",\n",
    "            fontsize=9,\n",
    "        )\n",
    "\n",
    "    ax1.set_title(\n",
    "        f\"Top 15 Most Important Features\\n{best_model_name} {title_suffix}\",\n",
    "        fontweight=\"bold\",\n",
    "        pad=15,\n",
    "    )\n",
    "    ax1.set_xlabel(\"Importance Score\", fontweight=\"bold\")\n",
    "    ax1.set_yticks(range(len(feature_names_clean)))\n",
    "    ax1.set_yticklabels(feature_names_clean, fontsize=10)\n",
    "    ax1.grid(axis=\"x\", alpha=0.3, linestyle=\"--\")\n",
    "    ax1.invert_yaxis()\n",
    "\n",
    "# 2. Prediction Probability Distribution\n",
    "best_proba = val_results[best_model_name][\"probabilities\"]\n",
    "upgrade_proba = best_proba[y_val_split == 1]\n",
    "no_upgrade_proba = best_proba[y_val_split == 0]\n",
    "\n",
    "ax2.hist(\n",
    "    no_upgrade_proba,\n",
    "    bins=30,\n",
    "    alpha=0.7,\n",
    "    color=upgrade_colors[0],\n",
    "    label=f\"No Upgrade (n={len(no_upgrade_proba)})\",\n",
    "    density=True,\n",
    "    edgecolor=\"white\",\n",
    ")\n",
    "ax2.hist(\n",
    "    upgrade_proba,\n",
    "    bins=30,\n",
    "    alpha=0.7,\n",
    "    color=upgrade_colors[1],\n",
    "    label=f\"Upgrade (n={len(upgrade_proba)})\",\n",
    "    density=True,\n",
    "    edgecolor=\"white\",\n",
    ")\n",
    "\n",
    "ax2.set_title(\n",
    "    f\"Prediction Probability Distribution\\n({best_model_name})\",\n",
    "    fontweight=\"bold\",\n",
    "    pad=15,\n",
    ")\n",
    "ax2.set_xlabel(\"Predicted Probability of Upgrade\", fontweight=\"bold\")\n",
    "ax2.set_ylabel(\"Density\", fontweight=\"bold\")\n",
    "ax2.legend(framealpha=0.9)\n",
    "ax2.grid(alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "# Add vertical line at decision threshold (0.5)\n",
    "ax2.axvline(x=0.5, color=\"red\", linestyle=\"--\", linewidth=2, alpha=0.8)\n",
    "ax2.text(\n",
    "    0.52, ax2.get_ylim()[1] * 0.9, \"Decision\\nThreshold\", color=\"red\", fontweight=\"bold\"\n",
    ")\n",
    "\n",
    "# 3. Precision-Recall Curve\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_val_split, best_proba)\n",
    "avg_precision = average_precision_score(y_val_split, best_proba)\n",
    "\n",
    "ax3.plot(\n",
    "    recall,\n",
    "    precision,\n",
    "    color=colors[0],\n",
    "    linewidth=3,\n",
    "    alpha=0.8,\n",
    "    label=f\"{best_model_name}\\n(AP = {avg_precision:.3f})\",\n",
    ")\n",
    "ax3.fill_between(recall, precision, alpha=0.2, color=colors[0])\n",
    "\n",
    "# Add baseline (random classifier)\n",
    "baseline = y_val_split.mean()\n",
    "ax3.axhline(\n",
    "    y=baseline,\n",
    "    color=\"gray\",\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.8,\n",
    "    linewidth=2,\n",
    "    label=f\"Random Classifier\\n(AP = {baseline:.3f})\",\n",
    ")\n",
    "\n",
    "ax3.set_title(\"Precision-Recall Curve\\n(Validation Set)\", fontweight=\"bold\", pad=15)\n",
    "ax3.set_xlabel(\"Recall (True Positive Rate)\", fontweight=\"bold\")\n",
    "ax3.set_ylabel(\"Precision (Positive Predictive Value)\", fontweight=\"bold\")\n",
    "ax3.legend(loc=\"lower left\", framealpha=0.9)\n",
    "ax3.grid(alpha=0.3)\n",
    "ax3.set_xlim([0, 1])\n",
    "ax3.set_ylim([0, 1])\n",
    "\n",
    "# 4. Model Calibration (Reliability Diagram)\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(\n",
    "    y_val_split, best_proba, n_bins=10\n",
    ")\n",
    "\n",
    "ax4.plot(\n",
    "    mean_predicted_value,\n",
    "    fraction_of_positives,\n",
    "    \"s-\",\n",
    "    color=colors[0],\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    "    alpha=0.8,\n",
    "    label=f\"{best_model_name}\",\n",
    ")\n",
    "ax4.plot([0, 1], [0, 1], \"k--\", alpha=0.8, linewidth=2, label=\"Perfectly Calibrated\")\n",
    "\n",
    "# Fill area between perfect calibration and actual\n",
    "ax4.fill_between(\n",
    "    mean_predicted_value,\n",
    "    fraction_of_positives,\n",
    "    mean_predicted_value,\n",
    "    alpha=0.3,\n",
    "    color=colors[0],\n",
    ")\n",
    "\n",
    "ax4.set_title(\"Model Calibration\\n(Reliability Diagram)\", fontweight=\"bold\", pad=15)\n",
    "ax4.set_xlabel(\"Mean Predicted Probability\", fontweight=\"bold\")\n",
    "ax4.set_ylabel(\"Fraction of Positives\", fontweight=\"bold\")\n",
    "ax4.legend(framealpha=0.9)\n",
    "ax4.grid(alpha=0.3)\n",
    "ax4.set_xlim([0, 1])\n",
    "ax4.set_ylim([0, 1])\n",
    "\n",
    "# Add calibration score annotation\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "brier_score = brier_score_loss(y_val_split, best_proba)\n",
    "ax4.text(\n",
    "    0.02,\n",
    "    0.98,\n",
    "    f\"Brier Score: {brier_score:.4f}\\n(Lower is Better)\",\n",
    "    transform=ax4.transAxes,\n",
    "    va=\"top\",\n",
    "    fontsize=10,\n",
    "    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8),\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graphs/05_best_model_analysis.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print(\"✓ Best model analysis plots saved to: graphs/05_best_model_analysis.png\")\n",
    "\n",
    "# Generate insights summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"VISUALIZATION INSIGHTS SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n📈 MODEL COMPARISON INSIGHTS:\")\n",
    "best_cv = max(cv_results.items(), key=lambda x: x[1].mean())\n",
    "most_robust = min(cv_results.items(), key=lambda x: x[1].std())\n",
    "fastest = min(training_times.items(), key=lambda x: x[1])\n",
    "\n",
    "print(f\"   • Best CV performance: {best_cv[0]} ({best_cv[1].mean():.4f})\")\n",
    "print(f\"   • Most robust model: {most_robust[0]} (std: {most_robust[1].std():.4f})\")\n",
    "print(f\"   • Fastest training: {fastest[0]} ({fastest[1]:.2f}s)\")\n",
    "\n",
    "print(f\"\\n🎯 BEST MODEL ({best_model_name}) INSIGHTS:\")\n",
    "print(f\"   • Validation AUC: {val_results[best_model_name]['auc']:.4f}\")\n",
    "print(f\"   • Average Precision: {avg_precision:.4f}\")\n",
    "print(\n",
    "    f\"   • Model calibration: {'Well calibrated' if brier_score < 0.25 else 'Needs calibration'}\"\n",
    ")\n",
    "print(\n",
    "    f\"   • Probability separation: {'Good' if abs(upgrade_proba.mean() - no_upgrade_proba.mean()) > 0.2 else 'Fair'}\"\n",
    ")\n",
    "\n",
    "if best_model_name in importance_results:\n",
    "    top_3_features = importance_results[best_model_name][:3]\n",
    "    if best_model_name == \"Logistic Regression\":\n",
    "        top_3_features.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "    else:\n",
    "        # For both permutation importance and tree-based importance, sort by value\n",
    "        top_3_features.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(f\"   • Top 3 predictive features:\")\n",
    "    for i, (feature, _) in enumerate(top_3_features[:3], 1):\n",
    "        clean_feature = (\n",
    "            feature.replace(\"standardized__\", \"\")\n",
    "            .replace(\"categorical__\", \"\")\n",
    "            .replace(\"numeric__\", \"\")\n",
    "            .replace(\"ordinal__\", \"\")\n",
    "        )\n",
    "        print(f\"     {i}. {clean_feature}\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2260a75",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Final test set evaluation\n",
    "print(\"\\nFinal Test Set Evaluation:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Retrain best model on full training data (training + validation)\n",
    "print(f\"Retraining {best_model_name} on full training data...\")\n",
    "final_model = models[best_model_name]\n",
    "final_model.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "test_pred = final_model.predict(X_test_processed)\n",
    "test_pred_proba = final_model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "# Calculate test metrics\n",
    "test_auc = roc_auc_score(y_test, test_pred_proba)\n",
    "test_accuracy = (test_pred == y_test).mean()\n",
    "\n",
    "# Get detailed metrics\n",
    "test_report = classification_report(y_test, test_pred, output_dict=True)\n",
    "test_precision = test_report[\"1\"][\"precision\"]\n",
    "test_recall = test_report[\"1\"][\"recall\"]\n",
    "test_f1 = test_report[\"1\"][\"f1-score\"]\n",
    "\n",
    "print(\"\\nFinal Model Performance on Test Set:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Model: {best_model_name}\")\n",
    "print(f\"ROC-AUC:   {test_auc:.4f}\")\n",
    "print(f\"Accuracy:  {test_accuracy:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall:    {test_recall:.4f}\")\n",
    "print(f\"F1-Score:  {test_f1:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "test_cm = confusion_matrix(y_test, test_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(\"                 Predicted\")\n",
    "print(\"Actual    No Upgrade  Upgrade\")\n",
    "print(f\"No Upgrade    {test_cm[0, 0]:4d}     {test_cm[0, 1]:4d}\")\n",
    "print(f\"Upgrade       {test_cm[1, 0]:4d}     {test_cm[1, 1]:4d}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70abd1a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Final Test Results Visualization\n",
    "print(\"\\nCreating Final Test Results Visualization:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create final test results visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Performance Metrics Comparison (Validation vs Test)\n",
    "metrics = [\"ROC-AUC\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "val_scores = [\n",
    "    val_results[best_model_name][\"auc\"],\n",
    "    val_results[best_model_name][\"accuracy\"],\n",
    "    val_results[best_model_name][\"precision\"],\n",
    "    val_results[best_model_name][\"recall\"],\n",
    "    val_results[best_model_name][\"f1\"],\n",
    "]\n",
    "test_scores = [test_auc, test_accuracy, test_precision, test_recall, test_f1]\n",
    "\n",
    "x_pos = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(\n",
    "    x_pos - width / 2,\n",
    "    val_scores,\n",
    "    width,\n",
    "    label=\"Validation\",\n",
    "    color=colors[0],\n",
    "    alpha=0.8,\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=1,\n",
    ")\n",
    "bars2 = ax1.bar(\n",
    "    x_pos + width / 2,\n",
    "    test_scores,\n",
    "    width,\n",
    "    label=\"Test\",\n",
    "    color=colors[1],\n",
    "    alpha=0.8,\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=1,\n",
    ")\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar1, bar2, val_score, test_score) in enumerate(\n",
    "    zip(bars1, bars2, val_scores, test_scores)\n",
    "):\n",
    "    ax1.text(\n",
    "        bar1.get_x() + bar1.get_width() / 2,\n",
    "        bar1.get_height() + 0.01,\n",
    "        f\"{val_score:.3f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=9,\n",
    "    )\n",
    "    ax1.text(\n",
    "        bar2.get_x() + bar2.get_width() / 2,\n",
    "        bar2.get_height() + 0.01,\n",
    "        f\"{test_score:.3f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=9,\n",
    "    )\n",
    "\n",
    "ax1.set_title(\n",
    "    f\"Final Model Performance\\n{best_model_name} (Validation vs Test)\",\n",
    "    fontweight=\"bold\",\n",
    "    pad=15,\n",
    ")\n",
    "ax1.set_ylabel(\"Score\", fontweight=\"bold\")\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(metrics, rotation=45, ha=\"right\")\n",
    "ax1.legend(framealpha=0.9)\n",
    "ax1.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "ax1.set_ylim(0, 1.1)\n",
    "\n",
    "# 2. Test Set Confusion Matrix (Enhanced)\n",
    "test_cm = confusion_matrix(y_test, test_pred)\n",
    "test_cm_normalized = test_cm.astype(\"float\") / test_cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Create custom colormap\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "colors_cm = [\"white\", colors[0]]\n",
    "cm_custom = LinearSegmentedColormap.from_list(\"custom\", colors_cm)\n",
    "\n",
    "sns.heatmap(\n",
    "    test_cm_normalized,\n",
    "    annot=True,\n",
    "    fmt=\".2%\",\n",
    "    cmap=cm_custom,\n",
    "    ax=ax2,\n",
    "    cbar_kws={\"label\": \"Percentage\"},\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    ")\n",
    "\n",
    "# Add count annotations\n",
    "for i in range(test_cm.shape[0]):\n",
    "    for j in range(test_cm.shape[1]):\n",
    "        ax2.text(\n",
    "            j + 0.5,\n",
    "            i + 0.3,\n",
    "            f\"n={test_cm[i, j]}\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            fontsize=11,\n",
    "            color=\"black\",\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "ax2.set_title(\n",
    "    f\"Final Test Confusion Matrix\\n{best_model_name}\", fontweight=\"bold\", pad=15\n",
    ")\n",
    "ax2.set_xlabel(\"Predicted\", fontweight=\"bold\")\n",
    "ax2.set_ylabel(\"Actual\", fontweight=\"bold\")\n",
    "ax2.set_xticklabels([\"No Upgrade\", \"Upgrade\"])\n",
    "ax2.set_yticklabels([\"No Upgrade\", \"Upgrade\"])\n",
    "\n",
    "# 3. Test Set ROC Curve\n",
    "test_fpr, test_tpr, _ = roc_curve(y_test, test_pred_proba)\n",
    "ax3.plot(\n",
    "    test_fpr,\n",
    "    test_tpr,\n",
    "    color=colors[0],\n",
    "    linewidth=3,\n",
    "    alpha=0.8,\n",
    "    label=f\"{best_model_name}\\n(AUC = {test_auc:.3f})\",\n",
    ")\n",
    "ax3.fill_between(test_fpr, test_tpr, alpha=0.2, color=colors[0])\n",
    "\n",
    "# Add diagonal line (random classifier)\n",
    "ax3.plot([0, 1], [0, 1], \"k--\", alpha=0.8, linewidth=2, label=\"Random Classifier\")\n",
    "\n",
    "ax3.set_title(\"Final Test ROC Curve\", fontweight=\"bold\", pad=15)\n",
    "ax3.set_xlabel(\"False Positive Rate\", fontweight=\"bold\")\n",
    "ax3.set_ylabel(\"True Positive Rate\", fontweight=\"bold\")\n",
    "ax3.legend(loc=\"lower right\", framealpha=0.9)\n",
    "ax3.grid(alpha=0.3)\n",
    "ax3.set_xlim([0, 1])\n",
    "ax3.set_ylim([0, 1])\n",
    "\n",
    "# 4. Prediction Probability Distribution (Test Set)\n",
    "test_upgrade_proba = test_pred_proba[y_test == 1]\n",
    "test_no_upgrade_proba = test_pred_proba[y_test == 0]\n",
    "\n",
    "ax4.hist(\n",
    "    test_no_upgrade_proba,\n",
    "    bins=25,\n",
    "    alpha=0.7,\n",
    "    color=upgrade_colors[0],\n",
    "    label=f\"No Upgrade (n={len(test_no_upgrade_proba)})\",\n",
    "    density=True,\n",
    "    edgecolor=\"white\",\n",
    ")\n",
    "ax4.hist(\n",
    "    test_upgrade_proba,\n",
    "    bins=25,\n",
    "    alpha=0.7,\n",
    "    color=upgrade_colors[1],\n",
    "    label=f\"Upgrade (n={len(test_upgrade_proba)})\",\n",
    "    density=True,\n",
    "    edgecolor=\"white\",\n",
    ")\n",
    "\n",
    "ax4.set_title(\n",
    "    f\"Test Set Probability Distribution\\n{best_model_name}\", fontweight=\"bold\", pad=15\n",
    ")\n",
    "ax4.set_xlabel(\"Predicted Probability of Upgrade\", fontweight=\"bold\")\n",
    "ax4.set_ylabel(\"Density\", fontweight=\"bold\")\n",
    "ax4.legend(framealpha=0.9)\n",
    "ax4.grid(alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "# Add vertical line at decision threshold (0.5)\n",
    "ax4.axvline(x=0.5, color=\"red\", linestyle=\"--\", linewidth=2, alpha=0.8)\n",
    "ax4.text(\n",
    "    0.52, ax4.get_ylim()[1] * 0.9, \"Decision\\nThreshold\", color=\"red\", fontweight=\"bold\"\n",
    ")\n",
    "\n",
    "# Add mean probabilities\n",
    "mean_upgrade = test_upgrade_proba.mean()\n",
    "mean_no_upgrade = test_no_upgrade_proba.mean()\n",
    "ax4.axvline(\n",
    "    x=mean_upgrade, color=upgrade_colors[1], linestyle=\":\", alpha=0.8, linewidth=2\n",
    ")\n",
    "ax4.axvline(\n",
    "    x=mean_no_upgrade, color=upgrade_colors[0], linestyle=\":\", alpha=0.8, linewidth=2\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graphs/06_final_test_results.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print(\"✓ Final test results plots saved to: graphs/06_final_test_results.png\")\n",
    "\n",
    "# Final test summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FINAL TEST RESULTS SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n🏆 FINAL MODEL: {best_model_name}\")\n",
    "print(f\"   • Test ROC-AUC: {test_auc:.4f}\")\n",
    "print(f\"   • Test Accuracy: {test_accuracy:.4f} ({test_accuracy:.1%})\")\n",
    "print(f\"   • Test Precision: {test_precision:.4f}\")\n",
    "print(f\"   • Test Recall: {test_recall:.4f}\")\n",
    "print(f\"   • Test F1-Score: {test_f1:.4f}\")\n",
    "\n",
    "print(f\"\\n📊 PROBABILITY ANALYSIS:\")\n",
    "print(f\"   • Mean probability for upgrades: {test_upgrade_proba.mean():.3f}\")\n",
    "print(f\"   • Mean probability for no upgrades: {test_no_upgrade_proba.mean():.3f}\")\n",
    "print(\n",
    "    f\"   • Separation: {abs(test_upgrade_proba.mean() - test_no_upgrade_proba.mean()):.3f}\"\n",
    ")\n",
    "\n",
    "print(f\"\\n🎯 CONFUSION MATRIX BREAKDOWN:\")\n",
    "tn, fp, fn, tp = test_cm.ravel()\n",
    "print(f\"   • True Negatives (Correct No-Upgrade): {tn}\")\n",
    "print(f\"   • False Positives (Incorrect Upgrade): {fp}\")\n",
    "print(f\"   • False Negatives (Missed Upgrade): {fn}\")\n",
    "print(f\"   • True Positives (Correct Upgrade): {tp}\")\n",
    "\n",
    "print(f\"\\n💼 BUSINESS METRICS:\")\n",
    "print(f\"   • Total test customers: {len(y_test)}\")\n",
    "print(f\"   • Actual upgrades: {y_test.sum()} ({y_test.mean():.1%})\")\n",
    "print(f\"   • Predicted upgrades: {test_pred.sum()}\")\n",
    "print(f\"   • Correctly identified upgrades: {tp}\")\n",
    "print(\n",
    "    f\"   • Marketing efficiency: {tp / max(test_pred.sum(), 1) * 100:.1f}% (precision)\"\n",
    ")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7099813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business insights and recommendations\n",
    "print(\"\\nBusiness Insights & Recommendations:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n📊 MODEL PERFORMANCE SUMMARY:\")\n",
    "print(f\"   • Best performing model: {best_model_name}\")\n",
    "print(f\"   • Test set accuracy: {test_accuracy:.1%}\")\n",
    "print(f\"   • Test set ROC-AUC: {test_auc:.3f}\")\n",
    "print(f\"   • Model can identify {test_recall:.1%} of customers who will upgrade\")\n",
    "print(f\"   • {test_precision:.1%} of predicted upgrades are correct\")\n",
    "\n",
    "# Calculate business impact\n",
    "total_customers = len(test_data)\n",
    "actual_upgrades = y_test.sum()\n",
    "predicted_upgrades = test_pred.sum()\n",
    "correctly_identified = (test_pred & y_test).sum()\n",
    "\n",
    "print(\"\\n💼 BUSINESS IMPACT:\")\n",
    "print(f\"   • Total test customers: {total_customers}\")\n",
    "print(\n",
    "    f\"   • Actual upgrades: {actual_upgrades} ({actual_upgrades / total_customers:.1%})\"\n",
    ")\n",
    "print(f\"   • Predicted upgrades: {predicted_upgrades}\")\n",
    "print(f\"   • Correctly identified upgrades: {correctly_identified}\")\n",
    "print(\"   • Potential revenue impact: High (targeted marketing efficiency)\")\n",
    "\n",
    "print(\"\\n🎯 KEY RECOMMENDATIONS:\")\n",
    "if best_model_name in importance_results:\n",
    "    top_features = importance_results[best_model_name]\n",
    "    if best_model_name == \"Logistic Regression\":\n",
    "        top_features.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "    else:\n",
    "        # For both permutation importance and tree-based importance, sort by value\n",
    "        top_features.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"   • Focus on top predictive features:\")\n",
    "    for i, (feature, _) in enumerate(top_features[:3], 1):\n",
    "        clean_feature = (\n",
    "            feature.replace(\"standardized__\", \"\")\n",
    "            .replace(\"categorical__\", \"\")\n",
    "            .replace(\"numeric__\", \"\")\n",
    "            .replace(\"ordinal__\", \"\")\n",
    "        )\n",
    "        print(f\"     {i}. {clean_feature}\")\n",
    "\n",
    "print(\"   • Implement targeted retention strategies\")\n",
    "print(\"   • Use model for customer segmentation\")\n",
    "print(\"   • Monitor model performance quarterly\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
