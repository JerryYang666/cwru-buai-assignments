{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb9DikpKjlcS"
      },
      "source": [
        "# BUAI 446 - Homework 2\n",
        "# Detecting COVID-19 from Chest CT Scans\n",
        "\n",
        "**Name:** Ruihuang Yang  \n",
        "**NetID:** rxy216  \n",
        "**Date:** Nov 26, 2025  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOsbEj2Ajlcd"
      },
      "source": [
        "As the Coronavirus Disease 2019 (COVID-19) pandemic continues to challenge many countries around the world, testing to detect COVID-19 and isolating individuals who test positive remains a crucial strategy for preventing community spread of the disease. In this context, automatic and accurate detection of COVID-19 using medical imaging modalities, such as Computed Tomography (CT), can be beneficial as a diagnostic tool.\n",
        "\n",
        "In this exercise, our goal is to develop Convolutional Neural Networks to automatically detect the subtle signs of COVID-19 infection in patients' lungs from CT images. Our dataset contains 1010 CT scans from individuals with COVID-19 and 1010 CT scans from patients with other pulmonary diseases (non-COVID-19). These data have been collected from real patients in hospitals from Sao Paulo, Brazil.\n",
        "\n",
        "Our training and validation sets include 1600 and 420 CT images, respectively (half COVID-19, half non-COVID-19). Given the small size of the original dataset, I did not set aside any images for the test set. We will use the validation accuracy to evaluate our models. This is OK since we are not going to use the validation performance as a feedback signal to fine tune the hyperparameters of our models.\n",
        "\n",
        "Your task is to classify the images correctly by building multiple CNNs and comparing their performance.\n",
        "\n",
        "Here are what a few of the CT images look like:\n",
        "\n",
        "![ct-covid](https://www.dropbox.com/s/r9lld9dj7875rsw/ct-covid.jpg?dl=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AmqyCfsjG8z"
      },
      "source": [
        "## Note on training time\n",
        "\n",
        "I recommend you train your CNNs on GPU for faster training. To do so, from the Runtime tab above, go to Change runtime type and select GPU as Hardware accelerator. Training time of each model may take up to an hour on GPU (longer on CPU), so please be patient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.9.1+cu130\n",
            "CUDA available: True\n",
            "CUDA version: 13.0\n",
            "GPU count: 6\n",
            "GPU name: NVIDIA RTX A6000\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"GPU count: {torch.cuda.device_count()}\")\n",
        "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ht4UjqOkkOXR"
      },
      "source": [
        "### Load the data\n",
        "\n",
        "First, add the `covid19_ct` folder from [here](https://drive.google.com/drive/folders/11-2z9P45FtJJPm9LbipVMAnNZ36kMQUH) to your Google Drive. For example, you can drag and drop the `covid19_ct` folder into your \"My Drive\"; this will add a shortcut to the original folder in your \"My Drive\". By doing so, you can run your code directly on the data that are stored on my Google Drive account without the need to download the images and upload them to your Drive.\n",
        "\n",
        "Mount your Google Drive and load the data. Be sure to change the directory path provided below to your own data path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxssO8zYk3Po",
        "outputId": "babaeb0f-3ce8-4c27-8f83-b13994351074"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/homes/rxy216/other-work/cwru-buai-assignments/9-covid-chest-scans/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /usr/homes/rxy216/.cache/kagglehub/datasets/mehradaria/covid19-lung-ct-scans/versions/1\n",
            "Base dir: /usr/homes/rxy216/.cache/kagglehub/datasets/mehradaria/covid19-lung-ct-scans/versions/1/COVID-19_Lung_CT_Scans\n",
            "Subfolders: ['Non-COVID-19', 'COVID-19']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"mehradaria/covid19-lung-ct-scans\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# This is the main folder that contains `COVID-19` and `Non-COVID-19`\n",
        "base_dir = os.path.join(path, \"COVID-19_Lung_CT_Scans\")\n",
        "print(\"Base dir:\", base_dir)\n",
        "print(\"Subfolders:\", os.listdir(base_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuoIdHHvZW8T",
        "outputId": "0c470d5d-8ed5-4878-ee0a-a24f818048ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classes: ['COVID-19', 'Non-COVID-19']\n",
            "Train size: 6751\n",
            "Val size: 1688\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Temporary dataset without transforms â€“ just to get labels for splitting\n",
        "tmp_dataset = datasets.ImageFolder(base_dir)\n",
        "print(\"Classes:\", tmp_dataset.classes)   # should be ['COVID-19', 'Non-COVID-19']\n",
        "\n",
        "indices = np.arange(len(tmp_dataset))\n",
        "labels  = np.array(tmp_dataset.targets)\n",
        "\n",
        "# 80% train, 20% val, stratified by label\n",
        "train_idx, val_idx = train_test_split(\n",
        "    indices,\n",
        "    test_size=0.2,\n",
        "    stratify=labels,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(\"Train size:\", len(train_idx))\n",
        "print(\"Val size:\", len(val_idx))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaUgzJ0vsY_F"
      },
      "source": [
        "Use the code below to check how many images are available for each class in the training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "759tbYH8ZvAq",
        "outputId": "57910044-484b-417f-cacf-ef68d8e826ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total COVID images: 7495\n",
            "Total Non-COVID images: 944\n",
            "Total training covid images: 5996\n",
            "Total training noncovid images: 755\n",
            "Total validation covid images: 1499\n",
            "Total validation noncovid images: 189\n"
          ]
        }
      ],
      "source": [
        "# Total images per class in the whole dataset\n",
        "covid_label     = tmp_dataset.class_to_idx['COVID-19']\n",
        "noncovid_label  = tmp_dataset.class_to_idx['Non-COVID-19']\n",
        "\n",
        "total_covid     = np.sum(labels == covid_label)\n",
        "total_noncovid  = np.sum(labels == noncovid_label)\n",
        "\n",
        "print(\"Total COVID images:\", total_covid)\n",
        "print(\"Total Non-COVID images:\", total_noncovid)\n",
        "\n",
        "# Now counts in TRAIN split\n",
        "train_labels = labels[train_idx]\n",
        "val_labels   = labels[val_idx]\n",
        "\n",
        "train_covid_count    = np.sum(train_labels == covid_label)\n",
        "train_noncovid_count = np.sum(train_labels == noncovid_label)\n",
        "\n",
        "val_covid_count      = np.sum(val_labels == covid_label)\n",
        "val_noncovid_count   = np.sum(val_labels == noncovid_label)\n",
        "\n",
        "print(\"Total training covid images:\", train_covid_count)\n",
        "print(\"Total training noncovid images:\", train_noncovid_count)\n",
        "\n",
        "print(\"Total validation covid images:\", val_covid_count)\n",
        "print(\"Total validation noncovid images:\", val_noncovid_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rENCt559jlcz"
      },
      "source": [
        "## Question 1. Build a simple CNN from scratch (50 pts)\n",
        "\n",
        "Build a simple CNN. Include 3 convolution and 3 max-pooling layers. In convolution layers 1, 2, and 3, include 32, 64, and 64 filters, respectively. Use 3x3 filters, 2x2 pooling windows, and ReLU activation functions. Please use an input shape of 64x64 and note that while these images look like greyscale images, they are in fact color images. Include a dense layer with 128 nodes on top along with an appropriate output layer. Compile the model using `RMSProp` optimizer and use a learning rate of `0.00005`. Follow the `accuracy` metric during training. (hint: if you do not recall how to change the default learning rate of your optimizer, check out Module 1 slides.)\n",
        "\n",
        "For data preprocessing, please use the `ImageDataGenerator` tool in Keras. Create `train_datagen` and `validation_datagen` generators that rescale the images appropriately. Do not do any data augmentation in your first model (that will come next!)\n",
        "Then, define a training set generator and validation set generator using the generators `train_datagen` and `validation_datagen` and the `.flow_from_directory` method. Specify the `target_size` (it should match the input size above), set the `batch_size` to 32 and choose an appropriate `class_mode`. Train the model for 50 epochs.\n",
        "\n",
        "When training is complete, plot the training and validation loss and accuracy. Interpret your plots. Does the model seem to be overfitting? Explain why / why not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DByEZEYpovu"
      },
      "source": [
        "## Question 2. Use transfer learning and data augmentation to improve your CNN (50 pts)\n",
        "\n",
        "Use one of the pre-trained models in Keras that has been trained on the ImageNet dataset (e.g., VGG16) as your convolutional base. Add a densly-connected layer and an output layer with the same number of neurons and the same activation functions as in your previous model to this convolutional base. Make sure to freeze the convolutional base so that the pre-trained weights and biases do not change during the training process of the new densly-connected classifier. Compile the model using `RMSProp` optimizer and use a learning rate of `0.00005`. Follow the `accuracy` metric during training.\n",
        "\n",
        "For data preprocessing, please use the `ImageDataGenerator` tool in Keras. This time use the tool to do data augmentation. You are free to choose the type of transformations made to the training images, or you can just use the same data augmentation parameters we used in class for the cat vs. dog example. Keep the same target size and batch size as your previous model.\n",
        "Train your model for 100 epochs.\n",
        "\n",
        "When training is complete, plot the training and validation loss and accuracy. Interpret your plots. Does the model seem to be overfitting? Explain why / why not.\n",
        "\n",
        "Compare the validation loss and accuracy of the two models you developed in this notebook. Which model would you choose to detect COVID-19 from chest CT images?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAusz81MMneV"
      },
      "source": [
        "Make sure you run all of your code so that the output of each code block appears below it.  Once you are done, download your final `.ipynb` file (File -> Download .ipynb) and submit it on Canvas. Name your file as follows: LastName_FirstName_HW2.ipynb"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
